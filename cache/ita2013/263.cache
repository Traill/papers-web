{"id":"263","paper":{"title":{"text":"Gaussian hybrid digital/analog coding with bandwidth expansion and side information at the decoder "},"authors":[{"name":"Koken, Erman"},{"name":"Tuncel, Ertem"}],"abstr":{"text":"Lossy transmission of a Gaussian source over an additive white Gaussian (AWGN) channel with side information at the decoder is tackled under the regime of bandwidth expansion. A previously known scheme, hybrid digital/analog Wyner-Ziv (HDA-WZ) coding is shown to remain optimal when extended from the bandwidth matched case to the bandwidth expansion case. The extended scheme also exhibits similar robustness properties under mismatched side information and/or channel quality. Its robustness is compared against a purely-digital scheme known as common description scheme (CDS) and uncoded transmission under the criterion of min-max distortion loss introduced in this paper.   "},"body":{"text":"The concept of network coding was introduced for satellite communication networks in [2] and fully developed in [3], where in the latter the term \u201cnetwork coding\u201d was coined and the advantage of network coding over routing was demonstrated. The main result in [3], namely a characterization of the maximum rate at which information generated at a single source node can be multicast, can be regarded as the Max-ﬂow Min-cut theorem for network infor- mation ﬂow. An algorithm for constructing linear network codes that achieve the Max-ﬂow Min-cut bound was devised in [5]. Subsequently, a more transparent proof for the existence of such linear net- work codes was given in [6]. For further references on the subject, we refer the reader to the Network Coding Homepage [10] and the tutorial [7].\nInspired by network coding, network error cor- rection has been introduced in [4] as a paradigm for error correction on networks which can be regarded as an extension of classical point-to-point error correction. Speciﬁcally, the results in [4] [8] [9] are network generalizations of the fundamental bounds in classical algebraic coding theory. In this paper, we discuss the relation between network coding, algebraic coding, and network error correction.\nThe rest of the paper is organized as follows. In Section II, we ﬁrst establish that a linear network code achieving the Max-ﬂow Min-cut bound is a network generalization of a maximum distance sep- aration (MDS) code in classical algebraic coding [1]. This clariﬁes the relation between network coding and classical algebraic coding. In Section III, upon giving an overview of network error correction, we illustrate the complexity involved in the construction of network error-correcting codes by means of an example. Concluding remarks are in Section IV.\nConsider the network in Fig. 1. In this network, there are three layers of nodes. The top layer con- sists of the source node   , the middle layer consists of ¡ nodes each connecting to node   , and the bottom layer consists of ¢¤£ ¥§¦ nodes each connecting to a distinct subset of ¨ nodes on the middle layer. We call this network an ¢ £ ¥ ¦ combination network, or simply an ¢¤£ ¥§¦ network, where ©¨¡ .\nAssume that a message consisting of  informa- tion symbols taken from a ﬁnite ﬁeld  is generated at the source node   , and each channel can transmit one symbol in  in the speciﬁed direction. A linear\nnetwork code on a given network is qualiﬁed as a linear multicast [7] if for all non-source node ! in the network, if\nthen node ! can decode the source message. Note that by the Max-ﬂow Min-cut theorem, (1) is a necessary condition for any node ! to be able to decode the source message. In [7], linear broadcast, linear dispersion, and generic linear network code are also deﬁned as linear network codes possess- ing stronger properties than linear multicast. These stronger linear network codes are useful for various applications.\nConsider a classical 3 ¡B@CD5 linear block code with minimum distance E and regard it as a linear network code on the ¢F£ £(GAHPIRQ ¦ network. Speciﬁcally, the code takes the source message as input and outputs ¡\noutgoing channels of node   . For each node on the middle layer, since there is only one input channel, we assume without loss of generality that the symbol received is replicated and transmitted on each outgoing channel.\nSince the 3 ¡B@C05 code has minimum distance E , by accessing a subset of ¡TSUEWV9© of the nodes on the middle layer (corresponding to EXSY© erasures), each node\non the bottom layer can decode the source message. From the foregoing, by the Max- ﬂow Min-cut theorem,\nwhich is precisely the Singleton bound for classical linear block code [1]. Thus the Singleton bound is a special case of the Max-ﬂow Min-cut theorem. Moreover, by (2), the non-source nodes in the net- work with maximum ﬂow at least equal to  are simply all the nodes on the bottom layer, and each of them can decode the source message. Hence, we conclude that an 3 ¡B@PD5 classical linear block code with minimum distance E is a  -dimensional linear multicast on the ¢ £ £(GAHPIRQ ¦ network.\nMore generally, an 3 ¡B@CD5 classical linear block code with minimum distance E is a  -dimensional linear multicast on the ¢ £ ¥§¦ network for all ¨r7\n. The proof is straightforward (we already have shown it for ¨4de¡BSuE(Vv© ). On the other hand, it is readily seen that a\n-dimensional linear multicast on the ¢ £ ¥ ¦ network, where\nA classical linear block code achieving tightness in the Singleton bound is called a maximum distance separation (MDS) code [1]. From the foregoing, the Singleton bound is a special case of the Max-ﬂow Min-cut theorem. Since a linear multicast, broadcast, or dispersion achieves tightness in the Max-ﬂow Min-cut theorem to different extents, they can all be regarded as network generalizations of an MDS code. The existence of MDS codes corresponds, in the more general paradigm of network coding, to the existence of linear multicasts and their stronger versions. This has been discussed in great detail in [7].\nInspired by network coding, network error- correcting codes has been introduced in [4] for multicasting a source message to a set of nodes on a network when the communication channels are not error-free. The usual approach in existing networks, namely link-by-link error correction, is a special case of network error correction. Network\ngeneralizations of the Hamming bound, the Sin- gleton bound, and the Gilbert-Varshamov bound in classical algebraic coding have been obtained. In particular, the tightness of the Singleton bound in the network setting is preserved, meaning that linear network codes are asymptotically optimal. We refer the reader to [8] [9] for the details.\nIn this section, we discuss an upper bound ob- tained in [8] which is given in terms of bounds de- ﬁned for classical error-correcting codes. By means of an example, we will show that this bound is not tight even for a simple class of networks called regular networks. This illustrates the com- plexity involved in the construction of network error-correcting codes.\nLet us ﬁrst describe the setup of network error correction. An acylic communication network is represented by a directed acyclic graph \u0083Ud 3\u0085\u0084 @\u0087\u0086\u00885 , where \u0084 is the node set and \u0086 is the channel set, in which multiple channels between a pair of nodes is allowed. On each channel, one symbol from a certain code alphabet \u0089 can be transmitted in the speciﬁed direction. A message taken from a source alphabet \u0090 is generated at the source node   , which is to be multicast to a set of sink nodes \u0091 . A network code on \u0083 is deﬁned in the usual way (see for example [8]), and for a network code \u0092 , the symbol transmitted on channel \u0093 when the message is \u0094 is\nDeﬁnition 1: A network code on \u0083 is \u0097 -error- correcting if it can correct all \u0098 -errors for \u0098\u0099d\u0097 , i.e., if the total number of errors in the network is at most \u0097 , then the source message can be recovered by all the sink nodes egfy\u0091 .\nSince \u0083 is acyclic, it naturally deﬁnes a partial order h on the channel set \u0086 . Two channels \u0093b@i\u0093kjlf\u0080\u0086 are said to be incompatible if neither \u0093mhi\u0093kj nor \u0093kjlh\n. A set of channels npoi\u0086 is called an antichain if the channels in n are pairwise incompatible.\nDeﬁnition 2: For a partition 3q @Crv5 of the node set \u0084 , s ec\u0097 3q @Crv5 is a regular cut if its members form an antichain, i.e., if \u0093\u0082@C\u0093kjXfts eu\u0097 3\u0085q @irv5 , then there exists no path either from \u0093 to \u0093kj or from \u0093kj to \u0093 .\nis the minimum volume of a regular cut between   and e .\nFor a \u0097 -error-correcting network code on a given network \u0083 , we are naturally interested in the max- imum possible value of  \u0090T , the size of the source alphabet. The following theorem renders an upper bound on\nTheorem 1: [8] Let \u0092 be a \u0097 -error-correcting code for an acyclic network \u0083 with source alphabet \u0090 and\ni) If s ec\u0097 3q @Crv5 is a regular cut between the source node   and a sink node e , then the set of all possible vectors transmitted across s\u0082ec\u0097 3q @ir5 , i.e.,\nform a classical \u0097 -error correcting code with alpha- bet \u0089 , and consequently ii)\nsize of an optimal classical \u0086 -ary \u0097 -error-correcting code of length ¡ and the size of an optimal classical linear \u0086 -ary \u0097 -error-correcting code of length ¡ , respectively.\nThe upper bound on  \u0090\u0080 rendered in the above theorem is in terms of bounds deﬁned for classical error-correcting codes. Since the errors occurring at the channels across any cut in a regular network do not interfere with each other (because the set of channels form an antichain), one may conjecture that this upper bound on \u0090 is generally tight for regular networks. The following example, however, shows the contrary.\nExample 1: Consider the network in Fig. 2 which is speciﬁed by\n, so it is regular. In light of the existence of a classical binary 1-error-correcting (3,1) code, if the bounds in Theorem 1 are tight, then there would exist a binary\n(4) where \u0092\u009f\u009e¡ C¢ £ ¤ denotes the encoding function of \u0092 for channel 3¤  @ \u008e 5 , etc, that multicasts a message from the binary source alphabet \u0090\u0088d \u0083~\u0095 @\u0093©h\u0085 .\nAssume that the network code \u0092 in (4) is 1- error-correcting. We will show that this leads to a contradiction. Without loss of generality, we let\nsince by symmetry one can exchange the roles of 0 and 1 componentwise. We observe that for a particular network code, a channel can be removed if its encoding function can only take one value because such a channel does not convey any infor- mation. For the network in Fig. 2, if the encoding function of any channel can take only one value, then by removing that channel from the network, we will ﬁnd a sink node such that the minimum cut between the source node and this sink node is reduced to 2. This contradicts Theorem 1 because of the nonexistence of a (2,1) code that can correct 1 error. This means that the encoding functions of all the channels must take two values. In particular, an encoding function of a channel whose input-nodes\nhas in-degree one must be a bijection, so we may assume with loss of generality that it is the identity function.\nwith the ﬁrst and the second arguments being the outputs of channels 3 \u008e @CEb5 and 3 s2@CEb5 , respectively. We will show that there is no way to choose the function\nsuch that the code is able to correct 1 error. First, without loss of generality, let\n(5) Let us consider the case that the source message is 1 and an error occurs at channel 3¤  @ \u008e 5 . It is easy to see that the outputs of channels 3 \u008e @CEb5 and 3 s2@CEb5 are 0 and 1, respectively, so that by (5), channel 3 E0@C\u009325\nif the source message is © and an error occurs at channel 3¤  @ \u008e 5 .\nNext, consider the case that the source message is \u0095 and an error occurs at channel 3¤  @C\u008f\u00825 . Then we must have\n(6) otherwise the outputs of the channels across the cut in (6) would again be 3 \u0095 @§©h@ \u0095 5 so that the sink node\ncannot distinguish the source messages 0 and 1. We now consider the cut\n(7) between   and eA\u008b . It is easy to verify that if\n, then the outputs of the channels across the cut in (7) is 3 \u0095 @§©h@ \u0095 5 if the source message is \u0095 and an error occurs at channel 3  @is§5 , or if the source message is © and an error occurs at channel\n(8) Now again consider the cut in (6). With (5), (6),\nis a classical 1-error-correcting code so that its minimum distance is at least 3, a contradiction to (9). Therefore, the assumption that the code in (4) is 1-error-correcting is incorrect, and we conclude that there exists no binary 1-error-correcting network code that can transmit 1 bit. This in turn shows that the upper bound in Theorem 1 is not tight.\nWe have clariﬁed the relation between network coding and algebraic coding. We have also have given an overview of network error correction, a paradigm for error correction on networks and an extension of classical point-to-point error correction, and discussed the complexity involved in the con- struction of network error correction codes.\nThe work of Raymond W. Yeung was partially supported by a grant from the Research Grant Council of the Hong Kong Special Administrative Region, China (RGC Ref. No. CUHK4214/03E)."},"refs":[{"authors":[{"name":"R. C. Singleton"}],"title":{"text":"Maximum distance Q-nary codes"}},{"authors":[{"name":"R. W. Yeung"},{"name":"Z. Zhang"}],"title":{"text":"Distributed source coding for satellite communications"}},{"authors":[{"name":"R. Ahlswede"},{"name":"N. Cai"},{"name":"S.-Y. R. Li"},{"name":"R. W. Yeung"}],"title":{"text":"Network information ﬂow"}},{"authors":[{"name":"N. Cai"},{"name":"R. W. Yeung"}],"title":{"text":"Network Coding and Error Correc- tion"}},{"authors":[{"name":"S.-Y. R. Li"},{"name":"R. W. Yeung"},{"name":"N. Cai"}],"title":{"text":"Linear network coding"}},{"authors":[{"name":"R. Koetter"},{"name":"M. M´edard"}],"title":{"text":"An algebraic approach to net- work coding"}},{"authors":[{"name":"R. W. Yeung"},{"name":"S.-Y. R. Li"},{"name":"N. Cai"},{"name":"Z. Zhang"}],"title":{"text":"Theory of network coding"}},{"authors":[{"name":"R. W. Yeung"},{"name":"N. Cai"}],"title":{"text":"Network error correc- tion, Part I: Basic concepts and upper bounds"}},{"authors":[{"name":"N. Cai"},{"name":"R. W. Yeung"}],"title":{"text":"Network error correction, Part II: Lower bounds"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/ita2013/263"},"links":[{"id":"205","weight":2},{"id":"2760","weight":3},{"id":"1486","weight":9},{"id":"3180","weight":3},{"id":"67","weight":10},{"id":"1606","weight":13},{"id":"153","weight":9},{"id":"3037","weight":4},{"id":"93","weight":13},{"id":"436","weight":6},{"id":"3191","weight":11},{"id":"12","weight":3},{"id":"223","weight":2},{"id":"1547","weight":7},{"id":"2254","weight":7},{"id":"2287","weight":5},{"id":"3200","weight":9},{"id":"3008","weight":5},{"id":"2217","weight":5},{"id":"3010","weight":7},{"id":"3222","weight":3},{"id":"2291","weight":8},{"id":"307","weight":11},{"id":"981","weight":6},{"id":"1430","weight":2},{"id":"3021","weight":3},{"id":"3199","weight":2},{"id":"813","weight":9},{"id":"3069","weight":7},{"id":"2634","weight":3},{"id":"2442","weight":8},{"id":"3183","weight":8},{"id":"175","weight":4},{"id":"362","weight":2},{"id":"2763","weight":16},{"id":"2534","weight":3},{"id":"1235","weight":2},{"id":"135","weight":10},{"id":"404","weight":9},{"id":"450","weight":5},{"id":"770","weight":5},{"id":"3165","weight":3},{"id":"1082","weight":3},{"id":"3182","weight":4},{"id":"1889","weight":3},{"id":"762","weight":5},{"id":"3154","weight":3},{"id":"3065","weight":4},{"id":"3195","weight":3},{"id":"284","weight":9},{"id":"3218","weight":6},{"id":"1060","weight":7},{"id":"3132","weight":20},{"id":"1160","weight":9},{"id":"3187","weight":7},{"id":"475","weight":8},{"id":"944","weight":5},{"id":"3137","weight":4},{"id":"3059","weight":4},{"id":"2646","weight":5},{"id":"90","weight":6},{"id":"236","weight":5},{"id":"117","weight":3},{"id":"1442","weight":2},{"id":"2745","weight":3},{"id":"2276","weight":4},{"id":"2352","weight":4},{"id":"3176","weight":3},{"id":"470","weight":8},{"id":"1643","weight":7},{"id":"3036","weight":2},{"id":"26","weight":8},{"id":"2455","weight":3},{"id":"1298","weight":14},{"id":"3175","weight":8},{"id":"3201","weight":2},{"id":"1268","weight":2},{"id":"2830","weight":7},{"id":"679","weight":4},{"id":"3135","weight":4},{"id":"123","weight":8},{"id":"1479","weight":3},{"id":"1215","weight":4},{"id":"107","weight":8},{"id":"217","weight":4},{"id":"1462","weight":2},{"id":"13","weight":4},{"id":"3038","weight":9},{"id":"1996","weight":6},{"id":"325","weight":5},{"id":"1458","weight":2},{"id":"2025","weight":2},{"id":"973","weight":10},{"id":"1279","weight":15},{"id":"2119","weight":8},{"id":"888","weight":4},{"id":"1436","weight":2},{"id":"459","weight":6},{"id":"155","weight":12},{"id":"1559","weight":2},{"id":"83","weight":2},{"id":"3072","weight":15},{"id":"306","weight":5},{"id":"1121","weight":2},{"id":"3057","weight":6},{"id":"3068","weight":8},{"id":"3164","weight":10},{"id":"2697","weight":4},{"id":"152","weight":5},{"id":"2750","weight":18},{"id":"1421","weight":7},{"id":"3105","weight":6},{"id":"2178","weight":10},{"id":"72","weight":3},{"id":"1866","weight":7},{"id":"3233","weight":2},{"id":"2488","weight":4},{"id":"3116","weight":3},{"id":"900","weight":4},{"id":"353","weight":6},{"id":"1074","weight":21},{"id":"1136","weight":6},{"id":"2751","weight":4},{"id":"1103","weight":6},{"id":"3157","weight":5},{"id":"2317","weight":6},{"id":"375","weight":2},{"id":"3127","weight":3},{"id":"572","weight":7},{"id":"76","weight":8},{"id":"419","weight":11},{"id":"372","weight":17},{"id":"138","weight":12},{"id":"3073","weight":4},{"id":"54","weight":7},{"id":"408","weight":4},{"id":"1696","weight":5},{"id":"1212","weight":8},{"id":"487","weight":2},{"id":"65","weight":7},{"id":"1096","weight":3},{"id":"71","weight":5},{"id":"642","weight":2},{"id":"3196","weight":14},{"id":"2033","weight":13},{"id":"1830","weight":13},{"id":"108","weight":3},{"id":"691","weight":8},{"id":"2740","weight":14},{"id":"3202","weight":14},{"id":"2812","weight":7},{"id":"3243","weight":9},{"id":"2188","weight":5},{"id":"3185","weight":7},{"id":"1671","weight":3},{"id":"1325","weight":5},{"id":"1844","weight":2},{"id":"2174","weight":9},{"id":"3001","weight":2},{"id":"1128","weight":3},{"id":"431","weight":4},{"id":"676","weight":4},{"id":"82","weight":8},{"id":"1448","weight":5},{"id":"3056","weight":7},{"id":"1","weight":3},{"id":"2996","weight":8},{"id":"2617","weight":8},{"id":"2435","weight":7},{"id":"3174","weight":3},{"id":"3051","weight":12},{"id":"1840","weight":27},{"id":"1988","weight":3},{"id":"1908","weight":4},{"id":"2884","weight":2},{"id":"771","weight":4},{"id":"3088","weight":2},{"id":"25","weight":8},{"id":"658","weight":3},{"id":"2743","weight":5},{"id":"687","weight":2},{"id":"230","weight":4},{"id":"3123","weight":2},{"id":"309","weight":18},{"id":"2177","weight":9},{"id":"2773","weight":4},{"id":"31","weight":10},{"id":"3071","weight":13},{"id":"503","weight":5},{"id":"1439","weight":8},{"id":"278","weight":10},{"id":"764","weight":5},{"id":"1444","weight":3},{"id":"887","weight":8},{"id":"95","weight":3},{"id":"1109","weight":6},{"id":"1438","weight":3},{"id":"264","weight":7},{"id":"257","weight":4},{"id":"694","weight":18},{"id":"203","weight":4},{"id":"1847","weight":7},{"id":"3205","weight":12},{"id":"75","weight":3},{"id":"3108","weight":11},{"id":"115","weight":12},{"id":"1822","weight":8},{"id":"376","weight":2},{"id":"723","weight":7},{"id":"308","weight":7},{"id":"2838","weight":7},{"id":"3197","weight":4},{"id":"293","weight":13},{"id":"767","weight":9},{"id":"354","weight":2},{"id":"326","weight":2},{"id":"2939","weight":7},{"id":"430","weight":22},{"id":"1915","weight":5},{"id":"1233","weight":6},{"id":"641","weight":5},{"id":"1905","weight":11},{"id":"3189","weight":16},{"id":"575","weight":11},{"id":"831","weight":3},{"id":"2862","weight":2},{"id":"402","weight":3},{"id":"371","weight":2},{"id":"2443","weight":6},{"id":"1084","weight":2},{"id":"423","weight":4},{"id":"2316","weight":2},{"id":"3156","weight":3},{"id":"1055","weight":7},{"id":"2173","weight":12},{"id":"2753","weight":2},{"id":"1517","weight":11},{"id":"198","weight":3},{"id":"1319","weight":13},{"id":"699","weight":3},{"id":"187","weight":3},{"id":"165","weight":5},{"id":"2255","weight":4},{"id":"1627","weight":2},{"id":"92","weight":10},{"id":"1528","weight":4},{"id":"705","weight":7},{"id":"621","weight":16},{"id":"3070","weight":6},{"id":"3181","weight":4},{"id":"1546","weight":3},{"id":"3198","weight":5},{"id":"2778","weight":8},{"id":"1098","weight":4},{"id":"1861","weight":12},{"id":"220","weight":6},{"id":"660","weight":5},{"id":"183","weight":2},{"id":"688","weight":5},{"id":"3169","weight":2},{"id":"982","weight":3},{"id":"359","weight":7},{"id":"1930","weight":5},{"id":"3173","weight":18},{"id":"288","weight":15},{"id":"3133","weight":4},{"id":"1553","weight":9},{"id":"3170","weight":5},{"id":"485","weight":6},{"id":"3193","weight":9},{"id":"2738","weight":2},{"id":"240","weight":27},{"id":"1166","weight":4},{"id":"1550","weight":3},{"id":"782","weight":2},{"id":"3125","weight":7},{"id":"2495","weight":6},{"id":"420","weight":2},{"id":"323","weight":2},{"id":"3136","weight":6},{"id":"74","weight":4},{"id":"1456","weight":3},{"id":"243","weight":9},{"id":"1231","weight":5},{"id":"1214","weight":2},{"id":"3114","weight":6},{"id":"1434","weight":3},{"id":"1871","weight":5},{"id":"3188","weight":3},{"id":"3177","weight":7},{"id":"3166","weight":7},{"id":"1187","weight":6},{"id":"449","weight":8},{"id":"377","weight":12},{"id":"424","weight":8},{"id":"229","weight":6},{"id":"2146","weight":5},{"id":"1680","weight":11},{"id":"3208","weight":5},{"id":"1402","weight":5},{"id":"2299","weight":2},{"id":"2309","weight":2},{"id":"1258","weight":12},{"id":"2288","weight":7},{"id":"2286","weight":19},{"id":"2038","weight":11},{"id":"2448","weight":12},{"id":"752","weight":7},{"id":"1393","weight":4},{"id":"1300","weight":7},{"id":"3162","weight":5}],"meta":{"jsonClass":"Map$Map3","room":"The Cocatoo","date":"1360600500000","session":"1"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
