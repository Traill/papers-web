{"id":"67","paper":{"title":{"text":"On rate-compatible non-binary protograph-based codes "},"authors":[{"name":"Dariush Divsalar"},{"name":"Lara Dolecek"},{"name":"Yizeng Sun"},{"name":"Tsung-Yi Chen"},{"name":"Richard Wesel"}],"abstr":{"text":"We investigate constructions of rate-compatible, finite-length, non-binary protograph-based codes in the short block-length regime. First, high rate codes are constructed by partitioning a high degree check node into several lower degree check nodes connected by punctured degree-2 nodes. This approach allows a construction of codes of lower rates by transmitting the punctured nodes, using replicated nodes, or using LT type graph structures with degree-1 nodes.  The resultant codes are structurally similar to the Raptor-like protograph codes extended to non-binary fields. Large girth, cycle cancellation method, and EXIT analysis are used to obtain codes with good performance. Performance of binary image of selected codes over AWGN is provided for short information block-lengths."},"body":{"text":"The standard multiple-access problem (see e.g. [3, p.388]) considers multiple transmitters, each with an independent data stream. Via interfering transmissions, these streams need to be communicated to a base station. The base station desires to reliably recover each of the data streams. This gives rise to the standard notion of the \u201ccapacity region\u201d of the multiple-access channel (MAC) (see e.g. [3, Thm.14.3.1]).\nA key question is whether this capacity region has the same universal signiﬁcance as the capacity of a point-to- point channel, in the sense that it represents the fundamental limit on communication performance. For example, consider the transmission of independent source streams with respect to (separate) distortion criteria, such as average bit error probability or mean-squared error. It is not hard to show (see e.g. [5, Thm.1.9]) that a \u201cseparation theorem\u201d applies, in the following sense: Communication satisfying the imposed ﬁdelity requirement is feasible if and only if the rate-distortion region for the source coding problem (subject to the same ﬁdelity requirement) intersects the capacity region of the MAC, implying that separately designed source and channel codes are sufﬁcient to attain optimum performance.\nHence, in this special problem, the capacity region does characterize the ultimate limit on communication performance. However, it is well known that for more general commu- nication problems, this does not apply. In this abstract, we discuss two facets of this fact, primarily via two examples. The ﬁrst example is well-known and concerns the situation where the underlying sources are dependent. In the second example, the sources are assumed to be independent, but we consider \u201cdependent criteria:\u201d Instead of separate recovery, the decoder is interested in a merged summary or function of the data streams (potentially subject to a ﬁdelity requirement). An example is the bit-wise modulo-2 sum of all the messages, which may be of interest to sensor networks and network coding.\nThe simplest example illustrating the issue of multiple access and dependent sources was given in [2], as follows: Consider two dependent binary sources, (S 1 , S 2 ), where (0, 1) never occurs and the other three possibilities are equally likely, and suppose that the base station is interested in the entire sequence of values that each source takes on. The MAC under study takes binary (0 or 1) inputs, and its output is their (real) sum (0, 1, or 2), without any noise. It is immediately clear that we can simply transmit the two sources without further coding, and always meet our goal. The more interesting question, however, is: can we also conclude this by looking at the capacity region of the channel?\nThe answer to this question is negative: The capacity region of this channel can be shown not to admit a sum rate that exceeds 1.5 bits per channel use, but the joint source entropy is log 2 3 ≈ 1.58 bits per source sample, more than what the MAC can support.\nOne way in which this has been interpreted is that there is a \u201cperformance gain\u201d for dependent sources on the multiple- access channels, where the gain is in comparison to a scheme in which the sources are ﬁrst optimally compressed in a distributed fashion [9], and the resulting messages are com- municated via a \u201cstandard\u201d multiple-access code [3, p.393].\nFurther treatments along these lines may be found, e.g., in [1], [4], [10].\nBy \u201cdependent criteria\u201d, we mean that the destination re- constructs a joint function of all the sources (possibly with respect to a ﬁdelity criterion).\nThe simplest example illustrating this can be phrased as fol- lows: Consider two independent binary (Bernoulli(p)) sources, S 1 and S 2 , and suppose that the base station is interested in the modulo-2 sum of these sources. The MAC under study takes binary inputs, and it outputs their modulo-2 sum, without any noise. It is immediately clear that we can simply transmit the two sources without further coding, and always meet our goal. The more interesting question, however, is: can we also conclude this by looking at the capacity region of the channel?\nThe answer to this question is negative: The capacity region of this channel can be shown not to admit a sum rate that exceeds 1 bit per channel use, but the rate required to compress the modulo-2 sum of two independent binary sources in a\ndistributed fashion is 2H b (p), where H b ( ·) denotes the binary entropy function (see [7]). When 0.11 < p < 0.89, this is more than what the MAC can support.\nOne way in which this can be interpreted is that there is a \u201cperformance gain\u201d for dependent criteria, where the gain is in comparison to a scheme in which the sources are ﬁrst optimally compressed in a distributed fashion with respect to the desired \u201cdependent criterion\u201d (in extension of [7]), and the resulting messages are communicated via a \u201cstandard\u201d multiple-access code [3, p.393].\nBy comparing the MAC with dependent sources and the MAC with dependent criteria, it may be tempting to suspect that the two effects are due to the same underlying structural property. The resulting duality could be one under which a given dependence structure between the sources (subject to separate recovery of each source) would be equivalent to an appropriately chosen \u201cdependent criterion\u201d (for independent sources).\nSuch a duality can be established at least for a limited class of multiple access problems. Consider the multiple access structure sketched in Figure 1. Denote the source sequences by {S m,i } i>0 , for m = 1, . . . , M , and let S i = (S 1,i , . . . , S M,i ) and S n = (S 1 , . . . , S n ). We assume that S n is a sequence of independent and identically distributed random vectors, according to a ﬁxed distribution p(s). Suppose that the source sequences need to be reconstructed with respect to a ﬁdelity criterion of the form\nWe consider block encoders f 1 , f 2 , . . . , f M that each map k source symbols onto n channel input symbols, and the block decoder g that maps n channel output symbols onto the reconstruction sequences. The MAC is assumed to be memoryless and characterized by a conditional distribution p Y |X . We deﬁne the input constraint over a block of n channel inputs as\nHence, from this particular (and somewhat limited) perspec- tive, a multiple access problem is characterized by the source distribution p(s) with the corresponding distortion measure d as well as the channel conditional distribution p(y |x) with the corresponding cost function ρ.\nThe following theorem provides a sufﬁcient condition under which a code (f 1 , . . . , f M , g) is optimal for a multiple access problem. Note, however, that the condition is by no means necessary.\nd(s k , ˆ s k ) = −c 0 (log 2 p(ˆ s k |s k ) − log 2 p(ˆ s k )) + d 0 (s k ) (3) ρ(x n ) = c 1 D(p Y n |X n ( ·|x n ) ||p Y n ( ·)) + ρ 0 , \t (4)\nwhere c 0 > 0, c 1 > 0, ρ 0 is an arbitrary constant, and d 0 (s k ) an arbitrary function of s k , then it is an optimal code for the multiple access problem.\nThis theorem follows directly from the results in [5]. It can also rather straightforwardly be extended to the case of multiple cost and/or distortion constraints.\nTo interpret the theorem, note that a ﬁxed code will be optimal for a number of multiple access problems, according to the dependence structure of the source. For each such structure (characterized by p(s)), a different distortion measure will be imposed, according to Equation (3) in the above theorem. Generally, the resulting distortion measure will be a \u201cdependent criterion,\u201d i.e., it will not be possible to split it into separate ﬁdelity criteria for each source. In this sense, one may identify a duality between dependence and distortion measure.\nA separate (and perhaps more interesting) question is that of gains over separately designed source and channel codes. Here, one may initially suspect that gains due to dependent sources are possible if and only if they are also possible due to dependent criteria. This, however, does not apply, as can be veriﬁed easily by reconsidering the example presented in Section II-B.\nSpeciﬁcally, reconsider the MAC that takes binary inputs and whose output is their modulo-2 sum, without any noise. For this channel, it is easy to show that a separation theo- rem applies whenever the sources need to be reconstructed separately: Consider two dependent binary sources with joint entropy H(S 1 , S 2 ). Then, from the data processing inequality, we infer that (denoting, as in Section III-A, the channel inputs by X 1 and X 2 , and its output by Y )\nwhere the last inequality follows since Y is binary. Hence, we can see that S 1 and S 2 can only be recovered if their joint entropy is no larger than one. However, in this case, separately designed source and channel codes will work, too. Hence, in this example, dependent messages do not enable any gains. By contrast, as explained in Section II-B, there is a gain for dependent criteria.\nThis argument straightforwardly extends to larger alphabets, and similar insights apply for the Gaussian MAC (as deﬁned in [3, p.378]) but under a constraint on the received power, see [6].\nThe most interesting perspective on the insights developed in this paper is that in the multiple access problem where the decoder is only interested in a \u201csummary\u201d of the original source data, joint source-channel coding techniques result in a gain over separately designed source and channel codes. However, the coding techniques that permit to harvest this gain are signiﬁcantly different from the codes that exploit dependent messages, such as developed in [2]. Speciﬁcally, the gains enabled by dependent criteria hinge on a structural similarity between the multiple-access channel at hand and the desired criterion, which can be thought of as \u201ccomputing a function\u201d of the original source information. Therefore, these gains typically cannot be harvested via generic random codes, but require structured codes. An initial study appears in [8].\nStimulating discussions with Bobak Nazer (Berkeley) are gratefully acknowledged. The material in this paper was supported in part by the National Science Foundation under award CCF-0347298 (CAREER)."},"refs":[{"authors":[{"name":"R. Ahlswed"},{"name":"T. S. Han"}],"title":{"text":"On source coding with side information via a multiple-access channel and related problems in multi-user information theory"}},{"authors":[{"name":"T. M. Cove"},{"name":"A. A. El Gama"},{"name":"M. Salehi"}],"title":{"text":"Multiple access channels with arbitrarily correlated sources"}},{"authors":[{"name":"T. M. Cove"},{"name":"J. A. Thomas"}],"title":{"text":"Elements of Information Theory"}},{"authors":[{"name":"G. Dueck"}],"title":{"text":"A note on the multiple access channel with correlated sources"}},{"authors":[{"name":"M. Gastpar"}],"title":{"text":"To Code Or Not To Code"}},{"authors":[{"name":"M. Gastpar"}],"title":{"text":"Gaussian multiple access channels under received-power constraints"}},{"authors":[{"name":"J. K¨orne"},{"name":"K. Marton"}],"title":{"text":"How to encode the modulo-two sum of binary sources"}},{"authors":[{"name":"B. Naze"},{"name":"M. Gastpar"}],"title":{"text":"Reliable computation over multiple access channels"}},{"authors":[{"name":"D. Slepia"},{"name":"J. K. Wolf"}],"title":{"text":"Noiseless coding of correlated information sources"}},{"authors":[{"name":"F. M. J. Willems"}],"title":{"text":"Informationtheoretical Results for The Discrete Mem- oryless Multiple Access Channel"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/ita2013/67"},"links":[{"id":"205","weight":6},{"id":"2760","weight":27},{"id":"1486","weight":3},{"id":"2741","weight":17},{"id":"3180","weight":3},{"id":"2206","weight":2},{"id":"1606","weight":7},{"id":"153","weight":3},{"id":"3037","weight":10},{"id":"93","weight":8},{"id":"436","weight":2},{"id":"3191","weight":13},{"id":"12","weight":6},{"id":"223","weight":2},{"id":"1278","weight":8},{"id":"2287","weight":9},{"id":"3200","weight":17},{"id":"3008","weight":9},{"id":"2217","weight":4},{"id":"3010","weight":4},{"id":"3222","weight":11},{"id":"2291","weight":8},{"id":"307","weight":5},{"id":"981","weight":3},{"id":"1430","weight":3},{"id":"3021","weight":2},{"id":"170","weight":5},{"id":"3199","weight":4},{"id":"813","weight":4},{"id":"3069","weight":6},{"id":"2634","weight":4},{"id":"526","weight":4},{"id":"2442","weight":11},{"id":"3183","weight":32},{"id":"175","weight":4},{"id":"362","weight":5},{"id":"2763","weight":17},{"id":"2534","weight":3},{"id":"1235","weight":10},{"id":"135","weight":8},{"id":"404","weight":14},{"id":"702","weight":4},{"id":"450","weight":6},{"id":"770","weight":23},{"id":"3165","weight":2},{"id":"1082","weight":11},{"id":"3182","weight":3},{"id":"1889","weight":9},{"id":"762","weight":5},{"id":"3154","weight":3},{"id":"2002","weight":2},{"id":"3065","weight":22},{"id":"3195","weight":5},{"id":"284","weight":4},{"id":"1060","weight":10},{"id":"3132","weight":10},{"id":"1160","weight":11},{"id":"3187","weight":25},{"id":"475","weight":3},{"id":"944","weight":3},{"id":"3137","weight":2},{"id":"3059","weight":7},{"id":"2646","weight":3},{"id":"104","weight":4},{"id":"90","weight":4},{"id":"236","weight":3},{"id":"33","weight":2},{"id":"117","weight":6},{"id":"273","weight":20},{"id":"3111","weight":5},{"id":"2330","weight":6},{"id":"2745","weight":3},{"id":"2276","weight":15},{"id":"2352","weight":6},{"id":"3176","weight":4},{"id":"3255","weight":3},{"id":"470","weight":2},{"id":"1643","weight":27},{"id":"250","weight":4},{"id":"3036","weight":3},{"id":"163","weight":12},{"id":"26","weight":7},{"id":"1298","weight":16},{"id":"3175","weight":8},{"id":"3201","weight":3},{"id":"1268","weight":2},{"id":"2830","weight":8},{"id":"679","weight":15},{"id":"3135","weight":6},{"id":"3049","weight":14},{"id":"1479","weight":7},{"id":"1215","weight":11},{"id":"1223","weight":9},{"id":"107","weight":10},{"id":"1473","weight":2},{"id":"217","weight":6},{"id":"1462","weight":7},{"id":"13","weight":7},{"id":"3038","weight":3},{"id":"1996","weight":5},{"id":"1458","weight":6},{"id":"2025","weight":2},{"id":"973","weight":8},{"id":"1279","weight":13},{"id":"1436","weight":5},{"id":"459","weight":5},{"id":"155","weight":10},{"id":"1877","weight":8},{"id":"83","weight":15},{"id":"3186","weight":4},{"id":"3072","weight":5},{"id":"306","weight":24},{"id":"1121","weight":9},{"id":"3057","weight":4},{"id":"3068","weight":4},{"id":"3164","weight":4},{"id":"1107","weight":4},{"id":"2697","weight":4},{"id":"398","weight":3},{"id":"152","weight":8},{"id":"2750","weight":9},{"id":"1421","weight":7},{"id":"3105","weight":5},{"id":"72","weight":3},{"id":"1866","weight":25},{"id":"3233","weight":7},{"id":"2488","weight":5},{"id":"3116","weight":23},{"id":"900","weight":7},{"id":"59","weight":2},{"id":"353","weight":8},{"id":"1846","weight":7},{"id":"1074","weight":9},{"id":"1081","weight":3},{"id":"3168","weight":12},{"id":"263","weight":10},{"id":"1136","weight":5},{"id":"2751","weight":3},{"id":"1103","weight":2},{"id":"3157","weight":9},{"id":"2317","weight":39},{"id":"375","weight":3},{"id":"572","weight":5},{"id":"76","weight":9},{"id":"419","weight":8},{"id":"372","weight":7},{"id":"138","weight":27},{"id":"3073","weight":16},{"id":"54","weight":32},{"id":"1660","weight":4},{"id":"408","weight":2},{"id":"3005","weight":6},{"id":"3016","weight":7},{"id":"1212","weight":4},{"id":"2324","weight":2},{"id":"487","weight":6},{"id":"65","weight":7},{"id":"3027","weight":3},{"id":"71","weight":29},{"id":"642","weight":4},{"id":"3196","weight":8},{"id":"2033","weight":5},{"id":"1830","weight":10},{"id":"108","weight":8},{"id":"202","weight":2},{"id":"691","weight":11},{"id":"2740","weight":3},{"id":"1443","weight":4},{"id":"3202","weight":2},{"id":"3243","weight":2},{"id":"3134","weight":9},{"id":"445","weight":5},{"id":"3185","weight":4},{"id":"1671","weight":2},{"id":"1325","weight":5},{"id":"1844","weight":8},{"id":"2174","weight":4},{"id":"3001","weight":2},{"id":"431","weight":4},{"id":"676","weight":6},{"id":"82","weight":4},{"id":"1376","weight":4},{"id":"1448","weight":11},{"id":"3056","weight":5},{"id":"1","weight":12},{"id":"2996","weight":12},{"id":"2617","weight":7},{"id":"2435","weight":28},{"id":"3174","weight":5},{"id":"3051","weight":9},{"id":"1840","weight":18},{"id":"1988","weight":7},{"id":"1908","weight":8},{"id":"2884","weight":3},{"id":"771","weight":21},{"id":"3088","weight":8},{"id":"221","weight":8},{"id":"25","weight":3},{"id":"658","weight":2},{"id":"2743","weight":6},{"id":"687","weight":4},{"id":"230","weight":9},{"id":"3123","weight":5},{"id":"309","weight":4},{"id":"31","weight":16},{"id":"3071","weight":8},{"id":"503","weight":5},{"id":"3163","weight":2},{"id":"1439","weight":8},{"id":"278","weight":18},{"id":"764","weight":3},{"id":"3113","weight":6},{"id":"1444","weight":14},{"id":"151","weight":17},{"id":"887","weight":4},{"id":"95","weight":3},{"id":"1109","weight":2},{"id":"1438","weight":2},{"id":"184","weight":2},{"id":"264","weight":7},{"id":"257","weight":2},{"id":"694","weight":11},{"id":"1573","weight":11},{"id":"203","weight":8},{"id":"525","weight":2},{"id":"1847","weight":21},{"id":"3205","weight":14},{"id":"1509","weight":8},{"id":"1836","weight":2},{"id":"3167","weight":4},{"id":"115","weight":8},{"id":"1822","weight":4},{"id":"275","weight":23},{"id":"376","weight":5},{"id":"723","weight":3},{"id":"308","weight":7},{"id":"2838","weight":9},{"id":"3197","weight":15},{"id":"293","weight":19},{"id":"630","weight":12},{"id":"767","weight":5},{"id":"326","weight":2},{"id":"2939","weight":5},{"id":"1076","weight":3},{"id":"430","weight":7},{"id":"1915","weight":17},{"id":"1233","weight":4},{"id":"641","weight":7},{"id":"1905","weight":5},{"id":"3189","weight":4},{"id":"575","weight":3},{"id":"831","weight":3},{"id":"2862","weight":8},{"id":"402","weight":6},{"id":"371","weight":7},{"id":"2443","weight":7},{"id":"1084","weight":6},{"id":"2729","weight":12},{"id":"3156","weight":2},{"id":"1883","weight":4},{"id":"3074","weight":6},{"id":"1055","weight":2},{"id":"1102","weight":3},{"id":"2173","weight":9},{"id":"2753","weight":2},{"id":"1517","weight":7},{"id":"198","weight":14},{"id":"1319","weight":6},{"id":"699","weight":8},{"id":"506","weight":4},{"id":"187","weight":7},{"id":"165","weight":4},{"id":"2255","weight":5},{"id":"1627","weight":5},{"id":"92","weight":11},{"id":"705","weight":4},{"id":"621","weight":11},{"id":"3070","weight":54},{"id":"1503","weight":4},{"id":"261","weight":2},{"id":"3181","weight":8},{"id":"1546","weight":9},{"id":"3198","weight":2},{"id":"2778","weight":4},{"id":"1098","weight":4},{"id":"220","weight":4},{"id":"660","weight":5},{"id":"183","weight":23},{"id":"688","weight":5},{"id":"3169","weight":11},{"id":"982","weight":9},{"id":"359","weight":5},{"id":"3173","weight":16},{"id":"288","weight":23},{"id":"3133","weight":5},{"id":"1553","weight":5},{"id":"1116","weight":2},{"id":"3044","weight":7},{"id":"3170","weight":6},{"id":"485","weight":12},{"id":"3193","weight":10},{"id":"240","weight":9},{"id":"1166","weight":9},{"id":"1550","weight":6},{"id":"211","weight":3},{"id":"782","weight":5},{"id":"3125","weight":5},{"id":"2495","weight":18},{"id":"420","weight":5},{"id":"323","weight":6},{"id":"3136","weight":6},{"id":"74","weight":4},{"id":"1456","weight":5},{"id":"243","weight":24},{"id":"1231","weight":19},{"id":"1214","weight":4},{"id":"1083","weight":16},{"id":"3114","weight":4},{"id":"1871","weight":4},{"id":"3188","weight":4},{"id":"3177","weight":7},{"id":"3166","weight":8},{"id":"1187","weight":13},{"id":"449","weight":4},{"id":"377","weight":6},{"id":"424","weight":2},{"id":"3151","weight":8},{"id":"229","weight":5},{"id":"2146","weight":8},{"id":"2638","weight":6},{"id":"2315","weight":4},{"id":"1680","weight":6},{"id":"3208","weight":14},{"id":"370","weight":3},{"id":"1402","weight":9},{"id":"2299","weight":11},{"id":"2309","weight":4},{"id":"1258","weight":12},{"id":"2288","weight":6},{"id":"2286","weight":7},{"id":"2038","weight":11},{"id":"2448","weight":5},{"id":"752","weight":8},{"id":"1393","weight":3},{"id":"1300","weight":4},{"id":"1714","weight":8},{"id":"3162","weight":10}],"meta":{"jsonClass":"Map$Map3","room":"The Mackaw","date":"1360580400000","session":"2"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
