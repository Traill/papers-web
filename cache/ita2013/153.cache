{"id":"153","paper":{"title":{"text":"Signal processing with factor graphs: beamforming and Hilbert transform "},"authors":[{"name":"Christoph Reller"},{"name":"Hans-Andrea Loeliger"}],"abstr":{"text":"Continuous-time linear state space models with discrete-time observations enable digital estimation of continuous-time signals with arbitrary temporal resolution by means of Kalman filtering/smoothing or Gaussian message passing in the corresponding factor graph. In this paper, we demonstrate the application of this approach to time-domain sensor array processing and to the Hilbert transform of a signal observed in noise."},"body":{"text":"Many users connect to the internet through asymmetric links, in which the upload capacities are much smaller than download capacities. Internet service Providers (ISPs) employ this asymmetric design based on the premise that casual internet use mostly involves downloading from a relatively small number of content providers.\nRecently the \u2018mostly download\u2019 proﬁle of users has started to change. Users now commonly have access to devices like digital video cameras, high resolution scanners, and high capacity sound recorders that capture large volumes of digital data. This change in users\u2019 access proﬁle makes upload speed a bottleneck for typical remote access. Thus, if a user remotely accesses data stored on a home computer, such as a song or video, his access rate is limited by both his home\u2019s upload capacity and his remote location\u2019s download capacity.\nThis work attempts to correct for such channel asymme- tries by ﬁlling a high bandwidth download pipe through the aggregation of multiple idle lower bandwidth upload pipes. Our proposed approach has the following features:\n\u2022 Fairness Unallocated bandwidth is re-distributed in proportion to the bandwidth contributed by system peers.\n\u2022 Incentive There is a natural incentive for peers to participate and cooperate with others in the system.\n\u2022 Distributed operation Only local information is needed (i.e. no control information needs to be exchanged).\nIn addition, it is not too difﬁcult to add security to the model. In effect, our approach permits users to bypass the \u2018band-\nwidth: use it or lose it\u2019 service model offered by commercial ISPs, and instead maintain \u2018credit\u2019 for their contributions within the system as a whole. With hard-disk storage costing under a dollar per gigabyte, the beneﬁts enumerated above quickly surpass the cost of caching other users\u2019 data.\nThe rest of this paper is organized as follows. In Section II we mention some of the related work in the ﬁeld and contrast it with our approach. Thereafter, we formally introduce the details of our proposed bandwidth sharing method in Sec- tion III. In Section IV we analytically prove the fairness of our system and show that it provides a natural incentive for peer contributions. We simulate various aspects of our system in Section V to demonstrate its features, including speciﬁc cases where malicious peers attempt to take unfair advantage of the system. We also demonstrate the real-time efﬁciency of random linear coding for this application. Finally Section VI concludes our results and suggests directions for future work.\nPeer-to-peer (P2P) systems are typically used to distribute content on the Internet, and it is estimated that a major portion of the bandwidth available on consumer ISP networks carries P2P content [13]. P2P services make scalable content distribution possible by utilizing peers\u2019 upload bandwidth to service other peers\u2019 download requests. It has been shown through analysis [7, 14\u201316], simulations and measurements [4, 8, 17] that the P2P content delivery model scales gracefully with user demands for heterogeneous P2P networks. In the remainder of this section we describe some of the literature that is relevant to the different aspects of our proposed system, ending with a brief explanation of the novelty of our approach.\na) Content distribution: Services like BitTorrent [11] assume some out-of-band mechanisms to locate content for users to download. In particular, BitTorrent content location information is published through web sites. Various distributed hash table (DHT) based mechanisms such as Tapestry [9] have been developed to provide the important functionality of locating shared content on P2P networks. Much recent work in P2P networks concentrates on mitigating non-cooperative behavior of peers by adding incentive schemes. Due to the\nscalability issues, most of these schemes are distributed, and require only local information readily available to each peer. As with our scheme, the most common schemes are based on Barter economy where peers offer their bandwidth to others according to the amount of bandwidth allocated to them [18, 19]. Although adding incentive scheme may increase the cooperation among reasonable users, namely users which try to optimize their resources, it usually has no guarantee against malicious peers, and additional measures are required to reduce their effect on the network.\nThe idea of sharing disk-space for data backup and down- loads is not new. For example, the Folder-share system [10] lets users share their documents with other users. In this system, however, users only download a ﬁle from one peer, thus limiting their download speed to the upload speed of the peer. In addition the system assumes that peers do not cheat others when it comes to offering bandwidth.\nb) Coding: The Oceanstore project [12], provides a large data storage solution using erasure codes. Erasure code type approaches such as digital fountain [3] have been proposed for large scale content distribution. Random linear coding [2, 5] has been used for achieving a network coding [1] min-cut bound on multicast in networks. The authors in [5] proposed random linear coding as a way to avoid the \u201ccoupon collector\u2019s problem\u201d in a P2P storage system. Their application considers the case when parts of the same ﬁle are encoded and kept on separate hosts and rebuilt. While our system can also operate in this fragmented storage mode, the emphasis is on fairness and the ability to beat the upload link bottleneck.\nc) Analysis: Much of the work on P2P systems char- acterizes fairness and incentives for peers to cooperate by simulations, measurements and experiments of P2P systems rather than actual analysis, probably because of the com- plexities arising from the size, chaotic nature and heteroge- neous conditions that characterize real systems (e.g. [18, 19]). Nevertheless, there has been some recent queuing theoretic analytical work [16] that uses a queuing based approach to study the scalability and resilience to freeloaders in P2P systems. A game theoretic approach was also applied to a related problem, the problem of parallel downloading, i.e., downloading a large ﬁle from several servers in parallel. In [20] this problem is analyzed using non-cooperative game theoretic tools. However, this approach cannot capture the effects of malicious users.\nUnlike many existing P2P systems that are built for discov- ering and disseminating popular content, our system attempts to share unused bandwidth among system subscribers. Users who contribute bandwidth to the system are rewarded with higher instantaneous bandwidth availability when they need it. In all cases, users are (asymptotically) assured that bandwidth they share with the network will be returned to them.\nOur system also differs from typical P2P systems in that it is used by remote users, thus differentiating between users and network peers. More precisely, when a user u wishes to access\nher content (which has been distributed among the network peers off-line), she downloads content from multiple peers in the network, (possibly) including her own home computer. This subtle difference means that our system no longer needs the \u2018non-dominant\u2019 condition in [14, 15], i.e., that the upload capacity of one peer is necessarily smaller than the sum of upload capacities of all other peers. This, in turn, means that our system does not require a symmetric instantaneous \u2018tit-for-tat\u2019 requirement to guarantee fairness (i.e., the system intrinsically evens out contributions asymptotically).\nWe now describe some algorithmic details of our system. Throughout this description we assume that each user corre- sponds to one peer on the network (e.g., his home computer).\nOur system is initialized with each peer disseminating its data among other peers using a random linear coding approach motivated by the work in [5] (which applies coding to P2P storage applications). For the purposes of our analysis, we assume that each peer has an inﬁnite amount of disk space so that there is no utility cost for caching another peer\u2019s data.\nMore precisely, consider a long ﬁle X consisting of b bits to be disseminated in an n-peer network.In the standard random linear coding approach, X is split into k chunks {X 1 , X 2 , . . . , X k } with each chunk mathematically repre- sented as an m-element vector with components in a ﬁnite ﬁeld F q of size q = 2 p for some p, i.e., X j ∈ F m 2 p with mpk = b. This formulation effectively translates ﬁle X into k vector chunks. These vectors are coded into nk message vectors {Y 1 , Y 2 , . . . , Y nk } whose i-th component Y i is\nwhere each β ij ∈ F q is randomly chosen. By choosing β\u2019s randomly, we insure that β i = [β ij , j = 1 . . . k] are almost surely linearly independent [6].\nOur encoding is similar to the encoding proposed in [2] for network coding-based multicast [1], with two important tech- nical differences: (1) rather than transmitting β\u2019s as message headers, we use them as a secret key; (2) rather than having peers transferring linear combinations of their information to others on the network, peers transmit exactly what was uploaded to their storage area. The ﬁrst difference guarantees that no peer can decode a message stored on its system unless it correctly guesses the k-tuple β i (and knows that the guess is correct). The second difference ensures that peers do not need to perform any computation when messages are requested from them; they simply forward what they have stored.\nTo complete the initialization phase, each plain text message-id i is appended to the Y i \u2019s of Equation ( 1) and these encoded messages are then uploaded to the n participating peers (up to k messages per peer) where they are stored.\nTo decode a ﬁle, a user requests a total of k messages (i.e., Y i \u2019s) from multiple peers, preferably in parallel, and multiplies this by the inverse of the appropriate square sub-matrix of the coefﬁcient matrix β = [β ij ]. The rows of the coefﬁcient sub- matrix are determined from the message-id\u2019s appended to each of the k received messages Y i (as in Section III-A).\nIn this section we introduce a technical analysis of our system. In particular we focus on the incentive and fairness aspects for peers comprising the network. A user has an incentive to join the system since he is guaranteed to receive on the average at least the amount of bandwidth he would get if he had operated with his corresponding peer in isolation, potentially reaching higher average and instantaneous band- widths. A user has incentive to cooperate since the amount of additional allocated bandwidth it receives from the system is proportional to the amount of bandwidth it allocates to the network. We will further argue that the system is resilient to adversarial users, that is, the incentive remains for any strategy adopted by one or several users. We will also show that the system is fair in the sense that the users are allocated with free bandwidth according to how much bandwidth they share with the network (relative to others).\nOur formal model considers n peers sharing their upload bandwidths in a time-slotted fashion. As indicated in previous sections, we will refer to the remote owner of a peer, say peer i, as user i. We denote the individual upload bandwidth of peer i with µ i , and assume a random demand pattern for each user. Speciﬁcally, we assume that user i requests bandwidth for download at time-slot t with probability γ i , independently of other users and of the history of the system at slot t. Let I i (t) be the binary random variable that is 1 if and only if user i requests bandwidth at time t. The independence assumption above implies that the variables I i = (I i (t) : t ≥ 0) are i.i.d. with P r (I i (t) = 1) = γ i , and that the sequences (I i : i = 1, 2, · · · , n) are independent.\nNote that if user i operates in isolation and downloads only from its own peer, then its download speed is limited by µ i per request, which corresponds to an average capacity utilization of µ i γ i per time slot in the long term. We next introduce our bandwidth allocation scheme and study its properties in the next subsections. Towards this end, let µ ij (t) denote the upload bandwidth that peer i devotes to user j at slot t. This non-negative quantity is non-zero only if I j (t) = 1, that is, user j has a request at that time. The proposed bandwidth allocation scheme is given by\nwith some arbitrary small positive initial values for µ ji (0). Note that the proposed scheme relies only on local measure-\nments at each peer, and it does not require any transfer of information among the peers or users, which is prone to attack.\nAs a motivation, we ﬁrst consider a different allocation scheme, which is similar to the global proportional fairness scheme of [14]. In this scheme the bandwidth allocated to peer i is proportional to his contribution among all actively requesting peers at that time. Although it can be shown to be asymptotically pairwise fair in the number of peers, i.e., µ ij (t)γ i ≈ µ ji (t)γ j , it has major drawbacks, primarily be- cause it gives incentive to peers to lie about their contribution. The problem could be mitigated through accurate measure- ment of peer contributions, but not without implementational difﬁculties and allowing secondary attacks. This leads to the proposed allocation rule of (2), which is studied hereafter.\nLet µ ij (t) denote the time-average of the bandwidth that user j receives from peer i by time t. That is, µ ij (t) = t −1 t −1 k=0 µ ij (k). The random sequence ({µ ij (t), µ ij (t), i, j = 1, 2, · · · , n} : t ≥ 1) is Markovian. Let us assume without rigorous justiﬁcation that this chain is ergodic; in particular that µ ij (t) converges to the equilibrium expectation of µ ij (t). Let µ ij denote the limit and deﬁne µ j = n i=1 µ ij . Recall that an average upload bandwidth of peer i operating in isolation is γ i µ i , and the unallocated or free average bandwidth is (1 − γ i )µ i .\nTheorem 1 Allocation rule (2) guarantees that, asymptoti- cally, the average download bandwidth of user i is not only its average bandwidth in isolation, but also fractional portions of the free bandwidth of other users in the network. That is,\nwhere the fractional portions are proportional to the amount of the bandwidth user i shares with the network, i.e.,\nIn this form the denominator and numerator are independent; taking the expectation and applying Jensen\u2019s inequality gives\nTheorem 1 provides two important features of the network. First it shows that each user has an incentive to share its corresponding peer\u2019s bandwidth. The larger the bandwidth he shares relative to the amount others share - the larger the portion of free bandwidth that he receives. This can also be interpreted in terms of fairness, i.e., . someone who has a larger portion in the upload bandwidth of user i will beneﬁt from a larger portion of the free bandwidth of this user.\nThe second feature of the network, is the incentive to join the network. Theorem 1 guarantees that all users receive at least the amount of bandwidth that they would have received if they hadn\u2019t joint the network. Note that this guarantee for a speciﬁc user, say user i, holds under the mere assumption that this user requests downloads independently of the remaining users. Consider, for example, the case where other users form a coalition in order to manipulate the bandwidth of peer i. No matter what strategy they use, the guarantee of Theorem 1 implies that another user can only gain by joining the network.\nIt can be further shown that in a stationary regime when all peers are saturated with upload requests, a strong pair-wise fairness holds.\nCorollary 1 In the saturated regime, when γ i → 1 ∀i, the network of allocation (2) guarantees pair-wise fairness, i.e\nA similar result in [15] requires the non-dominant condition that we do not. Note also that the peer-wise fairness property does not hold in general. Individual users can enjoy other peer\u2019s free upload bandwidth to increase their total average upload bandwidth even beyond their own single peer-user isolated bandwidth.\nIn Section V-A we demonstrate the fairness and incen- tive results of Section IV. We implemented a discrete time simulator of the p2p system described in Section III for the purposes of conﬁrming the claims made in this paper. Each peer reallocated their upload bandwidths once per second, and our graphs were smoothed with a running average of 10 seconds. In another set of experiments (Section V-B), we show the efﬁciency of random linear coding.\nIn our ﬁrst experiment, ten users request large ﬁles at the same time, but their corresponding peers have different upload capacities ranging from 100kbps to 1000kbps. The download rate provided by the system is plotted in Figure 1 as a function of time. We can see that system initially goes through a period where bandwidth allocation among peers looks random, but that it quickly converges to rates that are commensurate with the upload capacities of the various peers.\nOur next graph (Figure 2) demonstrates the beneﬁts of the proposed system to all collaborating peers commensurate with Theorem 1. For these graphs, we simulated a three peer network comprising users that have encoded and distributed home videos to all three peers. The users stream their videos to a remote computer for 12 randomly chosen hours in a day (meaning they request bandwidth from the shared pool of upload bandwidth during these intervals).\nPeers 2 and 3 are available to upload to other peers all through a 24 hour period but peer 1 only starts to contribute to the system after the ﬁrst three hours. Two interesting artifacts occur: ﬁrst, we notice that user 1 is still able to get some service from the network in the ﬁrst hour because user 2 has not yet requested anything from the network and so peer 2 is splitting its bandwidth between users 0 and 1, being oblivious to peer 1 not contributing (this is corrected in the 2-3 hour time slot). In the 3-4-hour time slot, user 1 is penalized for his non-contribution to the system, though this penalty decays by time t = 4 hours as all users start beneﬁting from the contributed bandwidth.\nWe next demonstrate the efﬁciency of the random linear coding component of our system (and the corresponding de- coding complexity). In order to establish the speed of random\nlinear coding and infer the maximum throughput when the bottleneck is the decoding computation on the user\u2019s computer, we have built a simple encoder/decoder and tested it on 1MB of data for various values of message size m, ﬁnite ﬁeld size q and corresponding number of messages k into which the 1MB of data is split and encoded according to Equation (1). We believe that this study will also aid in making design decisions in related applications such as network coding based multicast.\nOur experiments were performed on a Pentium 4 dual processor workstation running the Linux operating system, although the code only ran on one processor. The encoding and decoding operations are essentially the same, the latter using the inverse of the coefﬁcient matrix in Equation (1), so we only consider decoding times in our results.\nFrom Table I it is apparent that lower values of k (i.e., the number of chunks into which the ﬁle is split) yield faster decoding. The data further conﬁrms that it makes sense to use larger ﬁeld sizes to further reduce k, even with the additional overhead of more expensive ﬁeld operations, although reducing k indiscriminately would be problematic in maintaining fairness due to quantization errors. As a speciﬁc example, a 1MB ﬁle chunks represented as m = 32, 768- element vectors over q = GF (2 32 ) can be decoded in one second (i.e., a decoding rate of 1MB/s). At this speed, the ISP- offered download rate is more likely to be a bottleneck than the computations or upload capacities of the various peers.\nIn this paper we have proposed a new peer-to-peer applica- tion that enables users to overcome slow upload bandwidth bottlenecks when remotely accessing data on their home computers. The key to our approach is the use of random linear coding to disseminate the desired content over several peers, thus multiplexing their upload bandwidths in order to ﬁll up the downloading user\u2019s data pipe. This model ﬁts very well with into the typical user pattern of short periods of heavy link usage interspersed with long idle times.\nWe have also shown that our proposed system provides a natural incentive for peers to voluntarily join and cooperate within our framework. Moreover, our system is asymptotically fair in the sense that each user beneﬁts from unallocated network bandwidth in proportion to its contribution to the system. As such, our system is also resilient to adversarial or malicious collusion, guaranteeing that fairness even when some peers do not use the prescribed bandwidth allocation rule or attempt to interfere with others\u2019 access. These analytic conclusions have been conﬁrmed through simulation. We have also demonstrated the real-time applicability of random linear coding for the proposed application."},"refs":[{"authors":[{"name":"R. Ahlswede"},{"name":"N. Cai"},{"name":"S.-Y. R. Li"},{"name":"R. W. Yeung"}],"title":{"text":"Network information ﬂow"}},{"authors":[{"name":"P. A. Chou"},{"name":"Y. Wu"},{"name":"K. Jain"}],"title":{"text":"Practical network coding"}},{"authors":[{"name":"J. Byers"},{"name":"M. Luby"},{"name":"A. Rege"}],"title":{"text":"A Digital Fountain Approach to Reliable Distribution of Bulk Data"}},{"authors":[{"name":"D. Qiu"},{"name":"R. Srikant"}],"title":{"text":"Modelling and performance analysis of bittorrent-like peer-to-peer networks"}},{"authors":[{"name":"S. Acedanski"},{"name":"S. Deb"},{"name":"M. Medard"},{"name":"R. Koetter"}],"title":{"text":"How Good is Random Linear Coding Based Distributed Networked Storage?"}},{"authors":[{"name":"E. Calabi"}],"title":{"text":"On the sequential and random selection of subspaces over a ﬁnite ﬁeld"}},{"authors":[{"name":"R. Ma"},{"name":"S. Lee"},{"name":"D. Yau"}],"title":{"text":"A game theoretic approach to provide incentive and service differentiation in P2P networks"}},{"authors":[{"name":"Y. Chu"},{"name":"G. Rao"},{"name":"K. Sripanidkulchai"},{"name":"H. Zhang"}],"title":{"text":" Measurement-based optimization techniques for bandwidth-demanding peer-to-peer systems"}},{"authors":[{"name":"Y. Zhao"},{"name":"C. Rhea"},{"name":"D. Joseph"}],"title":{"text":"Tapestry: A resilient global-scale overlay for service deployment"}},{"authors":[],"title":{"text":"Foldershare"}},{"authors":[{"name":"B. Cohen"}],"title":{"text":"BitTorrent"}},{"authors":[{"name":"S. Rhea"},{"name":"P. Eaton"},{"name":"D. Geels"},{"name":"H. Weatherspoon"},{"name":"B. Zhao"},{"name":"J. Ku- biatowicz"}],"title":{"text":"Pond: The Oceanstore Prototype"}},{"authors":[],"title":{"text":"P2P Fuels Global Bandwidth Binge"}},{"authors":[{"name":"X. Yang"},{"name":"G. de Veciana"}],"title":{"text":"Service Capacity of Peer-to-Peer Net- works"}},{"authors":[{"name":"X. Yang"},{"name":"G. de Veciana"}],"title":{"text":"Performance of Peer-to-Peer Networks: Service Capacity and Role of Resource Sharing Policies"}},{"authors":[{"name":"Z. Ge"},{"name":"D. R. Figueiredo"},{"name":"S. Jaiswal"},{"name":"J. Kurose"}],"title":{"text":"Modeling Peer-Peer File Sharing Systems"}},{"authors":[{"name":"C. Gkantsidis"},{"name":"P. Rodriguez"}],"title":{"text":"Network Coding for Large Scale Content Distribution"}},{"authors":[{"name":"K. G. Anagnostakis"},{"name":"M. B. Greenwald"}],"title":{"text":"Exchange-Based Incentive Mechanisms for Peer-to-Peer File Sharing"}},{"authors":[{"name":"B. Yang"},{"name":"T. Condie"},{"name":"S. Kamvar"},{"name":"H. Garcia-Molina"}],"title":{"text":"Non-cooperation in competitve P2P networks"}},{"authors":[{"name":"J. Song"},{"name":"C. Sha"},{"name":"H. Zhu"}],"title":{"text":"Nash Equilibria in Parallel Downloading with Multiple Clients"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/ita2013/153"},"links":[{"id":"1486","weight":4},{"id":"2741","weight":10},{"id":"3180","weight":20},{"id":"67","weight":3},{"id":"2206","weight":2},{"id":"1606","weight":8},{"id":"93","weight":2},{"id":"436","weight":2},{"id":"12","weight":3},{"id":"223","weight":2},{"id":"1547","weight":2},{"id":"1278","weight":14},{"id":"2287","weight":18},{"id":"3200","weight":3},{"id":"3008","weight":13},{"id":"2217","weight":5},{"id":"3010","weight":2},{"id":"3222","weight":2},{"id":"2291","weight":6},{"id":"307","weight":12},{"id":"1430","weight":2},{"id":"170","weight":36},{"id":"3199","weight":4},{"id":"813","weight":5},{"id":"3069","weight":5},{"id":"526","weight":2},{"id":"2442","weight":2},{"id":"3183","weight":2},{"id":"175","weight":2},{"id":"362","weight":11},{"id":"2763","weight":4},{"id":"2534","weight":4},{"id":"1235","weight":4},{"id":"135","weight":7},{"id":"404","weight":4},{"id":"702","weight":2},{"id":"450","weight":12},{"id":"770","weight":7},{"id":"3165","weight":4},{"id":"1082","weight":7},{"id":"3182","weight":3},{"id":"762","weight":5},{"id":"3065","weight":3},{"id":"3195","weight":36},{"id":"3218","weight":3},{"id":"1060","weight":8},{"id":"3132","weight":3},{"id":"3187","weight":5},{"id":"475","weight":2},{"id":"3137","weight":7},{"id":"3059","weight":12},{"id":"104","weight":22},{"id":"90","weight":3},{"id":"236","weight":11},{"id":"117","weight":6},{"id":"273","weight":2},{"id":"3111","weight":15},{"id":"1442","weight":4},{"id":"2745","weight":2},{"id":"3176","weight":13},{"id":"3255","weight":7},{"id":"470","weight":10},{"id":"1643","weight":4},{"id":"250","weight":10},{"id":"3036","weight":6},{"id":"163","weight":4},{"id":"26","weight":11},{"id":"2455","weight":2},{"id":"3201","weight":5},{"id":"2830","weight":2},{"id":"679","weight":4},{"id":"123","weight":4},{"id":"3049","weight":6},{"id":"1479","weight":6},{"id":"1215","weight":10},{"id":"1223","weight":4},{"id":"1473","weight":2},{"id":"217","weight":2},{"id":"1462","weight":4},{"id":"13","weight":6},{"id":"1996","weight":13},{"id":"1458","weight":14},{"id":"2025","weight":4},{"id":"2119","weight":5},{"id":"1436","weight":5},{"id":"459","weight":3},{"id":"155","weight":3},{"id":"1877","weight":3},{"id":"83","weight":5},{"id":"3072","weight":26},{"id":"306","weight":3},{"id":"1121","weight":6},{"id":"3068","weight":14},{"id":"3164","weight":9},{"id":"2697","weight":2},{"id":"398","weight":7},{"id":"152","weight":5},{"id":"2750","weight":13},{"id":"1421","weight":5},{"id":"3105","weight":9},{"id":"2178","weight":7},{"id":"1866","weight":2},{"id":"3233","weight":3},{"id":"2488","weight":16},{"id":"900","weight":5},{"id":"59","weight":11},{"id":"353","weight":4},{"id":"1846","weight":5},{"id":"1074","weight":9},{"id":"1081","weight":2},{"id":"3168","weight":5},{"id":"263","weight":9},{"id":"1136","weight":9},{"id":"2751","weight":5},{"id":"1103","weight":5},{"id":"3157","weight":6},{"id":"2317","weight":2},{"id":"375","weight":8},{"id":"3127","weight":14},{"id":"372","weight":5},{"id":"138","weight":3},{"id":"3073","weight":6},{"id":"1660","weight":2},{"id":"628","weight":13},{"id":"408","weight":5},{"id":"3005","weight":8},{"id":"1696","weight":5},{"id":"3016","weight":7},{"id":"1212","weight":30},{"id":"2324","weight":19},{"id":"487","weight":7},{"id":"508","weight":4},{"id":"65","weight":2},{"id":"3027","weight":2},{"id":"71","weight":4},{"id":"642","weight":2},{"id":"3196","weight":10},{"id":"2033","weight":3},{"id":"1830","weight":6},{"id":"108","weight":5},{"id":"202","weight":5},{"id":"691","weight":6},{"id":"2740","weight":5},{"id":"1443","weight":4},{"id":"3202","weight":12},{"id":"2812","weight":20},{"id":"3243","weight":17},{"id":"2188","weight":3},{"id":"3134","weight":5},{"id":"1365","weight":8},{"id":"445","weight":10},{"id":"3185","weight":5},{"id":"1671","weight":17},{"id":"1325","weight":7},{"id":"1844","weight":7},{"id":"219","weight":4},{"id":"428","weight":12},{"id":"3001","weight":2},{"id":"2759","weight":4},{"id":"1128","weight":7},{"id":"431","weight":3},{"id":"676","weight":2},{"id":"82","weight":26},{"id":"1448","weight":3},{"id":"3056","weight":10},{"id":"1","weight":7},{"id":"2996","weight":15},{"id":"2617","weight":13},{"id":"2435","weight":9},{"id":"3174","weight":21},{"id":"3051","weight":4},{"id":"1988","weight":2},{"id":"2884","weight":21},{"id":"3088","weight":3},{"id":"221","weight":5},{"id":"25","weight":10},{"id":"658","weight":8},{"id":"2743","weight":5},{"id":"687","weight":6},{"id":"230","weight":3},{"id":"3123","weight":11},{"id":"309","weight":3},{"id":"2773","weight":2},{"id":"31","weight":5},{"id":"3071","weight":6},{"id":"503","weight":10},{"id":"1439","weight":5},{"id":"278","weight":2},{"id":"1444","weight":2},{"id":"151","weight":3},{"id":"887","weight":2},{"id":"95","weight":8},{"id":"1109","weight":2},{"id":"1438","weight":3},{"id":"264","weight":3},{"id":"257","weight":8},{"id":"694","weight":4},{"id":"1573","weight":8},{"id":"203","weight":2},{"id":"525","weight":2},{"id":"1847","weight":3},{"id":"3205","weight":4},{"id":"3108","weight":3},{"id":"1836","weight":4},{"id":"246","weight":2},{"id":"115","weight":6},{"id":"1822","weight":5},{"id":"275","weight":5},{"id":"376","weight":3},{"id":"723","weight":2},{"id":"308","weight":2},{"id":"2838","weight":2},{"id":"3197","weight":9},{"id":"293","weight":2},{"id":"630","weight":8},{"id":"767","weight":7},{"id":"2939","weight":2},{"id":"1076","weight":19},{"id":"430","weight":14},{"id":"1233","weight":8},{"id":"641","weight":3},{"id":"1905","weight":4},{"id":"3189","weight":3},{"id":"831","weight":10},{"id":"2862","weight":5},{"id":"402","weight":5},{"id":"1084","weight":10},{"id":"2729","weight":7},{"id":"423","weight":25},{"id":"2316","weight":5},{"id":"3156","weight":9},{"id":"1883","weight":5},{"id":"3074","weight":5},{"id":"1102","weight":2},{"id":"2173","weight":6},{"id":"2753","weight":3},{"id":"1517","weight":7},{"id":"198","weight":5},{"id":"1319","weight":6},{"id":"506","weight":7},{"id":"187","weight":6},{"id":"165","weight":3},{"id":"2255","weight":4},{"id":"1627","weight":13},{"id":"1528","weight":5},{"id":"705","weight":12},{"id":"3070","weight":7},{"id":"1503","weight":3},{"id":"438","weight":3},{"id":"3181","weight":5},{"id":"2778","weight":2},{"id":"1098","weight":4},{"id":"660","weight":2},{"id":"183","weight":3},{"id":"688","weight":10},{"id":"3129","weight":3},{"id":"982","weight":2},{"id":"1930","weight":5},{"id":"3173","weight":5},{"id":"288","weight":8},{"id":"3133","weight":2},{"id":"1553","weight":13},{"id":"3184","weight":3},{"id":"3044","weight":10},{"id":"3170","weight":7},{"id":"3193","weight":6},{"id":"2738","weight":3},{"id":"1166","weight":10},{"id":"211","weight":2},{"id":"3125","weight":2},{"id":"2495","weight":4},{"id":"420","weight":3},{"id":"323","weight":5},{"id":"3136","weight":6},{"id":"1456","weight":3},{"id":"1214","weight":12},{"id":"1083","weight":12},{"id":"1434","weight":9},{"id":"1871","weight":2},{"id":"3188","weight":5},{"id":"3177","weight":4},{"id":"3166","weight":3},{"id":"1187","weight":5},{"id":"449","weight":16},{"id":"377","weight":6},{"id":"424","weight":21},{"id":"3029","weight":5},{"id":"3151","weight":29},{"id":"229","weight":7},{"id":"2146","weight":10},{"id":"1423","weight":12},{"id":"1680","weight":10},{"id":"3208","weight":5},{"id":"370","weight":4},{"id":"2299","weight":10},{"id":"2309","weight":2},{"id":"1258","weight":14},{"id":"2288","weight":2},{"id":"2340","weight":4},{"id":"2038","weight":6},{"id":"2448","weight":4},{"id":"752","weight":10},{"id":"1393","weight":7},{"id":"1300","weight":2},{"id":"1714","weight":4},{"id":"3162","weight":12}],"meta":{"jsonClass":"Map$Map3","room":"The Mackaw","date":"1360840800000","session":"2"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
