{"id":"1569565271","paper":{"title":{"text":"Iterative Encoding with Gauss-Seidel Method for Spatially-Coupled Low-Density Lattice Codes"},"authors":[{"name":"Hironori Uchikawa ∗"},{"name":"Brian M. Kurkoski \u2020"},{"name":"Kenta Kasai ∗"},{"name":"Kohichi Sakaniwa ∗"}],"abstr":{"text":"Abstract\u2014While it is known that spatially-coupled low-density lattice codes (SC-LDLC) have better decoding performance than conventional (non-coupled) LDLC lattices, in this paper it is shown that their encoding complexity is also lower. Since non- zero elements are mainly in lower triangular entries of the sparse inverse generator matrix of SC-LDLC, iterative encoding with the Gauss-Seidel method performs well. The convergence speed of iterative encoding is evaluated by both the mean square error (MSE) and the symbol error rate between a given integer vector b and the inversely generated integer vector from the codeword of b. Numerical experiments show that the convergence of encoding for SC-LDLC is 3 times faster than that of the conventional LDLC, at an MSE of 10 −10 for dimension n = 10000."},"body":{"text":"Although the decoder\u2019s computational complexity is only O(n), generating lattice points requires computational com- plexity of O(n 2 ) in general. In [4], Sommer et al. suggested that linear computational complexity encoding can be ac- complished using the Jacobi method, which is an iterative algorithm for determining the solution of a system of linear equations. Sommer et al. described that the convergence of the method was guaranteed by the nature of the sparse inverse generator matrix of LDLC lattices. However, they did not investigate convergence speed of such iterative encoding methods. Since processing over many iterations is time- and power-consuming, not only convergence conditions but also convergence speed is important for practical applications. In this paper, we evaluate the convergence speed of encoding using the Gauss-Seidel method, another iterative algorithm [8]. Numerical experiments show that the SC-LDLC encoder with the Gauss-Seidel method has signiﬁcantly faster convergence speed than the LDLC encoder with the Gauss-Seidel method because of the spatially-coupled structure.\nAn n-dimensional lattice Λ is deﬁned by an n-by-n genera- tor matrix G. The lattice consists of the discrete set of points x = (x 1 , x 2 , . . . , x n ) T for which\nwhere b = (b 1 , . . . , b n ) T is from the set of all possible integer vectors, b i ∈ Z. The transpose of a vector x is denoted x T . Lattices are linear, in the sense that x 1 + x 2 ∈ Λ if x 1 and x 2 are lattice points. It is assumed that G is n-by-n and full rank (note SC-LDLC lattices allow G to have additional rows which are linearly dependent).\nThe decoding performance of lattices are evaluated over the unconstrained-power AWGN channel [4], [5]. Let the codeword x be an arbitrary point of the lattice Λ. This codeword is transmitted over an AWGN channel, where noise z i with noise variance σ 2 is added to each codeword sym- bol. Then the received sequence y = (y 1 , y 2 , . . . , y n ) T is\nis used, so that if the ( N, α, d, L) SC-LDLC lattice has a lattice point x = (x (1) , . . . , x (l) , . . . , x (L) ) T and x (l) = (x (l) 1 , . . . , x (l) N ), then H [L] x = b, where b = (b (1) , . . . , b (l) , . . . , b (L−d+1) ) T and b (l) = (b (l) 1 , . . . , b (l) N ), is an information integer vector, and, 0 N (d−1) is the all zero column vector of length N (d − 1). The inverse matrix of H [L] is deﬁned as ˜ G [L] . Since we set 0 N (d−1) to the last d − 1 sections of ˜ b, The sub-matrix G [L] which is from column 1 to N (L − d + 1) of ˜ G [L] can be used for generating lattice points. Therefore a lattice point in the dimension N (L−d+1) SC-LDLC lattice is generated as\nThe dimension of the SC-LDLC lattice is, therefore, less than the number of elements in x, which is n = NL. Dimension ratio is deﬁned as\nThe ratio R L converges to 1 with increasing L, with a gap of O(1/L). Therefore, this dimension loss is negligible for sufﬁciently large L. We observe that the noise threshold of the ( N , 0.8, 7, L) SC-LDLC lattices, with sufﬁciently large L, is very close to the theoretical limit [5].\nGenerally, a lattice encoder generates a lattice point x using Eq. (1). For LDLC lattices, G is not sparse in general, and so the encoder requires computational complexity and storage of O(n 2 ). However, b = Hx is a system of linear equa- tions which can be solved using iterative methods. One such method, the Jacobi method, can be described as a \u201cparallel\u201d approach, ﬁnding a candidate solution x(t) on iteration t, using the previous solution x(t−1). This approach was suggested by Sommer et al., observing that encoding complexity is O(n), since H is sparse [4].\nThe Gauss-Seidel method is another iterative method. The Gauss-Seidel method is a \u201cserial\u201d approach; in each iteration, each element of the candidate solution is computed in turn. To perform computations serially, the Gauss-Seidel method decomposes the matrix into upper- and lower-triangular parts. In this section, LDLC and SC-LDLC encoders with the Gauss- Seidel method are described. The Gauss-Seidel method has faster convergence speed than the Jacobi method. Moreover the SC-LDLC encoder with the Gauss-Seidel method performs well because of the spatially-coupled structure.\nBefore explanation of the Gauss-Seidel Method, we deﬁne the matrix H as a row-permuted version of the sparse inverse generator matrix H, such that H has ±1 in the diagonal entries (non-zero diagonal elements are required by the Gauss-Seidel method). For example, a pictorial view of a matrix H for the (100, 0.8, 7) LDLC lattices is shown in Fig. 1. Also the vector b is a permuted version of the integer vector b, such\n⎡ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎣\n⎤ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎦\nwhere x i (t + 1) is the ith entry of x(t + 1), h i,j is the (i, j) entry of H, and J i is the column index set of the non-zero elements in the row i of H. The computation of x i (t+1) uses the elements of x(t + 1) that have already been computed, and the elements of x(t) that have not yet been computed at iteration t + 1.\nConsider a sparse inverse generator matrix H [L] of the SC-LDLC lattices. Non-zero elements are mainly in lower triangular entries of H [L] without the ﬁrst N (d − 1) rows, see Eq. (7). Since the Gauss-Seidel method uses already-computed elements of x(t + 1) at iteration t + 1 for x i (t + 1) in the case that the non-zero elements are in J i ∩{j|j < i}, it is expected that the convergence speed of the encoding of the SC-LDLC lattices with the Gauss-Seidel method is faster than that of the LDLC lattices.\nAn SC-LDLC encoder with the Gauss-Seidel method gen- erates a codeword vector x (l) (t + 1) at section l and iteration t + 1 by Eq. (9). The matrix P (l) d is row-permuted version of the P (l) d , such that H [L] has ±1 in the diagonal entries. For example, a pictorial view of a matrix H [L] for a (5, 0.8, 7, 20) SC-LDLC lattice is shown in Fig. 2. The vector b (l) is a permuted version of the integer vector b (l) , such that the ith element of b (l) equals the element of b (l) for which the corresponding row of P (l) 1 has ±1 at the ith location.\nAll elements of x(0) are initialized with 0. From Eq. (9), it is observed that the SC-LDLC encoder uses the elements of x(t) (l) computed at the previous iteration for the ﬁrst d − 1 sections. For remaining sections, the SC-LDLC encoder uses only the elements of x(t + 1) (l) computed at the current iteration. Intuitively it is expected that the convergence speed of the encoding of SC-LDLC lattices with the Gauss-Seidel method is faster than that of LDLC lattices.\n⎧ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎩\nWe generate 1000 sparse inverse generator matrices for each lattice ensemble and evaluate 100 randomly generated integer vectors 2 for each matrix to compute the average. Mean square error (MSE) at iteration t is calculated by\nwhere n is the length of b. Fig. 4 shows MSE(t) for (1000, 0.8, 7) and (10000, 0.8, 7) LDLC lattices, and (50, 0.8, 7, 20) and (500, 0.8, 7, 20) SC-LDLC lattices. (1000, 0.8, 7) LDLC and (50, 0.8, 7, 20) SC-LDLC resp. (10000, 0.8, 7)\nLDLC and (500, 0.8, 7, 20) SC-LDLC lattices are the same dimension n = 1000 (resp. n = 10000). It is observed that convergence speed becomes faster with increasing dimension n. Convergence of the (500, 0.8, 7, 20) SC-LDLC lattices is almost 3 times faster than that of the (10000, 0.8, 7) LDLC lattices at an MSE of 10 −10 . It is also observed that the slopes of the MSE( t) curves for the dimension n = 1000 both LDLC and SC-LDLC lattices change around an MSE of 10 −5 . We conjecture that this is caused by small cycles in the H, similar to error ﬂoors of low-density parity-check codes. Section size N does not seem to affect the convergence of SC-LDLC lattices because there are small differences in the MSE( t) between the (50, 0.8, 7, 20) and (500, 0.8, 7, 20) SC- LDLC lattices. Fig. 5 shows MSE( t) for the (50, 0.8, 7, L) SC-LDLC lattices for L = 20, 100, 200 and 500. We observe that convergence speed accelerates with increasing coupling factor L. From the results in Fig. 5, we can obtain sufﬁciently accurate codewords for transmission with few iterations if L is sufﬁciently large.\nWe also show symbol error rate (SER) performance in Fig. 6. The SER at iteration t is calculated by\nwhere I[·] is an indicator function that returns 1 if an argument is true, otherwise returns 0, and (·) i denotes ith element of an argument vector. The dimension of lattices in Fig. 6 is 1000, therefore 8 iterations is sufﬁcient for SC-LDLC lattices with the Gauss-Seidel method to vanish encoding symbol error from expectations. On the other hand, 21 iterations is neces- sary for LDLC lattices. In addition, the Gauss-Seidel method converges slightly faster than Jacobi method for conventional LDLC lattices, and signiﬁcantly faster for SC-LDLC lattices.\nsubstitution. As in many previous papers, shaping was not considered here because of the unconstrained power scenario (i.e. Poltyrev setting). It should be further noted that if a purely lower-triangular matrix is available, then a power constraint can be easily introduced by using cubic shaping, see [10]."},"refs":[{"authors":[{"name":"C. E. Shannon"}],"title":{"text":"Probability of error for optimal codes in a Gaussian channel"}},{"authors":[{"name":"R. Urbanke"},{"name":"B. Rimoldi"}],"title":{"text":"Lattice codes can achieve capacity on the AWGN channel"}},{"authors":[{"name":"U. Erez"},{"name":"R. Zamir"}],"title":{"text":"Achieving 1/2 log (1+SNR) on the AWGN channel with lattice encoding and decoding"}},{"authors":[{"name":"N. Sommer"},{"name":"M. Feder"},{"name":"O. Shalvi"}],"title":{"text":"Low-density lattice codes"}},{"authors":[{"name":"H. Uchikawa"},{"name":"B. M. Kurkoski"},{"name":"K. Kasai"},{"name":"K. Sakaniwa"}],"title":{"text":"Threshold improvement of low-density lattice codes via spatial coupling"}},{"authors":[{"name":"S. Kudekar"},{"name":"T. Richardson"},{"name":"R. Urbanke"}],"title":{"text":"Threshold saturation via spatial coupling: Why convolutional LDPC ensembles perform so well over the BEC"}},{"authors":[{"name":"B. M. Kurkoski"},{"name":"K. Yamaguchi"},{"name":"K. Kobayashi"}],"title":{"text":"Single-Gaussian messages and noise thresholds for decoding low-density lattice codes"}},{"authors":[{"name":"Y. Saa"}],"title":{"text":"Iterative Methods for Sparse Linear Systems"}},{"authors":[{"name":"G. Poltyrev"}],"title":{"text":"On coding without restrictions for the AWGN channel"}},{"authors":[{"name":"N. Sommer"},{"name":"M. Feder"},{"name":"O. Shalvi"}],"title":{"text":"Shaping methods for low-denisty lattice codes"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569565271.pdf"},"links":[],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S10.T4.3","endtime":"12:30","authors":"Hironori Uchikawa, Brian Michael Kurkoski, Kenta Kasai, Kohichi Sakaniwa","date":"1341403800000","papertitle":"Iterative Encoding with Gauss-Seidel method for Spatially-Coupled Low-Density Lattice Codes","starttime":"12:10","session":"S10.T4: Coding with Lattices","room":"Stratton 20 Chimneys (306)","paperid":"1569565271"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
