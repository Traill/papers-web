{"id":"1569566871","paper":{"title":{"text":"Spherically punctured biorthogonal codes"},"authors":[{"name":"Ilya Dumer"},{"name":"Olga Kapralova"}],"abstr":{"text":"Abstract\u2014 Consider a binary Reed-Muller code RM(r, m) deﬁned on the full set of binary m-tuples and let this code be punctured to the spherical layer S(b) that includes only m-tuples of a given Hamming weight b. More generally, we can consider punctured RM codes RM(r, m, B) restricted to some set B of several spherical layers S(b), b ∈ B. In this paper we specify this construction for the biorthogonal codes RM(1, m) and the Hadamard codes H(m). It is shown that the overall weight of any code vector in a punctured code H(m, B) is determined by the weight w of its information block. More speciﬁcally, this weight depends only on the values of the Krawtchouk polynomials K m b (w) for all b ∈ B. We further reﬁne our codes by limiting the possible weights w of the input information blocks. As a result, we obtain sequences of codes that meet or closely approach the Griesmer bound."},"body":{"text":"In this paper we study punctured codes obtained by restrict- ing some binary Reed-Muller (RM) codes to small subsets of their positions. Our main goal is to retain simple code structure of RM codes and obtain new codes with good parameters. Codes RM(r, m) - deﬁned by two integers m ≥ r ≥ 0 - have length n, dimension k, and distance d as follows:\nRM codes enjoy some simple and powerful decoding proce- dures, such as majority decoding [1] that has decoding com- plexity of order nk or recursive decoding that has complexity order of n min(r, m − r). In addition, these simple algorithms can perform well beyond half the code distance [12], [13]. In particular, long RM codes of any ﬁxed order r have low de- coding complexity of order nr and correct most error patterns of weight T = n(1 − ε)/2 or less for any ε > 0. Subcodes of RM codes substantially improve decoding performance [13], while polar codes - similarly related to RM codes - achieve channel capacity [14]. However, subcodes of RM codes or polar codes, which have been designed to date, achieve good performance only on very long blocks. Therefore, we wish to substantially reduce the original lengths of RM codes. Our goal is to design codes with better performance on short blocks while keeping a simple recursive structure of RM codes that yields fast decoding procedures.\nIn this paper we consider punctured codes derived from the simplest RM codes. Namely, we study codes RM(1, m), which are also called biorthogonal codes, and the Hadamard codes H(m). We restrict code positions to the binary tuples (x 1 , . . . , x m ) of any given Hamming weight b and deﬁne the\nparameters of the resulting codes of length ( m b ). In our future work we will also describe simple decoding algorithms that efﬁciently correct high-noise errors in these punctured codes.\nLet F (r, m) be the set of m-variate Boolean polynomials f of degree r or less. Then the binary RM code RM(r, m) is a set of truth-tables F m 2 f → F 2 . In other words, code RM(r, m) contains any vector (. . . , f (x), . . .) obtained on all n = 2 m positions x = (x 1 , . . . , x m ) by evaluating any polynomial f ∈ F (r, m). Now let S(b) be the Hamming sphere of radius b in F m 2 , which includes all vectors x of the Hamming weight wt(x) = b. In this paper we consider the punctured codes P (r, m, b) which are formed by the maps S(b) f → F 2 and have length n b = ( m b ) .\nDeﬁnition 1: A code P (r, m, b) consists of the vectors (. . . , f (x), . . .), where x ∈ S b , f ∈ F (r, m) and r, m, b are integers such that 0 ≤ r, b ≤ m.\nMore generally, consider some subset of radii B ⊆ [m], where [m] = {0, 1, . . . , m} and deﬁne the union of spheres S(B) = ∪ b∈B S(b). Then P (r, m, B) is obtained from RM(r, m) by restricting its positions to the set S(B). Ob- viously, P (r, m, B) is a linear code of length\nLet us now deﬁne the incidence matrix W t,b (m) of t-subsets vs. b-subsets, which is an m t × m b matrix whose rows represent the values of the Boolean monomials of degree t taken on a sphere S(b). Incidence matrices have been extensively studied in combinatorial designs (see [2], [3]). For a set of layers B = {b 1 , ..., b s } we deﬁne the matrix\nby appending different incidence matrices W t,b i (m). Then a punctured code P (r, m, B) is the linear span of the matrix 1\n   \nW 0,B (m) W 1,B (m)\n   \nFinally, note that the set B = [m] gives the full RM code RM(r, m) and its generator matrix G (r,m,[m]) .\nOur next goal is to ﬁnd parameters of the spherically restricted codes P (r, m, b). For a general order r ≥ 2, this study leads to some long-standing problems associated with the weight distributions A(w) of code vectors and informa- tion blocks in the original codes RM(r, m). Therefore, we will address the simplest case r = 1. More speciﬁcally, we will consider the Hadamard codes H(m) obtained from linear functions of m variables, and then proceed with codes RM(1, m) obtained from afﬁne functions. We will also intro- duce a new precoding technique that drastically increases code distance and yields some inﬁnite code families that meet the Griesmer bound.\nConsider the Hadamard code H(m) of dimension m formed by linear Boolean functions f (x 1 , ..., x m ). We take positions x on a sphere S(b) and obtain a spherically restricted Hadamard code H(m, b) .\nLet g = (g 1 , . . . , g m ) be an information block and let w denote its Hamming weight. Also for parameters m, b, w, we use the binary Krawtchouk polynomial [1], [5]\nThe following lemma shows that the input weight w deﬁnes the weight of the vector y = gW 1,b (m) in code H(m, b).\nLemma 2: A binary input vector g = (g 1 , . . . , g m ) of weight w gives the code vector y = gW 1,b (m) of weight\nProof: Consider a point x ∈ S b and deﬁne the respective supports of g and x as follows\ntakes values g I (x) = 1 if and only if the set I ∩ X has odd size j. The number of such points x on sphere S b ,\nw j\nNote that S m b (w) > 0 for any w > 0, except for the case w = m for even b. Thus, we have\nNow we proceed with the punctured biorthogonal code P (m, b) = P (1, m, b) obtained by restricting RM(1, m) to the spherical layer S(b).\nLemma 4: Code P (m, b) has dimension k(m, b) = m. Any input afﬁne function\nProof: Let 1 be the all-ones vector of length n = 2 m . Then RM(1, m) reduces to either H(m) if g 0 = 0 or the coset H(m) + 1 if g 0 = 1. However, the punctured vector 1 S(b) on the sphere S(b) can still belong to H(m, b). Namely,\nIndeed, (2) shows that vector y has weight m b if and only if w = m and b is odd. Thus,\nFrom (3) we see that P (m, b) always has dimension m. Finally, note that afﬁne forms (4) generate vectors y of weight n b /2 ± K m b (w)/2, depending on the value of g 0 = 0, 1.\nLemma 4 shows that the matrix G(m, b) = G (1,m,B) has rank m. It is easy to verify that its null-space\nBelow we mostly use induction for other cases b ∈ [2, m − 2]. Lemma 5: Code P (m, b) has generator matrix\nG(m, b) = G(m − 1, b) G(m − 1, b − 1) \t (8) Proof: We ﬁrst re-order the columns of G(m, b) by\ntaking all positions x ∈ S(b) with x m = 0 and then all positions with x m = 1. This obviously gives the matrix\nThe last unit row in matrix G(m−1, b−1) is linearly dependent of the ﬁrst m rows and can be removed.\nwt min (gG(m, b)) = min m−1 b−1 , m−1 b \t . \t (9) Proof: Note that case (A) can only include one of the\ntwo vectors g ⊥ deﬁned in (6). Either vector g ⊥ gives the all- zero code vector gG on one of the two submatrices (8) and an all-one vector on the other.\nWe now proceed with case B, which is much more involved. Consider representation (8) and deﬁne the sum of distances\nd(m, b) ≥ min δ(m, b), m−1 b−1 , m−1 b \t (11) Proof: The two latter estimates come directly from\ncase A. For case B, (8) shows that vector gG has weight wt g (m, b) = wt g (m − 1, b) + wt g (m − 1, b − 1).\nNote that case A gives two tight estimates in (11). By contrast, case B gives a tight estimate only if the same input block generates both minimum distances, d(m − 1, b) and d(m − 1, b − 1). First consider two special cases, for which the estimate δ(m, b) is not tight.\nProof: See [15]. We use straightforward but lengthy calculations related to the Krawtchouk polynomials.\n    \n   \nProof: We ﬁrst bound d(m, b) from above. Then equal- ities (12) are immediately satisﬁed if we take\n \n(13) Next we prove the lower bounds for d(m, b) in case B. Our base case includes equalities (7). By induction, we assume that (12) holds for some m and any b ∈ [2, m − 1]. Then we use (12) and recalculate function (10):\n   \n  \nWe complete case B with two special cases m = 2b − 2, 2b, for which δ(m + 1, b) < d(m + 1, b).Then Lemma 8 gives\n \nThus, case B always gives lower bound (12). Finally, note that this bound also includes case A. Indeed, (9) gives (12) in its ﬁrst and last lines. The second line of (12) also gives the lowest estimate, since for m = 2b\nTheorem 9 can also be reformulated for the Krawtchouk polynomials. First, note [5], [6], [7] that the Krawtchouk polynomial K m b (w) has b simple (non-repeating) roots 0 < r 1 < . . . < r b < m, which are symmetric with respect to m/2. These roots are also interlaced with b − 1 roots of the derivative of K m b (w). Due to this, K m b (w) decreases in the subinterval I 1 = [1, r 1 ] and oscillates in the second subinterval I 2 = [r 1 , m/2] . Here r 1 > 1 for all b < m/2 and r 1 = 1 for b = m/2. Now we reformulate Theorem 9 as follows.\nCorollary 10: For all integers b ∈ [1, m − 1] and w ∈ [1, m − 1], polynomial K m b (w) has maximum absolute value at w = 1 :\nexcept for b = m/2, in which case the maximum is achieved at w = 2.\nWe note that the result similar to Corollary 10 is known in the asymptotic setting [10], where it is shown that condition (14) holds for all 1 ≤ w ≤ m/2 given parameters η ∈ (0, 1), b = (1 + η) m/2, and sufﬁciently large m > m 0 (η). Our Corollary 10 extends this result for all b and m using recursive techniques instead of asymptotic estimates of the Krawtchouk polynomials.\nFrom Lemma 2 we see that restriction of an input spectrum can improve the weight spectra of the resulting codes H(m, b) and P (m, b). We now describe this technique in more detail. Consider a code H(m, {1, 2}) of length m(m + 1)/2. By Lemma 2, an information word g of weight w generates a codeword of weight\nThus, the minimum distance of H(m, {1, 2}) keeps growing as long as the entire weight range [w 0 , w 1 ] of nonzero infor- mation blocks gets closer to the midpoint (m+1)/2. Therefore we will now restrict the set G of possible information blocks and consider this set as a code G[m, k, δ] of dimension k and distance δ. Our encoding now becomes a two-step procedure. First, the information word u ∈ F k 2 is encoded into a vector g ∈ G of length m, which in turn is encoded\ninto y ∈ H(m, B). This procedure yields the smaller code H G (m, B) and can be depicted as follows\nFor example, the parity-check code G[m, m − 1, 2] increases the distance m of H(m, {1, 2}) to 2m − 2, while reducing its dimension m to m − 1. The resulting codes can have good parameters. For example, code G[7, 6, 2] generates a [28, 6, 12] linear code that meets the Griesmer bound. Similarly, the (extended) Hamming code G[m, m− log 2 m −1, 4] increases the distance of H(m, {1, 2}) almost fourfold.\nAs another example, we take odd s and consider the code G[m = 2 s − 1, 2s, 2 s−1 − 2 (s−1)/2 ] which is the dual of the double-error-correcting BCH code [1]. Then the two-layer code H G (m, {1, 2}) has length m(m + 1)/2 and distance (m 2 − 1)/4, which is very close to half the code length.\nNote also that any linear code G can be replaced with a nonlinear code, such as the Kerdock code with an even parameter s in the above example. Indeed, it is easy to see from Lemma 2 that a non-linear precoding of vectors g and g separated by some distance w gives vectors\nThus, the parameters of codes H G (m, B) can be improved by using the precoded sets G with good distance distributions.\nFinally, let us describe some inﬁnite families of codes that achieve the Griesmer bound. Let G(s) = G[2 s − 1, s, 2 s−1 ] denote the shortened code RM(1, s). We then use encoding (15) and consider code H G(s) (2 s − 1, {1, 2}).\nLemma 11: Code H G(s) (2 s −1, {1, 2}) meets the Griesmer bound.\nProof: G(s) is a constant-weight equidistant code that has length m = 2 s − 1 and nonzero weight w = 2 s−1 . Then code H G(s) retains the dimension s of code G(s), has length\nand distance d = w + w(m − w) = 2 2s−2 . Thus, H G(s) (2 s − 1,B) meets the Griesmer bound\nNote also that H G(s) is a constant-weight equidistant code with all weights and pairwise distances equal to 2 2s−2 . It is also easy to verify that the extended set of layers B ext = {1, 2, 2 s − 2, 2 s − 3} and all of its subsets B also give codes H G(s) (2 s −1, B) that meet the Griesmer bound. Both families of codes were previously designed using different techniques (see, for example, [4]).\nWe will now consider some general layer b < m/2 and analyze the minimum distance of code H G (m, b) that uses general encoding procedure (15). Recall [5] that the Krawtchouk polynomial K m b (w) has b simple (non-repeating) roots 0 < r 1 < . . . < r b < m, which are symmetric with re- spect to m/2. Below we use the estimate [5]\n1 2\nThus, r 1 /m ≥ λ. Observe also that H(λ) is the ﬁrst linear programming bound for a code with a relative distance τ , whereas 1 − H(τ ) is the lower Gilbert-Varshamov bound (see 17.61 in [1]). Thus, parameter θ represents the (positive) gap between the two bounds.\nNow consider a code G[m, k, δ min ], in which all nonzero code weights (or pairwise distances) fall into some interval [δ min , δ max ] and let\nTheorem 12: Code H G (m, b) of length n b = m b has minimum distance\nProof: Using equality (2), we only need to upper-bound the Krawtchouk polynomials K m b (w). We may also consider the interval w ∈ [δ, m/2] , due to the symmetry conditions for Krawtchouk polynomials. Note that K m b (w) decreases in the ﬁrst subinterval I 1 = [δ, r 1 ] for δ ≤ r 1 , and oscillates in the second subinterval I 2 = [r 1 , m/2] . Thus, K m b (w) ≤ K m b (δ) for I 1 . To estimate K m b (w) in I 2 we use the bound [5]\nThis bound holds for any w ∈ [0, m] but will be used only in the oscillating region I 2 , where it is exponentially tight. Then w/m ≥ r 1 /m ≥ λ. We obtain bound (16) using standard estimates 10.16 of [1] for binomial coefﬁcients:\nDiscussion. The lower bound (16) can be improved for δ > r 1 . First, the exponent of the bound in the oscillating region I 2 can be tightened. Indeed, the function (17) decreases in w on subinterval I 2 , so the larger w > r 1 gives the larger λ > λ, which in turn increases the resulting positive gap θ = H(λ ) + H(τ ) − 1.\nAlso, our estimates can be further improved by replacing (17) with some other bounds of [5] and [6] (the latter gives the best known estimate). However, (17) still exhibits the same exponential behavior in the oscillating region I 2 as the other known bounds. In the non-oscillating region I 1 , all these bounds are not tight. It is for this reason that we employ a simple tight estimate K m b (δ) in I 1 instead of (17). Note also that our bound (16) approaches the small order of √ n b as w tends to m/2. This was already demonstrated in Section IV-A, in which precoding procedure was used to eliminate the lowest input weights w = 1, 2, 3, . . . and their (highest) counterparts m − w.\nBound (16) gives some tight estimates on code distance. However, this bound becomes rather loose if we consider a combination of multiple layers B = {b 1 , ..., b s }. The most notable example is the original code H(m). In this case, bound (16) is placed below n b /2 for each layer b. However, the overall code distance 2 m−1 exceeds the sum of distances d(m, b) and equals the sum n b /2. Thus, in the multi-layer design, one can exceed the sum of one-layer distances. This gain mostly stems from the following. Note that the largest layers S b give the largest increase to the code length n B and its distance d(m, B). On the other hand, for b < m/2 and for b > m/2, different layers yield the lightest codewords on the different information blocks as seen in (13). Therefore, multi- layer design can improve spherical codes if the set B includes several consecutive high-level layers with b ∼ m/2.\nWe now brieﬂy describe the algorithm that efﬁciently com- putes the sets B that can maximize the minimum distance of a code H G (m, B). To ﬁnd the optimal sets B for codes of length up to N, we formulate the following problem:\nm b\nHere w b i denotes the weight produced by the information word of weight i on a given level b, and the binary variable c b ∈ {0, 1} takes value 1 if b ∈ B. The integer program (18) is an instance of the NP-hard weighted set cover problem. To simplify our code search, we assume that the initial information-level codes G have k = o(m) different weights for large m. Our algorithm has time complexity O(m k 2 m/2 ) and space complexity O(m k−1 2 m/2 ). In brief, this algorithm generalizes meet-in-the-middle approach [8] developed for the 0-1 knapsack problem, and uses range trees [9] for a k- dimensional range searching. As a result, we found about 50 codes (see [15]) that coincide with the best known codes listed in the table [11]. The algorithm also produces longer codes with parameters that approach the Griesmer bound.\nThis paper presents a new code design that combines single- layer restrictions of biorthogonal codes with a precoding of information blocks. This design has produced some high- distance codes that meet or approach the Griesmer bound. One possible extension is to consider the multi-layer constructions, which bring code distance closer to the Griesmer bound, as shown in Section V. Another important direction is to extend our spherically-restricted design to general codes RM(r, m) of an arbitrary order r. This approach can potentially give many good codes with the higher code rates. Finally, our preliminary observations indicate that spherically-punctured codes enable efﬁcient decoding procedures. Our goal is to design decoding algorithms for these codes that can correct high-noise errors and operate close to channel capacity.\nThe authors thank I. Krasikov for helpful remarks. Re- search was supported by NSF grant 1102074 and ARO grant W911NF-11-1-0027."},"refs":[{"authors":[{"name":"J. MacWilliams"},{"name":"A. Sloane"}],"title":{"text":" The Theory of Error-Correcting Codes"}},{"authors":[{"name":"D. H. Gottlieb"}],"title":{"text":"A certain class of incidence matrices"}},{"authors":[{"name":"R. M. Wilson"}],"title":{"text":"A diagonal form for the incidence matrices of t-subsets vs k-subsets"}},{"authors":[{"name":"T. Helleseth"}],"title":{"text":"Further classiﬁcations of codes meeting the Griesmer bound"}},{"authors":[{"name":"I. Krasikov"},{"name":"S. Litsyn"}],"title":{"text":"Survey of Krawtchouk Polynomials"}},{"authors":[{"name":"M. Ismail"},{"name":"P. Simeonov"}],"title":{"text":"Strong asymptotics of Krawtchouk Poly- nomials"}},{"authors":[{"name":"V. Levenshtein"}],"title":{"text":"Krawtchouk polynomials and universal bounds for Hamming spaces"}},{"authors":[{"name":"E. Horowitz"},{"name":"S. Sahni"}],"title":{"text":"Computing partitions with applications to the knapsack problem"}},{"authors":[{"name":"M. de Berg"},{"name":"O. Cheong"},{"name":"M. van Kreveld"}],"title":{"text":"Computa- tional Geometry: Algorithms and Applications"}},{"authors":[{"name":"N. Alon"},{"name":"B. Sudakov"}],"title":{"text":"Bipartite Subgraphs and the Smallest Eigen- value"}},{"authors":[{"name":"M. Grassl"}],"title":{"text":"Bounds on the minimum distance of linear codes and quantum codes"}},{"authors":[{"name":"E. Krichevskiy"}],"title":{"text":"On the Number of Reed-Muller Code Correctable Errors"}},{"authors":[{"name":"I. Dumer"}],"title":{"text":"Recursive decoding and its performance for low-rate Reed- Muller codes"}},{"authors":[{"name":"E. Arıkan"}],"title":{"text":"Channel polarization: A method for constructing capacity achieving codes for symmetric binary-input memoryless channels"}},{"authors":[],"title":{"text":"Available online at http://www"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569566871.pdf"},"links":[{"id":"1569565883","weight":4},{"id":"1569565711","weight":4},{"id":"1569559967","weight":4},{"id":"1569564805","weight":4},{"id":"1569565775","weight":4},{"id":"1569566207","weight":4},{"id":"1569566739","weight":13},{"id":"1569565609","weight":4},{"id":"1569566795","weight":4},{"id":"1569565803","weight":4},{"id":"1569566575","weight":4},{"id":"1569563307","weight":4},{"id":"1569566369","weight":4},{"id":"1569566581","weight":4},{"id":"1569559111","weight":4},{"id":"1569565839","weight":4},{"id":"1569566139","weight":4},{"id":"1569554689","weight":4},{"id":"1569565847","weight":8},{"id":"1569563231","weight":4},{"id":"1569566003","weight":4},{"id":"1569562207","weight":4},{"id":"1569565705","weight":4},{"id":"1569566695","weight":4},{"id":"1569561123","weight":4},{"id":"1569565155","weight":4},{"id":"1569557633","weight":4},{"id":"1569566293","weight":4},{"id":"1569557715","weight":4},{"id":"1569565925","weight":4},{"id":"1569566737","weight":4},{"id":"1569564283","weight":4},{"id":"1569563975","weight":4},{"id":"1569564253","weight":4},{"id":"1569565113","weight":4},{"id":"1569565143","weight":4},{"id":"1569566727","weight":4},{"id":"1569565515","weight":4},{"id":"1569560581","weight":4}],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S2.T5.2","endtime":"12:10","authors":"Ilya Dumer, Olga Kapralova","date":"1341229800000","papertitle":"Spherically punctured biorthogonal codes","starttime":"11:50","session":"S2.T5: Reed-Muller Codes","room":"Kresge Little Theatre (035)","paperid":"1569566871"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
