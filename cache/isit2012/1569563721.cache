{"id":"1569563721","paper":{"title":{"text":"Systematic DFT Frames: Principle and Eigenvalues Structure"},"authors":[{"name":"Mojtaba Vaezi"},{"name":"Fabrice Labeau"}],"abstr":{"text":"Abstract\u2014Motivated by a host of recent applications requiring some amount of redundancy, frames are becoming a standard tool in the signal processing toolbox. In this paper, we study a speciﬁc class of frames, known as discrete Fourier transform (DFT) codes, and introduce the notion of systematic frames for this class. This is encouraged by application of systematic DFT codes in distributed source coding using DFT codes, a new application for frames. Studying their extreme eigenvalues, we show that, unlike DFT frames, systematic DFT frames are not necessarily tight. Then, we come up with conditions for which these frames can be tight. In either case, the best and worst systematic frames are established from reconstruction error point of view. Eigenvalues of DFT frames, and their subframes, play a pivotal role in this work."},"body":{"text":"A basis is a set of vectors that is used to \u201cuniquely\u201d represent any vector as a linear combination of basis elements. Frames , as opposed to bases, are \u201credundant\u201d set of vectors which are used for signal representation. Therefore, frames are more general than bases as they are not necessarily linearly independent, but are complete. What would be the beneﬁt of representing a signal with more than the minimum number of vectors required for completeness? Frames offer ﬂexibility in design and have variety of applications. They show resilience to additive noise (including quantization noise), robustness to erasure (loss), and numerical stability of reconstruction [1], [2]. With increasing applications, frames are becoming more prevalent in signal processing.\nFrames are generally motivated by applications requiring some level of redundancy. Among them is distributed source coding (DSC) that uses DFT codes, recently introduced in [3]. This provides a new application for frame expansion, viewing the generator matrix of a DFT code as a frame operator [4]. In this paper, we consider this speciﬁc type of tight frames which are known as DFT codes and used for erasure and error correction in the real ﬁeld [2]\u2013[5].\nMotivated by its application in parity-based DSC that uses DFT codes [3], we introduce the notion of systematic frames. A systematic frame is deﬁned to be a frame that includes the identity matrix as a subframe. Since tight frames minimize\nreconstruction error [2], [1], we explore systematic tight DFT frames . Although it is straightforward to come up with sys- tematic DFT frames, we show that systematic \u201ctight\u201d DFT frames exist only for speciﬁc DFT codes. When such a frame does not exist, we will be looking for systematic DFT frames with the \u201cbest\u201d performance, from minimum mean-squared reconstruction error standpoint. We also demonstrate which systematic frames are the \u201cworst\u201d in this sense.\nCentral to this paper is the properties of the eigenvalues of V H V , in which V is a square or non-square submatrix of a DFT frame. 1 Speciﬁcally, we present some bounds on the extreme eigenvalues of such matrices. These bounds are used to determine the conditions required for a systematic frame so as to be tight. Besides, eigenvalues are crucial in establishing the best and worst systematic frames.\nThe paper is organized as follows. In Section II, we review two set of inequalities on the eigenvalues of Hermitian matri- ces which are frequently used in this paper. In Section III, we introduce systematic DFT frames and set the ground to study their extreme eigenvalues in Section IV. Section V is devoted to the evaluation of reconstruction error and classiﬁcation of systematic frames based on that. We conclude in Section VI.\nAn n × n Vandermonde matrix with unit complex entries is deﬁned by\n   \n   \nin which θ p ∈ [0, 2π) and θ p = θ q for p = q, 1 ≤ p, q ≤ n. If θ p = 2π n (p − 1), W becomes the well-known IDFT matrix [6]. For this Vandermonde matrix we can write [7], [8]\nLet A be a Hermitian k × k matrix with real eigenvalues {λ 1 (A), . . . , λ k (A)} which are collectively called the spec- trum of A, and assume λ 1 (A) ≥ λ 2 (A) ≥ · · · ≥ λ k (A).\nSchur-Horn inequalities show to what extent the eigenvalues of a Hermitian matrix constraint its diagonal entries. Proposition 1. Schur-Horn inequalities [9]\nLet A be a Hermitian k × k matrix with real eigenvalues λ 1 (A) ≥ λ 2 (A) ≥ · · · ≥ λ k (A). Then, for any 1 ≤ i 1 < i 2 < · · · < i l ≤ k,\nwhere a 11 , . . . , a kk are the diagonal entries of A. Particularly, for l = 1 and l = k we obtain\nAnother basic question in linear algebra asks the degree to which the eigenvalues of two Hermitian matrices constrain the eigenvalues of their sum. Weyl\u2019s theorem gives an answer to this question in the following set of inequalities.\nLet A and B be two Hermitian k × k matrices with spectrums {λ 1 (A), . . . , λ k (A)} and {λ 1 (B), . . . , λ k (B)}, respectively. Then, for i, j ≤ k, we have\nλ i (A + B) ≤ λ j (A) + λ i−j+1 (B) \t for j ≤ i, (6) λ i (A + B) ≥ λ j (A) + λ k+i−j (B) \t for j ≥ i. (7)\nIII. DFT F RAMES A. BCH-DFT Codes\nDFT codes [5], are linear block codes over the complex ﬁeld whose parity-check matrix H is deﬁned based on the DFT matrix. A Bose-Chaudhuri-Hocquenghem (BCH) DFT code is a DFT code that insert d − 1 cyclically adjacent zeros in the spectrum of any codevector where d is the designed distance of that code [10]. Real BCH-DFT codes, a subset of complex BCH-DFT codes, beneﬁt from a generator matrix with real entries. The generator matrix of an (n, k) real 2 BCH- DFT code is typically deﬁned by\nG = n k\n0 0 0 I β\nwhere α = n/2 − (n − k)/2 , β = k − α, and the sizes of zero blocks are such that Σ is an n × k matrix [11]. One can check that Σ H Σ = I k , and ΣΣ H is an n × n matrix given by\n0 0 0 0 0 I β\nOne can view the generator matrix G in (8) as an analysis frame operator. The following lemma presents some properties of GG H which are central for our results in the next section.\nLemma 1. Let G p×k be a matrix consisting of p arbitrary rows of G deﬁned by (8). Then, the following statements hold: i. GG H is a Toeplitz and circulant matrix\niii. All principal diagonal entries of G p×k G H p×k , 1 ≤ p ≤ n are equal to 1.\nProof: Let a r,s be the (r, s) entry of the matrix GG H then it can readily be shown that\na r,s = 1 k\nin which θ x = 2π n (x − 1). From this equation, it is clear that a r,s = a r+i,s+i ; that is, the elements of each diagonal are equal, which means that GG H is a Toeplitz matrix. In addition, we can check that a r,n = a r+1,1 , i.e., the last entry in each row is equal to the ﬁrst entry of the next row. This proves that the Toeplitz matrix GG H is circulant as well [12]. Also, a quick look at (13) reveals that the elements of the principal diagonal (r = s) are equal to 1. Similarly, one can see that for any 1 < p < n, the square matrix G p×k G H p×k is also a Toeplitz matrix; it is not necessarily circulant, however.\nRemoving W k from (8) we end up with a complex G, representing a complex BCH-DFT code. In such a code, α and β can be any nonnegative integers such that α + β = k.\nRemark 1. Lemma 1 also holds for complex BCH-DFT codes. As a result, all properties that we prove in the remainder of this paper are valid for \u201cany\u201d BCH-DFT code, although they are formally proved for \u201creal\u201d BCH-DFT codes, which we simply refer to as \u201cDFT codes\u201d or \u201cDFT frames\u201d hereafter.\nIn the context of channel coding, there is a special interest in systematic codes so as to simplify the decoding algorithm. This is more pronounced in \u201cparity-based\u201d DSC as it requires distinction between parity and data. The parity-based approach becomes even more worthwhile in the DSC that uses DFT codes because it is more \u201cefﬁcient\u201d than the syndrome-based approach [3]. This is due to the fact that syndrome, even in a real DFT code, is a complex vector whereas parity is real. This encourages a systematic generator matrix for DFT codes.\nA systematic generator matrix for a real BCH-DFT code can be obtained by [3]\nin which G k is a submatrix (subframe) of G including k arbitrary rows of G. Note that G k is invertible since it can\nbe represented as G k = n k W H k×n ΣW k = V H k W k , in which V H k \t n k W H k×n Σ is a Vandermonde matrix. Remember that W k is also invertible as it is a DFT matrix. This proves that systematic DFT frames exist for any DFT frame. It also shows that there are many (but, a ﬁnite number of) systematic frames for each frame, because the rows of G k can be arbitrarily chosen from those of G. These systematic frames differ in the \u201cposition\u201d of systematic samples (input data) in resulting codewords. This implies that the parity samples are not restricted to form a consecutive block in codewords. Such a degree of freedom is useful in the sense that one can ﬁnd the most suitable systematic frames for speciﬁc applications (e.g., one with the smallest reconstruction error.)\nFrom rate-distortion theory, it is well known that the rate required to transmit a source, with a given distortion, in- creases as the variance of the source becomes larger [13]. Particularly, for Gaussian sources this relation is logarithmic with variance, under the mean-squared error (MSE) distortion measure. In DSC that uses real-number codes [3], since coding is performed before quantization, the variance of transmitted sequence depends on the behavior of the encoding matrix. In view of rate-distortion theory, it makes a lot of sense to keep this variance as small as possible. Not surprisingly, we will show that using a tight frame (tight G sys ) for encoding is optimal.\nLet x be the message vector and y = G sys x represent the codevector generated using the systematic frame, then the variance of y is given as\n= n k\nin which λ 1 ≥ λ 2 ≥ · · · ≥ λ k > 0 are the eigenvalues of G k G H k (or V H k V k equivalently).\nThis shows that the variance of codevectors, generated by a systematic frame, depends on the submatrix G k which is used to create G sys . G k , in turn, is fully known once the position of systematic (data) samples is ﬁxed in the codevector. In other words, the \u201cposition\u201d of systematic samples, determines the variance of codevectors generated by a systematic DFT frame. From (15), (16), to minimize the effective range of transmitted signal, we need to do the following optimization problem.\nwhere, the constraint k i=1 λ i = k is achieved in light of Lemma 1 and (5).\nBy using the Lagrangian method, we can show that the optimal eigenvalues are λ i = 1; this implies a tight frame [2]. In the sequel, we analyze the eigenvalues of G p×k G H p×k , p ≤ n, that helps us characterize tight systematic frames, so as to minimize the variance of transmitted codevectors.\nTheorem 1. Let G p×k , 1 ≤ p ≤ n be any p × k submatrix of G. Then, the smallest eigenvalue of G p×k G H p×k is no more than one, and the largest eigenvalue of G p×k G H p×k is at least one.\nProof: From Lemma 1, we know that all principal diag- onal entries of G p×k G H p×k are unity. As a result, using the Schur-Horn inequality in (4), we obtain λ min (G p×k G H p×k ) ≤ 1 ≤ λ max (G p×k G H p×k ). This proves the claim. Also, note that\nWe use the above results to ﬁnd better bounds for the extreme eigenvalues of G k G H k in the following theorem.\nTheorem 2. For any G k , a square submatrix of G in (8) in which n = M k, the smallest (largest) eigenvalue of G k G H k is strictly upper (lower) bounded by 1.\nProof: We ﬁrst investigate a bound for the smallest eigenvalue. Let n = M k + l, 0 < l < k, then G can be partitioned as G = [G H k | G 1H k | · · · | G (M −1)H k \t | G M H k×l ] H . In general, G k , G 1 k , . . . , G M −1 k \t and G M k×l include arbitrary rows of G, hence they have different spectrums, i.e., different sets of eigenvalues. We consider the case with largest λ k for G H k G k ; this occurs when G k consist of the rows of G such that the distance between each two successive rows is as large as possible and at least M . The latter guarantees existence of G 1 k , . . . , G M −1 k \t such that G mH k G m k , for any 1 ≤ m ≤ M − 1, has the same spectrum as G H k G k . To ﬁnd the row indices corresponding to G m k , we can simply add m to each row index of G k . Then, to show these matrices have the same spectrum, we use Lemma 3 [8] which states that any Hermitian n × n matrices E and F with F i,j = c i c\nE i,j have the same eigenvalues. Now, given a G k , one can verify that (G 1 k ) i,j = a j (G k ) i,j and thus (G 1 k ) H i,j = a ∗ i (G k ) H i,j = 1/a i (G k ) H i,j . Therefore, G 1H k G 1 k and G H k G k have the same spectrum. The same argument is valid for G 2 k , . . . , G M −1 k . Next, we see that G H G = A + B in which A = G H k G k + · · · + G (M −1)H k \t G M −1 k\nand B = G M H k×l G M k×l . Then, in consideration of the above discussion, λ i (A) = M λ i (G H k G k ) for any 1 ≤ i ≤ k. Hence, from (7), for i = 1, j = k, we will have\nwhere the last line follows using λ 1 (B) ≥ 1 from Theorem 1. This completes the proof for the worst case, i.e., the largest possible λ k (G H k G k ), and implies that (18) holds for any other\nG k . Hence, the ﬁst part of the proof is completed; that is, the smallest eigenvalue of G H k G k where G k is an arbitrary square submatrix of G in (8) with n = M k is strictly less than one.\nFinally, knowing that k i=1 λ i (G H k G k ) = k i=1 a ii = k and using (18), it is obvious that λ 1 (G H k G k ) > 1. This proves the bound for the largest eigenvalue.\nTheorem 2 implies that for n = M k we cannot have \u201ctight\u201d systematic frames. This is due to the fact that for a tight frame with frame operator F , λ min (F H F ) = λ max (F H F ); i.e., the eigenvalues of F H F are equal [2].\nCorollary 1. For n = M k, where M is a positive integer, \u201ctight\u201d systematic DFT frames do not exist.\nNote that systematic DFT frames are not necessarily tight for n = M k. Evaluating the performance of systematic frames in the next section, we prove that tight systematic DFT frames exist for n = M k and show how to construct such frames.\nIn this section, we analyze the performance of quantized systematic DFT codes using the quantization model proposed in [2], which assumes that noise components are uncorrelated and each noise component q i has mean 0 and variance σ 2 q . We assume the quantizer range covers the dynamic range of all codevectors encoded using the systematic DFT code in (14).\nThe codevectors are generated by y = G sys x. We also con- sider linear reconstruction of x form y using the pseudoinverse [2] of G sys , which is deﬁned as G \u2020 sys = (G H sys G sys ) −1 G H sys . It is easy to check that G \u2020 sys = k n G k G H , then the linear reconstruction is given by\nNow, suppose we want to estimate x from ˆ y = G sys x + q, where q represents quantization error. From (19) we obtain\nThen, the mean-squared reconstruction error, due to the quan- tization noise, using a systematic frame can be written as\nwhere the last step follows because of Lemma 1. The above analysis indicates that the MSE is the same for all systematic\nDFT frames of same size, provided that the effective range codevectors generated by different G sys is equal. This implies a same σ 2 q for a given number of quantization levels. However, for a ﬁxed number of quantization levels, σ 2 q depends on the variance of transmitted codevectors, which, in turn, varies for different systematic frames, as shown in (15).\nAs we discussed in Section IV, the optimal G sys is achieved from the optimization problem (17). Similarly, to ﬁnd the worst G sys , we can maximize (17) instead of minimizing it. The optimal eigenvalues are known to be λ i = 1. But, how can we ﬁnd the corresponding G sys , or G k equivalently?\nWe approach this problem by studying another optimization problem. By using the Lagrangian method, one can check the optimal arguments of the optimization problem in (17) are equal to those of\nin which {λ i } k i=1 are the eigenvalues of G k G H k (or V H k V k ). In other words, subject to the above constraints\nProblem (22) has the maximum of 1 and inﬁmum of 0. Then, considering that k i=1 λ i = det(V H k V k ) = det(G k G H k ), we conclude that the \u201cbest\u201d submatrix is the one with the largest determinant (possibly 1) and the \u201cworst\u201d submatrix is the one with smallest determinant. Next, we evaluate the determinant of V H k V k so as to ﬁnd the matrices corresponding to these extreme cases.\nIn this section, we ﬁrst evaluate the determinate of W W H where W is the Vandermonde matrix with unit complex entries as deﬁned in (1). From (2) we can write\nin which θ x = 2π n (x − 1), r = q − p, and n(n − 1)/2 is the total number of terms that satisfy 1 ≤ p < q ≤ n. But, we see that W is a DFT matrix, and thus, its determinant must be 1. Therefore, we have\nThe above analysis helps us evaluate the determinant of V k or G k , deﬁned in (14). Let I r = {i r 1 , i r 2 , . . . , i r k } be those rows of G used to build G k . Also, without loss of generality,\nassume i r 1 < i r 2 < · · · < i r k . Clearly, i r 1 ≥ 1, i r k ≤ n, and we obtain\nThen, since sin π n u = sin π n (n − u), one can see that this determinant depends on the circular distance between rows in I r . For a matrix with n rows, we deﬁne the circular distance between rows p and q as min {|q − p|, n − |q − p|}. In this sense, for example, the distance between rows 1 and n is one, i.e., they are circularly successive. Now, we can see that (26) is minimized when the selected rows are (circularly) successive. Note that sin u is strictly increasing for u ∈ [0, π/2] and the circular distance cannot be greater than n/2, in this problem.\nIn such circumstances where all rows in I r are (circularly) successive, (26) is minimal and reduces to\nsin 2 π n\nThe other extreme case comes up when n = M k (M is a positive integer) provided that G k consists of every M th row of G. In such a case (26) simpliﬁes to 1 because\nwhere the last step follows from (25). Recall that this gives the best V k (and equivalently G k ), in light of (22). For such a G k , it is easy to see that G sys stands for a \u201ctight\u201d systematic frame and minimizes the MSE for a given number of quantization levels. Effectively, such a frame is performing integer oversampling . There are M such frames; they all have the same spectrum, though.\nNumerical calculations conﬁrm that \u201cevenly\u201d spaced data samples gives rise to systematic frames with the best perfor- mance. When a systematic code is doing integer oversampling, we end up with tight systematic frames. The ﬁrst code in Table I is an example of this case. When n = M k, data samples cannot be equally spaced; however, as it can be seen from the second code in Table I, still the best performance is achieved when they are as equally spaced as possible. Note that, circular shift of codewords pattern does not change the spectrum of corresponding matrices. For example, in the (7, 5) code, frames with pattern × − × × × − × and × × − × × − × have the same properties. Also, reversal of a frame yields a frame with similar properties (e.g., × × − × −− is shifted version of reversed × × − − ×−).\nSystematic DFT frames as well as the approach to make such a frame out of the generator matrix of a BCH-DFT code has been introduced. Further, we found the conditions for which a systematic DFT frame can be tight, too. We then related the performance of these frames to the position of systematic samples in the codevector. The analysis shows that evenly spaced systematic (parity) samples result in the minimum reconstruction error, whereas the worst performance is achieved when systematic samples are circularly successive. Finally, we found the conditions for which a DFT frame becomes both systematic and tight."},"refs":[{"authors":[{"name":"J. Kovacevic"},{"name":"A. Chebira"}],"title":{"text":"Life beyond bases: The advent of frames (Part I)"}},{"authors":[{"name":"V. K. Goyal"},{"name":"J. Kovacevic"},{"name":"J. A. Kelner"}],"title":{"text":"Quantized frame expan- sions with erasures"}},{"authors":[{"name":"M. Vaezi"},{"name":"F. Labeau"}],"title":{"text":"Distributed lossy source coding using real- number codes"}},{"authors":[{"name":"G. Rath"},{"name":"C. Guillemot"}],"title":{"text":"Frame-theoretic analysis of DFT codes with erasures"}},{"authors":[{"name":"T. Marshall Jr."}],"title":{"text":"Coding of real-number sequences for error correction: A digital signal processing problem"}},{"authors":[{"name":"S. K. Mitr"},{"name":"Y. Ku"}],"title":{"text":"Digital Signal Processing: A Computer-Based Approach "}},{"authors":[{"name":"G. H. Tucci"},{"name":"P. A. Whiting"}],"title":{"text":"Asymptotic results on generalized vandermonde matrices and their extreme eigenvalues"}},{"authors":[{"name":"G. H. Tucci"},{"name":"P. A. Whiting"}],"title":{"text":"Eigenvalue results for large scale random vandermonde matrices with unit complex entries"}},{"authors":[{"name":"G. A. F. Sebe"}],"title":{"text":"A Matrix Handbook for Statisticians"}},{"authors":[{"name":"R. E. Blahu"}],"title":{"text":"Algebraic Codes for Data Transmission"}},{"authors":[{"name":"A. Gabay"},{"name":"M. Kieffer"},{"name":"P. Duhamel"}],"title":{"text":"Joint source-channel coding using real BCH codes for robust image transmission"}},{"authors":[{"name":"R. M. Gra"}],"title":{"text":"Toeplitz and Circulant Matrices: A Review"}},{"authors":[{"name":"T. M. Cove"},{"name":"J. A. Thoma"}],"title":{"text":"Elements of Information Theory"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569563721.pdf"},"links":[{"id":"1569566381","weight":8},{"id":"1569565663","weight":8},{"id":"1569565377","weight":8},{"id":"1569565355","weight":8},{"id":"1569551535","weight":4},{"id":"1569566765","weight":13},{"id":"1569564897","weight":4},{"id":"1569565461","weight":8},{"id":"1569564227","weight":8},{"id":"1569566303","weight":8},{"id":"1569560613","weight":8},{"id":"1569566999","weight":8},{"id":"1569565859","weight":4},{"id":"1569558483","weight":8},{"id":"1569566963","weight":8},{"id":"1569566709","weight":8},{"id":"1569566905","weight":8},{"id":"1569561143","weight":8},{"id":"1569566687","weight":8},{"id":"1569566209","weight":4},{"id":"1569558985","weight":8},{"id":"1569566473","weight":4},{"id":"1569566721","weight":8},{"id":"1569555879","weight":8},{"id":"1569565219","weight":8},{"id":"1569556671","weight":8},{"id":"1569566223","weight":8},{"id":"1569566191","weight":8},{"id":"1569566051","weight":4},{"id":"1569566245","weight":4},{"id":"1569566229","weight":4},{"id":"1569566133","weight":8},{"id":"1569563395","weight":8},{"id":"1569551347","weight":8},{"id":"1569565549","weight":8},{"id":"1569565611","weight":8},{"id":"1569565397","weight":8},{"id":"1569565765","weight":8},{"id":"1569565435","weight":8},{"id":"1569565661","weight":4},{"id":"1569566253","weight":8},{"id":"1569566237","weight":8},{"id":"1569566755","weight":4},{"id":"1569566771","weight":8},{"id":"1569564247","weight":4},{"id":"1569551905","weight":8},{"id":"1569556759","weight":8},{"id":"1569565669","weight":8},{"id":"1569564923","weight":8},{"id":"1569564769","weight":8},{"id":"1569561713","weight":4},{"id":"1569566933","weight":8},{"id":"1569565389","weight":13},{"id":"1569560459","weight":8},{"id":"1569565853","weight":8},{"id":"1569564505","weight":8},{"id":"1569565165","weight":8},{"id":"1569565731","weight":4},{"id":"1569566375","weight":4},{"id":"1569564141","weight":8}],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S13.T9.1","endtime":"15:00","authors":"Mojtaba Vaezi, Fabrice Labeau","date":"1341499200000","papertitle":"Systematic DFT Frames: Principle and Eigenvalues Structure","starttime":"14:40","session":"S13.T9: Fourier Subsampling","room":"Stratton West Lounge (201)","paperid":"1569563721"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
