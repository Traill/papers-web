{"id":"1569566619","paper":{"title":{"text":"On Linear Transforms in Zero-delay Gaussian Source Channel Coding"},"authors":[{"name":"Emrah Akyol"},{"name":"Kenneth Rose"}],"abstr":{"text":"Abstract\u2014This paper is concerned with the optimal linear transforms in zero-delay source channel coding for Gaussian sources and channels. In preparation for the main results, we ﬁrst consider the classical problem in the point-to-point setting, which had already been solved by Lee and Petersen, where we provide an alternative proof using majorization. We then analyze the performance of linear source-channel coding in the low signal- to-noise ratio (SNR) regime. We show that at asymptotically low SNR, or equivalently as the power tends to zero, the power- distortion function of zero delay linear coding achieves optimum theoretically achievable performance. Finally, we consider zero- delay source-channel coding with decoder side information. Here, subject to structural constraints on the encoder, we ﬁnd the optimal encoder-decoder pair in closed form. We analyze two structures: i) the encoder is constrained to be linear where we show that the optimal transform is product of matrices including as factor the conditional Karhunen Lo´eve transform (KLT) of the source given the side information. ii) the encoder consists of linear transformation followed by individual optimal nonlinear mapping of each transform coefﬁcient. Using majorization principles, we show that the optimal transform does not depend on the nonlinearities introduced, as long as they are scale invariant, hence the optimal transform is also a product involving the conditional KLT of the source.\nIndex Terms\u2014Linear transforms, zero delay source-channel coding"},"body":{"text":"Zero delay source channel coding has attracted much recent interest [1]\u2013[6] due to its low complexity and zero delay advantages, and also due to the fact that it provides graceful degradation with channel signal to noise ratio (SNR) mis- match. Most prior efforts were focused on mapping optimiza- tion at low dimensions, eg., mapping two source samples to one channel symbol, due to the complexity of such optimiza- tions. In this work, we consider tractable generalization to multi-dimensional settings via structured mappings.\nThe problem of zero delay linear source-channel codes was previously studied by Lee and Petersen [7], where the optimal encoding transform was found to be the product of three matrices, the Karhunen Lo´eve transform (KLT) of the source, a diagonal scaling matrix, and the KLT of the channel. We ﬁrst revisit this problem from a different perspective and provide an alternative proof, based on the majorization theory, that gives new insights on this problem and its extensions.\nOne of our main results pertains to the asymptotic opti- mality of zero-delay linear coding at the low SNR regime.\nA motivating factor for considering the low SNR regime in communications, is that the absolute value of the slope of the capacity-cost function is large, which indicates that one achieves the most channel capacity per unit cost at low SNR, as was shown by Verdu [8]. In [9], it was shown that at low SNR, the optimal estimator converges to linear, for a Gaussian channel, regardless of the density of the source. Recently, Ostergaard and Zamir combined the results in [9], and the incremental channel method introduced in [10], to analyze the additive rate distortion function [11] at the low SNR regime. Our main result here establishes the ﬁrst order optimality of linear coding at low SNR. We show that asymptotically, at low channel SNR, the power-distortion function of the zero delay linear coding approaches the unbeatable power- distortion bound. In other words, zero-delay linear coding is asymptotically (at low SNR) optimal. To the best of our knowledge, this perhaps surprising fact has not been previously known.\nNext, we study zero-delay linear source-channel coding within the decoder side information setting. We show that the optimal encoding transform is the product of the \u201cconditional\u201d KLT of the source, a diagonal power allocation matrix and the KLT of the channel. It is a \u201cconditional\u201d relative of the seminal result in the point-to-point setting.\nFinally, we analyze the optimal linear transforms for a struc- tured nonlinear zero-delay mapping: a linear code followed by nonlinear \u201cscalar\u201d mappings for each transform coefﬁcient (channel). We show, using majorization tools, that the optimal linear transform remains the same, and hence surprisingly does not depend on the subsequent nonlinearities, as long as these nonlinear mappings are scale invariant.\nThis paper is organized as follows: In Section II, we provide a brief review of the known results in matrix analysis and majorization theory. In Section III, we present an alternative proof for the well known point-to-point result. In Section IV, we study the optimality of the linear schemes. Section V presents the results in the decoder side information setting. Discussions are presented in Section VI.\nIn general, lowercase letters (e.g., c) denote scalars, boldface lowercase (e.g., x) vectors, uppercase (e.g., C, X) matrices and random variables. I denotes the identity matrix. E[·], R X , and R XZ denote the expectation, auto-covariance of X and\ncross covariance of X and Z respectively. A T denotes the transpose of matrix A. (x) + denotes the function max(0, x).\nThroughout this paper, we assume that the source is an m- dimensional Gaussian with zero mean and covariance R X . The channel noise is additive k-dimensional Gaussian, of zero mean and covariance R N . Covariance matrices R X and R N allow the diagonalization\nwhere Q X Q T X = Q N Q T N = I and Λ X and Λ N are diagonal matrices, having ordered eigenvalues as entries, i.e., Λ X = diag{λ X (1), λ X (2), ..., λ X (m)} and Λ N = diag{ λ N (1), λ N (2), ..., λ N (k)} where λ X (1) ≥ λ X (2) ≥ , ..., ≥ λ X (n) and λ N (1) ≥ λ N (2) ≥, ..., ≥ λ N (k). Q T X\nand Q T N are the KLT matrices of the source and the channel, respectively.\nSimilarly, let us deﬁne the covariance of the prediction error of the optimal linear predictor of X given observation Z\nSince R X|Z is a covariance matrix, it allows the eigendecom- position:\nwhere Q X|Z Q T X|Z = Q T X|Z Q X|Z = I and Λ X|Z is a diagonal matrix with ordered eigenvalues as entries. Q T X|Z is also referred as conditional KLT of X ∈ R m with respect to Z ∈ R k [12].\nwhere A, B, C are matrices of appropriately matching dimen- sions.\nThis paper builds on the results from majorization theory. Let us introduce the basic notion of majorization and state some important auxiliary results that will be of use later (see [13] for complete reference on majorization). Roughly speak- ing majorization measures how spread out the components of a vector is. Let x ∈ R m be such that x(1) ≥ x(2) ≥ ... ≥ x(m).\nSchur concave functions: A real valued function f is said to be Schur-concave if and only if\nWe reproduce the following well known result, without proof, see eg. [13].\nLemma 1. Let be A a Hermitian matrix with ordered diagonal elements denoted by the vector a and ordered eigenvalues denoted by the vector λ. Then λ a.\nwhere K is the space of k × m matrices K that satisfy the constraint\nwhere Φ is a symmetric, positive deﬁnite m × m matrix, is a diagonal k × m matrix.\nProof: Since variants of this result appeared before [14], we only provide a sketch of the proof for brevity. We ﬁrst note, using the matrix inversion lemma [15], that\nGiven the fact that T r Λ X (I + K T K) −1 is a Schur- concave function of the vector consisting the diagonal ele- ments of K and that the constraint is convex, it follows that the objective is minimized when K is diagonal, due to Lemma 1 [14].\nThe problem setting, depicted in Figure 1-a, can be stated as the following optimization problem: ﬁnd the encoder and decoder matrices, C and B that minimize distortion, D = E{||(X − ˆ X|| 2 }, subject to the power constraint E ||Y || 2 ≤ P where Y = CX. Recall that this is the classical problem solved in the seminal paper of Lee and Petersen [7]. Our approach gives an alternative proof as well as some new results. Also note that a general framework for solving such convex problems was presented in [14].\nTheorem 1. The encoding transform that minimizes the MSE distortion subject to the power constraint P is\nwhere Σ is diagonal power allocation matrix. Moreover the total distortion is\nwhere w is the number of active channels determined by the power P .\nProof: Using orthogonality, E (X − ˆ X ) ˆ X T = 0 we have\nNoting that the optimal decoder is ˆ X = R X ˆ Y R −1 ˆ Y ˆ Y . Plugging ˆ Y = CX + N, we have\nD =T r Λ X − Λ X Q T X C T (CQ X Λ X Q T X C T + Q N Λ N Q T N ) −1 CQ X Λ X } \t (18)\nUsing Lemma 2, we obtain that K is diagonal, hence C = Q N ΣQ T X where Σ is diagonal. The entries of Σ and the dis- tortion, (12), can be obtained applying Kuhn-Tucker necessary conditions for each scalar channel.\nIn this section, we derive the conditions under which zero delay linear coding achieves the asymptotic performance bound which overall would require asymptotic delay.\nTo obtain asymptotically (in delay) achievable bounds, we have to consider the rate distortion function and channel capacity. In this section, we assume R X = I for simplicity.\n1) Channel capacity: The capacity of k-dimensional Gaus- sian channel with covariance matrix R N with total power P is given parametrically as\nfor some µ ≥ 0, where we use natural logarithm for conve- nience.\n2) Rate-distortion: The rate distortion function for the m-dimensional Gaussian source with covariance matrix R X under mean square error distortion measure is given by the inverse water-ﬁlling formula\n1 2\nfor some θ ≥ 0. Plugging R X = I in the above expressions, we get\nm } \t (24) B. First Order Optimality\nHere, we present our main result on ﬁrst order optimality of zero-delay linear source-channel coding for Gaussian sources and channels.\nTheorem 2. For a m-dimensional Gaussian source with R X = I and k-dimensional Gaussian channel, as P → 0, linear coding achieves the (asymptotic) OPTA in ﬁrst order, i.e.,\nProof: The key observation here is that as P → 0, the active channels must have the same eigenvalue. Let us call this eigenvalue λ N . Also, the number of active channels will be identical in asymptotic and zero-delay coding. Let w be the number of active channels, then we have\nIn this section, we focus on the settings where side infor- mation is available to the decoder. The ﬁrst result derives the optimal encoding and decoding matrices in the side informa- tion setting. Next, we allow scalar nonlinearities per transform coefﬁcient, and obtain the optimal encoding and decoding matrices.\nConsider the setting shown in Figure 1-b. The following theorem states that the optimal encoding transform C is the product of the conditional KLT of the source given the side information, a diagonal power allocation matrix and the KLT of the noise.\nTheorem 3. The encoding transform that minimizes the MSE distortion, subject to a power constraint is\nProof: It follows from standard linear estimation princi- ples [16] that\n−1 CX +N Z\nWe make use of an auxiliary lemma from matrix analysis [15]. Lemma 3 (Schur\u2019s complement). Let U, V, A, B, C be matri- ces of appropriate dimensions. Then, the following holds:\nU V\nT \t A \t B B T C\nwhere Φ = Λ −1/2 X|Z Q T X|Z R X Q X|Z Λ −1/2 X|Z is symmetric and positive deﬁnite. Applying Lemma 2, we obtain the result.\nIn this section, we allow scalar nonlinearities in the problem deﬁnition. Unlike the point-to-point case, the optimal zero- delay scalar mappings for the point-to-point setting are highly nonlinear in the side information setting. In [4], [5] an algo- rithm was proposed to ﬁnd such mappings for this setting. Figure 2 presents examples of such encoding mappings. Inter- estingly, the analog mapping captures the central characteristic observed in digital Wyner-Ziv mappings, in the sense of many- to-one mappings, or multiple source intervals are mapped to the same channel interval, which will potentially be resolved by the decoder given the side information. Within each bin, there is a mapping function which is approximately linear in this case (scalar Gaussian sources and channel).\nHere we consider generalizing this highly non-linear scalar mapping to vector spaces. This generalization, albeit being algorithmically infeasible, can be done through a structured combination of linear m to k mapping followed by scalar nonlinear functions, as illustrated in Figure 1-c. The i th transform coefﬁcient is nonlinearly transformed through the mapping g i and it is estimated through another nonlinear mapping h i . The problem of interest here is ﬁnding the optimal linear transforms, which, in general, might depend on the nonlinearities introduced. For simplicity, we assume R N = I.\nThe following theorem states that if the functions are scale invariant, the optimal transform is identical to the case where no nonlinearities were present, hence it does not depend on the nonlinearities. Let us deﬁne scale invariance in our context.\nLet { g 1 , g 2 , ...} : R → R be a set of functions. If for all i, j, g i (x) = βg j (αx), for some α, β ∈ R then we call these functions as scale invariant. Note that if we use these functions as encoding mappings in conjunction with the associated optimal decoding mappings, the distortion depend on the source variance only through scaling, in other words in the power distortion function can be expressed as D = σ 2 X f (P ), where function f is independent of σ 2 X .\nIn passing, we note that Ziv showed the optimal encoding mappings cannot be scale invariant for the point-to-point\nsetting, other than the trivial scalar Gaussian source-channel case [17]. We conjecture, based on the observations from our experimental results in [5], that for Gaussian source, channel and side information, the optimal mappings are scale invariant. Theorem 4. In the setting where g i \u2019s are scale invariant, the encoding transform that minimizes MSE distortion is\nProof: From matrix differentiation, it follows that the optimal transform must be in the form C = ΣS where S is a unitary matrix, and Σ is diagonal. Now, we will show that S = Q T X|Z . Let P = [P 1 , P 2 , .., P k ] be the power allocation vector. It follows from scale invariance that D i = σ 2 Y\nf (P i ) for each Y i . Then, the problem is to minimize the function\nNote that SR X|Z S T has eigenvalues λ X|Z . From Lemma 1, we know that λ X|Z majorizes σ. This implies that σ is in the convex hull of k! permutations of λ X|Z . Hence, our objective is to minimize D over the convex polytope deﬁned by the permutations of λ X|Z . Note that D is linear in σ i . It is well known that the corner point minimizes a linear function over a convex polytope, i.e., σ = λ X|Z will minimize (37). This establishes that the optimal transform is a conditional KLT, i.e., S = Q T X|Z .\nRemark 1. This results is perhaps surprising in that al- though the transform effects the particular nonlinear mapping employed, via changing the correlation between Y i and Z, optimal transform remains S = Q T X|Z as in Theorem 3.\nRemark 2. The linear coding scheme in the previous section is a special case of this setting with the trivial identity mappings, g i (x) = h i (x) = x, ∀i. Hence, the proof of Theorem 4 also implies Theorem 3 when R N = I.\nRemark 3. The nonlinear coding scheme can also be ex- tended to the case with R N = I, with the help of a linear transformation of the outputs of the scalar nonlinear functions. Such optimal transform would be Q N . Detailed extensions are omitted due to space constraints.\nIn this paper, we presented several results regarding linear zero-delay source-channel coding. First, using the majorization tools, we presented an alternative solution to the classical problem in the point-to-point setting. Next, we showed that zero-delay linear source channel coding achieves OPTA in the ﬁrst order at asymptotically low SNR. We then studied the optimal linear transform for the side information setting and\nshowed that, similar to the point-to-point setting, the optimal linear transform is conditional KLT of the source, followed by a diagonal power allocation matrix and the channel noise KLT. Finally, we considered a practical structured nonlinear mapping, as the combination of a linear transform with scalar nonlinearities. We showed that the optimal linear transform is independent of the the scalar nonlinear mappings as long as these mappings are scale invariant."},"refs":[{"authors":[{"name":"X. Chen"},{"name":"E. Tuncel"}],"title":{"text":"Zero-delay joint source-channel coding for the Gaussian Wyner-Ziv problem"}},{"authors":[{"name":"F. Hekland"},{"name":"A. Floor"},{"name":"A. Ramstad"}],"title":{"text":"Shannon-Kotelnikov mappings in joint source-channel coding"}},{"authors":[{"name":"M. Kleiner"},{"name":"B. Rimoldi"}],"title":{"text":"A tight bound on the performance of a minimal-delay joint source-channel coding scheme"}},{"authors":[{"name":"J. Karlsson"},{"name":"M. Skoglund"}],"title":{"text":"Optimized low-delay source-channel- relay mappings"}},{"authors":[{"name":"E. Akyol"},{"name":"K. Rose"},{"name":"T. Ramstad"}],"title":{"text":"Optimized analog mappings for distributed source-channel coding"}},{"authors":[{"name":"N. Khormuji"},{"name":"M. Skoglund"}],"title":{"text":"On instantaneous relaying"}},{"authors":[{"name":"H. Lee"},{"name":"D. Petersen"}],"title":{"text":"Optimal linear coding for vector channels"}},{"authors":[{"name":"S. Verdu"}],"title":{"text":"On channel capacity per unit cost"}},{"authors":[{"name":"E. Akyol"},{"name":"K. Viswanatha"},{"name":"K. Rose"}],"title":{"text":"On conditions for linearity of optimal estimation"}},{"authors":[{"name":"D. Guo"},{"name":"S. Shamai"},{"name":"S. Verd´u"}],"title":{"text":"Mutual information and minimum mean-square error in Gaussian channels"}},{"authors":[{"name":"J. Ostergaard"},{"name":"R. Zamir"}],"title":{"text":"Incremental reﬁnement using a Gaussian test channel"}},{"authors":[{"name":"M. Gastpar"},{"name":"L. Dragotti"},{"name":"M. Vetterli"}],"title":{"text":"The distributed Karhunen- Lo`eve transform"}},{"authors":[{"name":"I. Olki"}],"title":{"text":"AW Marshall and  Inequalities: Theory of Majorization and Its Applications , Academic Press, New York, 1979"}},{"authors":[{"name":"P. Palomar"},{"name":"M. Ciofﬁ"},{"name":"A. Lagunas"}],"title":{"text":"Joint TX-RX beamform- ing design for multicarrier MIMO channels: A uniﬁed framework for convex optimization"}},{"authors":[{"name":"A. Hor"},{"name":"R. Johnso"}],"title":{"text":"R"}},{"authors":[{"name":"T. Kailath"},{"name":"H. Sayed"},{"name":"B. Hassibi"}],"title":{"text":"Linear Estimation"}},{"authors":[{"name":"J. Ziv"}],"title":{"text":"The behavior of analog communication systems"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569566619.pdf"},"links":[{"id":"1569566381","weight":5},{"id":"1569565383","weight":5},{"id":"1569565223","weight":2},{"id":"1569566725","weight":2},{"id":"1569565377","weight":2},{"id":"1569566385","weight":5},{"id":"1569564635","weight":2},{"id":"1569566799","weight":5},{"id":"1569565067","weight":5},{"id":"1569559665","weight":2},{"id":"1569564669","weight":2},{"id":"1569566875","weight":2},{"id":"1569559617","weight":5},{"id":"1569566981","weight":2},{"id":"1569566605","weight":2},{"id":"1569566683","weight":10},{"id":"1569566227","weight":5},{"id":"1569566091","weight":2},{"id":"1569566697","weight":8},{"id":"1569566943","weight":13},{"id":"1569566591","weight":2},{"id":"1569552245","weight":5},{"id":"1569564481","weight":2},{"id":"1569566415","weight":2},{"id":"1569566469","weight":5},{"id":"1569566081","weight":8},{"id":"1569565355","weight":5},{"id":"1569565547","weight":2},{"id":"1569565461","weight":10},{"id":"1569564245","weight":2},{"id":"1569564227","weight":5},{"id":"1569566119","weight":2},{"id":"1569564233","weight":8},{"id":"1569563411","weight":2},{"id":"1569559541","weight":8},{"id":"1569566319","weight":2},{"id":"1569565123","weight":5},{"id":"1569558459","weight":2},{"id":"1569565291","weight":2},{"id":"1569564203","weight":5},{"id":"1569566751","weight":2},{"id":"1569566467","weight":2},{"id":"1569565771","weight":8},{"id":"1569566157","weight":2},{"id":"1569560613","weight":2},{"id":"1569566903","weight":2},{"id":"1569566999","weight":8},{"id":"1569565859","weight":2},{"id":"1569558483","weight":2},{"id":"1569565455","weight":8},{"id":"1569566497","weight":2},{"id":"1569566963","weight":5},{"id":"1569564989","weight":8},{"id":"1569566523","weight":2},{"id":"1569565897","weight":2},{"id":"1569564189","weight":2},{"id":"1569566985","weight":2},{"id":"1569566905","weight":2},{"id":"1569566753","weight":2},{"id":"1569558681","weight":5},{"id":"1569559995","weight":2},{"id":"1569565213","weight":2},{"id":"1569566511","weight":2},{"id":"1569565841","weight":2},{"id":"1569566531","weight":5},{"id":"1569567665","weight":2},{"id":"1569564611","weight":2},{"id":"1569565667","weight":2},{"id":"1569561795","weight":2},{"id":"1569566423","weight":2},{"id":"1569567015","weight":2},{"id":"1569566437","weight":2},{"id":"1569559111","weight":2},{"id":"1569562285","weight":2},{"id":"1569565427","weight":2},{"id":"1569552251","weight":2},{"id":"1569553519","weight":2},{"id":"1569566231","weight":2},{"id":"1569554971","weight":5},{"id":"1569566209","weight":2},{"id":"1569562821","weight":2},{"id":"1569566909","weight":2},{"id":"1569564333","weight":2},{"id":"1569566629","weight":2},{"id":"1569566257","weight":2},{"id":"1569565033","weight":2},{"id":"1569566357","weight":2},{"id":"1569565055","weight":2},{"id":"1569564677","weight":2},{"id":"1569565633","weight":8},{"id":"1569555879","weight":2},{"id":"1569558509","weight":2},{"id":"1569566037","weight":2},{"id":"1569565095","weight":8},{"id":"1569566223","weight":2},{"id":"1569564969","weight":5},{"id":"1569565357","weight":2},{"id":"1569561245","weight":2},{"id":"1569566505","weight":2},{"id":"1569565393","weight":5},{"id":"1569562207","weight":2},{"id":"1569566191","weight":8},{"id":"1569567033","weight":2},{"id":"1569565527","weight":2},{"id":"1569566655","weight":2},{"id":"1569566673","weight":13},{"id":"1569565311","weight":2},{"id":"1569566233","weight":2},{"id":"1569566667","weight":2},{"id":"1569564097","weight":2},{"id":"1569566407","weight":2},{"id":"1569565463","weight":2},{"id":"1569565439","weight":2},{"id":"1569562551","weight":2},{"id":"1569563395","weight":2},{"id":"1569566901","weight":2},{"id":"1569551347","weight":2},{"id":"1569565415","weight":2},{"id":"1569555367","weight":2},{"id":"1569566383","weight":5},{"id":"1569565571","weight":2},{"id":"1569565885","weight":2},{"id":"1569566805","weight":2},{"id":"1569566929","weight":5},{"id":"1569566983","weight":8},{"id":"1569566097","weight":2},{"id":"1569566479","weight":2},{"id":"1569565397","weight":2},{"id":"1569566873","weight":5},{"id":"1569565435","weight":2},{"id":"1569566129","weight":8},{"id":"1569565093","weight":2},{"id":"1569565181","weight":2},{"id":"1569566711","weight":5},{"id":"1569565661","weight":5},{"id":"1569566267","weight":2},{"id":"1569564131","weight":2},{"id":"1569561221","weight":2},{"id":"1569566253","weight":2},{"id":"1569565353","weight":2},{"id":"1569566651","weight":2},{"id":"1569566823","weight":5},{"id":"1569566137","weight":5},{"id":"1569565013","weight":2},{"id":"1569565375","weight":5},{"id":"1569566755","weight":10},{"id":"1569566771","weight":2},{"id":"1569566641","weight":8},{"id":"1569559035","weight":5},{"id":"1569551905","weight":5},{"id":"1569564787","weight":2},{"id":"1569566487","weight":5},{"id":"1569565529","weight":2},{"id":"1569565271","weight":5},{"id":"1569561185","weight":5},{"id":"1569565669","weight":2},{"id":"1569566817","weight":13},{"id":"1569566389","weight":2},{"id":"1569566435","weight":5},{"id":"1569566299","weight":2},{"id":"1569564281","weight":5},{"id":"1569564769","weight":2},{"id":"1569563919","weight":2},{"id":"1569557851","weight":5},{"id":"1569567691","weight":2},{"id":"1569559919","weight":2},{"id":"1569566147","weight":2},{"id":"1569566057","weight":2},{"id":"1569566847","weight":5},{"id":"1569559597","weight":2},{"id":"1569567013","weight":2},{"id":"1569565337","weight":2},{"id":"1569550425","weight":5},{"id":"1569566341","weight":2},{"id":"1569565889","weight":2},{"id":"1569563725","weight":2},{"id":"1569565165","weight":2},{"id":"1569566375","weight":2},{"id":"1569565143","weight":2},{"id":"1569564257","weight":10},{"id":"1569564141","weight":2},{"id":"1569566973","weight":2},{"id":"1569566987","weight":2},{"id":"1569565031","weight":2},{"id":"1569564509","weight":2},{"id":"1569551541","weight":2},{"id":"1569566067","weight":2},{"id":"1569566825","weight":2},{"id":"1569566615","weight":2},{"id":"1569564807","weight":2},{"id":"1569566609","weight":2},{"id":"1569566113","weight":2},{"id":"1569566443","weight":5}],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S9.T4.1","endtime":"10:10","authors":"Emrah Akyol, Kenneth Rose","date":"1341395400000","papertitle":"On Linear Transforms in Zero-delay Gaussian Source Channel Coding","starttime":"09:50","session":"S9.T4: Joint Source-Channel Codes","room":"Stratton 20 Chimneys (306)","paperid":"1569566619"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
