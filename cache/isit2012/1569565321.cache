{"id":"1569565321","paper":{"title":{"text":"Analog Network Coding in General SNR Regime"},"authors":[{"name":"Samar Agnihotri"},{"name":"Sidharth Jaggi"},{"name":"Minghua Chen"}],"abstr":{"text":"Abstract\u2014The problem of maximum rate achievable with analog network coding for a unicast communication over a layered wireless relay network with directed links is considered. A relay node performing analog network coding scales and forwards the signals received at its input. Recently this problem has been considered under two assumptions: (A) each relay node scales its received signal to the upper bound of its transmit power constraint, (B) the relay nodes in speciﬁc subsets of the network operate in the high-SNR regime. We establish that assumption (A), in general, leads to suboptimal end-to-end rate. We also characterize the performance of analog network coding in a class of symmetric layered networks without assumption (B).\nThe key contribution of this work is a lemma that states that in a layered relay network a globally optimal set of scaling factors for the nodes that maximizes the end-to-end rate can be computed layer-by-layer. Speciﬁcally, a rate-optimal set of scaling factors for the nodes in a layer is the one that maximizes the sum-rate of the nodes in the next layer. This critical insight allows us to characterize analog network coding performance in network scenarios beyond those that can be analyzed using the existing approaches. We illustrate this by computing the maximum rate achievable with analog network coding in one particular layered network, in various communication scenarios."},"body":{"text":"Analog network coding (ANC) extends to multihop wireless networks the idea of linear network coding [1] where an inter- mediate node sends out a linear combination of its incoming packets. In a wireless network, signals transmitted simultane- ously by multiple sources add in the air. Each node receives a noisy sum of these signals, i.e. a linear combination of the received signals and noise. A multihop relay scheme where an intermediate relay node merely ampliﬁes and forwards this noisy sum is referred to as analog network coding [2], [3].\nThe performance of the analog network coding in layered relay networks is previously analyzed in [3], [4]. In [3], the achievable rate is computed under two assumptions: (A) each relay node scales the received signal to the maximum extent possible subject to its transmit power constraint, (B) the nodes in all layers operate in the high-SNR regime, where the received signal power P R,k at the k th node satisﬁes min k∈l P R,k ≥ 1/δ, l = 1, . . . , L for some small δ ≥ 0, where L is the number of layers of relay nodes. It is shown that the rate achieved under these two assumptions approaches network capacity as the source power increases. The authors in [4] extend this work to the scenarios where the nodes in at most one layer do not satisfy these two assumptions and show that achievable rates in such scenarios also approach the network capacity as the source power increases.\nHowever, requiring each relay node to amplify its received signal to the upper bound of its transmit power constraint\nresults in suboptimal end-to-end performance of analog net- work coding, as we establish in this paper and was also previ- ously indicated in [5], [6]. Further, even in low-SNR regimes amplify-and-forward relaying can be capacity achieving relay strategy in some scenarios, [7]. Therefore, in this paper we are concerned with analyzing the performance of analog network coding in layered networks, without above two assumptions on input signal scaling factors and received SNRs. Computing the maximum rate achievable with analog network coding without these two assumptions, however, results in a computationally intractable problem, in general [4], [6].\nOur main contribution is a result that a globally optimal set of scaling factors for the nodes that maximizes the end-to-end rate in a general layered relay network can be computed layer- by-layer. In particular, a rate-optimal set of scaling factors for the nodes in a layer is the one that maximizes the sum-rate of the nodes in the next layer. This result allows us to exactly compute the optimal end-to-end rate achievable with analog network coding, over all possible choices of scaling factors for the nodes, in a class of layered networks that cannot be so addressed using existing approaches. We illustrate this by computing the maximum ANC rate in different scenarios for one particular layered network. Further, for general layered relay networks, our result signiﬁcantly reduces the computa- tional complexity of solving this problem.\nIn this paper, we provide the summary of our work. We have omitted most proofs or give only brief outlines. The details can be found in our arXiv submission [8].\nOrganization: In Section II we introduce a general wireless layered relay network model and formulate the problem of maximum rate achievable with ANC in such a network. Sec- tion III discusses the computational hardness of this problem and existing approaches to address it. In Section IV we ﬁrst motivate and then state and prove the key lemma of this paper that allows us to compute a rate-optimal set of scaling factors for the nodes in a layered network in a layer-by- layer manner. Then Section V illustrates the computation of the maximum ANC rate in one particular layered network in various scenarios. Finally, Section VI concludes the paper.\nConsider a (L + 2)-layer wireless relay network with di- rected links 1 . Source s is at layer \u20180\u2019, destination t is at layer \u2018L + 1\u2019, and a set R of relay nodes are arranged in L layers between them. The l th layer contains n l relay nodes,\nn l = |R|. Each node is assumed to have a single antenna and operate in full-duplex mode.\nwhere x j [n] is the channel input of the node j in the neighbor set N (i) of node i. In (1), h ji is a real number representing the channel gain along the link from node j to node i. It is assumed to be ﬁxed (for example, as in a single realization of a fading process) and known throughout the network. The source symbols x s [n], −∞ < n < ∞, are i.i.d. Gaussian random variables with zero mean and variance P s that satisfy an average source power constraint, x s [n] ∼ N (0, P s ). Further, {z i [n] } is a sequence (in n) of i.i.d. Gaussian random variables with z i [n] ∼ N (0, σ 2 ). We also assume that z i are independent of the input signal and of each other. We assume that the i th relay\u2019s transmit power is constrained as:\nE[x 2 i [n]] ≤ P i , −∞ < n < ∞ \t (2) In analog network coding each relay node ampliﬁes and\nforwards the noisy signal sum received at its input. More precisely, a relay node i at instant n + 1 transmits the scaled version of y i [n], its input at time instant n, as follows\nx i [n + 1] = β i y i [n], 0 ≤ β 2 i ≤ β 2 i,max = P i /P R,i , (3) where P R,i is the received power at the node i.\nIn layered networks, all copies of a source signal and a noise symbol introduced at a node and traveling along different paths arrive at the destination with the same respective time delays. Therefore, the outputs of the source-destination channel are free of intersymbol interference. This simpliﬁes the relation between input and output of the channel and allows us to omit the time-index while denoting the input and output signals.\nUsing (1) and (3), the input-output channel between the source and destination can be written as\nwhere K s is the set of L-tuples of node indices corresponding to all paths from source s to destination t with path delay L. Similarly, K lj is the set of L − l + 1-tuples of node indices corresponding to all paths from the j th relay of l th layer to destination t with path delay L − l + 1.\nFor all the paths between source s and destination t, and all the paths between the j th relay of the l th layer to destination t with path delay L − l + 1, we introduce modiﬁed channel gains, respectively, as follows\nIn terms of these modiﬁed channel gains 2 , the source- destination channel in (4) can be written as:\nIn [8] we provide an example to illustrate the derivation of the source-destination channel expression in (7) for a speciﬁc layered network in terms of the modiﬁed channel gains introduced above.\nProblem Formulation: For a given network-wide scaling vector β = (β li ) 1≤l≤L,1≤i≤n l , the achievable rate for the channel in (7) with i.i.d. Gaussian input is ([3], [4], [6]):\nThe maximum information-rate I AN C (P s ) achievable in a given layered network with i.i.d. Gaussian input is deﬁned as the maximum of I(P s , β) over all feasible β, subject to per relay transmit power constraint (3). In other words:\nTherefore in the rest of the paper, we concern ourselves mostly with maximizing the received SNRs.\nThe problem (11) is a hard optimization problem. In terms of Geometric Programming [10], [11], SN R t is a ratio of posynomials that is a nonlinear (neither convex nor concave) function of l n l variables in β, in general. It is well-known that maximizing such ratios of posynomials is an intractable problem with no efﬁcient and global solution methods [10, Page 85]. However, globally optimal solutions of such prob- lems can be approximated using heuristic methods based on signomial programming condensation that solves a sequence of geometric programs, as in [10, Section 3.3]. Such heuristics though useful in providing good numerical approximations to the optimal SN R t , do not provide non-trivial characterization of the optimal SN R t (or a β opt that achieves it) in terms of various system parameters. We argue that such characterization however, is highly desired not only for the accurate analysis of ANC performance in general layered networks, but also for various reasons of signiﬁcant practical consequences, [8].\nTowards this goal, in [3], [4] the performance of analog network coding is analyzed under assumptions A and B discussed earlier about per node scaling factor and received SNR at each node, respectively. In the following, we provide an example to establish that assumption A, in general, leads to suboptimal ANC rates.\nExample 1: Let us consider the 2-relay Gaussian diamond network, [3], [5]. It is deﬁned as a directed graph G = (V, E) with V = {s, t, 1, 2} and E = {(s, 1), (s, 2), (1, t), (2, t)}. Let h e be the channel gain along the link e, e ∈ E. The problem of maximum rate achievable with analog network coding for this network can be formulated as (using (11)), [8]:\nwhere β = (β 1 , β 2 ) and β max = (β 1,max , β 2,max ) with β 2 1,max = P 1 /(h 2 s1 P + σ 2 ), β 2 2,max = P 2 /(h 2 s2 P + σ 2 ).\nEquating the partial derivatives of the objective function with respect to β 1 and β 2 to zero, we get the following two conditions for global maximum:\nIn [8] we prove that all choices of the parameters ( {h e , e ∈ E }, P s , P 1 , P 2 ) that result in one of the constraints β 2 1 < β 2 1,max and β 2 2 < β 2 2,max being satisﬁed lead to a whole class of scenarios where the global optimum solutions are achieved when a relay node transmits strictly below its maximum transmit power constraint, thus contradicting assumption A. In [6], we provide an instance of such parameter choices.\nNext, we introduce our result that allows us to characterize the optimal performance of analog network coding in general layered networks without assumption B or its limited relax- ation in [4]. This result also provides some key insights into the nature of β opt in terms of system parameters.\nIn this section we prove that in an end-to-end rate optimal network-wide scaling vector β opt , the component scaling fac- tors corresponding to the relay nodes in the layer l, 1 ≤ l ≤ L, maximize the sum-rate of the nodes in the layer l + 1. However before discussing this result formally, we motivate it by computing the maximum rate of information transfer over a linear amplify-and-forward relay network.\nWe consider a linear amplify-and-forward network of L relay nodes between source s and destination t, as shown in the Figure 1.\nConsider a feasible scaling vector β = (β 1 , . . . , β L ) such that the output of each relay node satisﬁes the corresponding transmit power constraint (2). Then the maximum scaling factor for the l th , 1 ≤ l ≤ L, relay is (from (3)):\nIn a linear AF network, both the source signal and the noise introduced at each intermediate relay node can reach the destination along only one path. Therefore using (5), (6), (7), and (9), for a given scaling vector β, the received SNR at destination t or any relay node l can be written as\nLemma 1: The value of β L−1 that maximizes SN R L also maximizes SN R t .\nThis implies that for a given (β 1 , . . . , β L−1 ), SN R t increases with β L . However, as the maximum value that β L can take is β L,max , so SN R t attains it maximum value at β L,max .\nStep 2: Using (15) we can express SN R t only in terms of (β 1 , . . . , β L−1 ) as SN R t (β 1 , . . . , β L−1 ) given below as\n, the partial derivative of SN R t (β 1 , . . . , β L−1 ) with respect to β L−1 as\nFurther, from (16) the partial derivative of SN R L with respect to β L−1 evaluates to\nIt follows from (17) and (18) that SN R t (β 1 , . . . , β L−1 ) and SN R L are increasing functions of β L−1 . Therefore both attain their respective maximum at β L−1,max , the maximum value of β L−1 . In other words, a value of β L−1 that maximizes SN R L also maximizes SN R t .\nFollowing the same sequence of steps as in the proof of above lemma with SN R t and SN R L replaced by SN R L and SN R L−1 , respectively, we can also prove that the same value of β L−2 (speciﬁcally β L−2,max ) maximizes both, SN R L and SN R L−1 . This along with Lemma 1 that al- lows us to express both, SN R L and SN R t as functions of (β 1 , . . . , β L−2 ), proves that the same value of β L−2,max maximizes SN R L−1 , SN R L and SN R t . Furthermore car- rying out this reasoning recursively allows us to express SN R i , 2 ≤ i ≤ L + 1, only in terms of β 1 and to prove that the same value of β 1 (speciﬁcally β 1,max ) maximizes all of them. We summarize this in the following proposition.\nProposition 1: For a linear AF network, β opt = (β opt 1 , . . . , β opt L ) that solves (11) can be computed recursively as\nCorollary 1: For a linear AF network with P s = P 1 = . . . = P L = P and h 0 = h 1 = . . . = h L = h, the maximum achievable information rate R = O(1/L).\nWe now discuss our result for the general layered networks, discussed in Section II, in general SNR regime.\nLemma 2: Consider a layered relay network of L+2 layers, with source s in layer \u20180\u2019, destination t in layer \u2018L + 1\u2019, and L layers of relay nodes between them. The l th layer contains n l nodes, n 0 = n L+1 = 1. A network-wide scaling vector β opt = (β opt 1 , . . . , β opt L ) that solves (11) for this network, can be computed recursively for 1 ≤ l ≤ L as\nwhere β opt l is the subvector of optimal scaling factors for the nodes in the l th layer, β opt l = (β opt l1 , . . . , β opt ln\n) and constraints β 2 l ≤ β 2 l,max are component-wise β 2 li ≤ β 2 li,max .\nRemark 1: Lemma 2, in other words, states that the sub- vector of the optimal scaling vector β opt corresponding to the scaling factors of the nodes in the l th layer, is one that maximizes the product n l+1 i=1 (1 + SN R l+1,i ) over the nodes in the next layer. However, log n l+1 i=1 (1 + SN R l+1,i ) equals\nR l+1,i , the sum of the information rates to the nodes in the l +1 st layer. Therefore an interpretation of the Lemma 2 is: if starting with the ﬁrst layer, the scaling factors for the nodes in each successive layer are chosen such that the sum-rate of the nodes in the next layer is maximized, then such a choice also leads to a globally optimal solution of the problem (11).\nRemark 2: The problem (11) is a hard optimization problem in l n l variables as noted in Section III. However, Lemma 2 leads to the decomposition of this problem into a cascade of L such subproblems, where the l th subproblem involves n l variables. This results in exponential reduction in search space required to solve (11) in general layered networks.\nProof: For the ease of presentation, we discuss the proof for a class of layered networks where channel gains along all links between the nodes in two adjacent layers are equal, as in Figure 2. We call such layered networks as \u201cEqual Channel Gains between Adjacent Layers (ECGAL)\u201d networks.\nConsider the ECGAL network shown in Figure 2. We assume that all relays have the same transmit power constraint EX 2 ≤ P . Consider three adjacent layers k − 1, k, and k + 1.\nClaim: The scaling factors for the nodes in layer k − 1 that maximize 2 i=1 (1 + SN R k,i ) also maximize 2 i=1 (1 + SN R k+1,i ) and vice-versa.\nProof: Let the source signal components 3 of the input at the two nodes in the layer k − 1 be denoted as S, with var(S) = S 2 . Let the noise components at the two nodes be denoted as N 1 and N 2 , respectively, with var(N 1 ) = var(N 2 ) = N 2 .\nwith α 2 = S 2 h 2 k−1 (β 1 +β 2 ) 2 and γ 2 = σ 2 +h 2 k−1 N 2 (β 2 1 +β 2 2 ). Deﬁne for j = k, k + 1\nwhere β 2 k,max = P α 2 +γ 2 , i ∈ {1, 2}. In [8], we prove that (β 2 k,max , β 2 k,max ) is the only solution of (19).\nSubstituting the above solution of (19) in the expression for SN R k+1 above, allows us to express it in terms of β k−1,1 and β k−1,2 as SN R k+1 . Consider the following two problems.\nwhere β 2 k−1,max = \t P S 2 +N 2 , i ∈ {1, 2}. In [8], we prove that (β 2 k−1,max , β 2 k−1,max ) is the only solution of both the problems (20) and (21). Thus proving our claim.\nCarrying out the above procedure in the proof of our claim recursively for all k layers, 1 ≤ k ≤ L, proves the lemma for the ECGAL networks.\nIn the following, we illustrate the usefulness of Lemma 2 by computing the maximum achievable ANC rate in a network scenario without any a priori assumption on input signal scaling factors and the received SNRs, as in [3], [4].\nExample 2: Consider the ECGAL network of Figure 2 with L layers of relay nodes between the source and the destination and N nodes in each layer. We assume all relay nodes have the same transmit power constraint EX 2 ≤ P . We assume that the channels gains along all links are equal and denoted as h. From the symmetry of the network, it follows that β 2 li,max = β 2 l,max , 1 ≤ l ≤ L, 1 ≤ i ≤ N, where\nUsing Lemma 2, we can solve problem (11) for this network. The solution β opt is such that all relays in a layer use the same scaling factor and it is equal to the maximum value of the scaling factor for the nodes in the layer, i.e. β 2 li = β 2 l,max , 1 ≤ l ≤ L, 1 ≤ i ≤ N. The corresponding SNR t is:\nand the maximum achievable ANC rate in this scenario is R AN C = 1 2 log(1 + SN R t,opt ). In the following, we further discuss the computation of R AN C in two particular scenarios.\nThe received SNR at the l th layer varies with the number of preceding layers as SN R ∼ (1 + l−1 N ) −1 . Therefore, for any ﬁxed δ as in [3], [4], an arbitrarily large number of layers may violate the high-SNR regime condition min k∈l P R,k ≥ 1/δ, l = 1, . . . , L as L grows. Thus the approaches in [3], [4] cannot be used to exactly compute SN R t,opt as above or the optimal ANC rate in such networks.\nCase 2: Let P s → ∞. In this case, for the leading order in N we have\nTherefore, R AN C = 1 2 log(1 + SN R t,opt ) approaches the MAC cut-set bound C = 1 2 log(1 + N x) [6], within a constant gap as x → ∞, as shown in Figure 3.\nWe consider the problem of maximum rate achievable with analog network coding in general layered networks. Previ- ously, this problem was addressed assuming that the nodes in all but at most one layer in the network are in the high- SNR regime, and each node forwards the received signal at the upper bound of its transmit power constraint. We provide a key result that allows us to exactly compute the maximum\nANC rate in a class of symmetric layered network without these two assumptions. Further, our result signiﬁcantly reduces the computational complexity of this problem for general layered networks. We illustrate the signiﬁcance of our result by computing the maximum ANC rate for one particular relay network in a scenario that cannot be addressed using existing approaches. In the future, we plan to extend this work to general wireless networks.\nThis work is partially supported by a grant from the Uni- versity Grants Committee of the Hong Kong Special Admin- istrative Region, China (Project No. AoE/E-02/08), the CERG grant 412207, and the Project MMT-p7-11 of the Shun Hing Institute of Advanced Engineering, The Chinese University of Hong Kong."},"refs":[{"authors":[{"name":"S. -Y. R. Li"},{"name":"R. W. Yeung"},{"name":"N. Cai"}],"title":{"text":"Linear network coding"}},{"authors":[{"name":"S. Katti"},{"name":"S. Gollakotta"},{"name":"D. Katabi"}],"title":{"text":"Embracing wireless interference: analog network coding"}},{"authors":[{"name":"I. Mari´c"},{"name":"A. Goldsmith"},{"name":"M. M´edard"}],"title":{"text":"Analog network coding in the high-SNR regime"}},{"authors":[{"name":"B. Liu"},{"name":"N. Cai"}],"title":{"text":"Analog network coding in the generalized high- SNR regime"}},{"authors":[{"name":"B. Schei"}],"title":{"text":"Distributed Coordination in Network Information Theory"}},{"authors":[{"name":"S. Agnihotri"},{"name":"S. Jaggi"},{"name":"M. Chen"}],"title":{"text":"Amplify-and-Forward in Wireless Relay Networks"}},{"authors":[{"name":"K. S. Gomadam"},{"name":"S. A. Jafar"}],"title":{"text":"Optimal relay functionality for SNR maximization in memoryless relay networks"}},{"authors":[{"name":"S. Agnihotri"},{"name":"S. Jaggi"},{"name":"M. Chen"}],"title":{"text":"Analog Network Coding in General SNR Regime"}},{"authors":[{"name":"R. Koetter"},{"name":"M. M´edard"}],"title":{"text":"An algebraic approach to network coding"}},{"authors":[{"name":"M. Chian"}],"title":{"text":"Geometric Programming for Communication Systems"}},{"authors":[{"name":"S. Boyd"},{"name":"S. -J. Kim"},{"name":"L. Vandenberghe"},{"name":"A. Hassibi"}],"title":{"text":"A tutorial on geometric programming"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569565321.pdf"},"links":[{"id":"1569564889","weight":4},{"id":"1569566725","weight":4},{"id":"1569567049","weight":4},{"id":"1569565867","weight":12},{"id":"1569565067","weight":4},{"id":"1569566981","weight":4},{"id":"1569559259","weight":4},{"id":"1569564469","weight":8},{"id":"1569566373","weight":4},{"id":"1569566647","weight":4},{"id":"1569564731","weight":4},{"id":"1569558325","weight":12},{"id":"1569565837","weight":16},{"id":"1569566119","weight":12},{"id":"1569560427","weight":4},{"id":"1569559541","weight":8},{"id":"1569566319","weight":4},{"id":"1569558459","weight":4},{"id":"1569565809","weight":4},{"id":"1569566843","weight":4},{"id":"1569558483","weight":4},{"id":"1569564903","weight":4},{"id":"1569566173","weight":4},{"id":"1569564387","weight":8},{"id":"1569566795","weight":4},{"id":"1569561679","weight":8},{"id":"1569566015","weight":4},{"id":"1569566895","weight":24},{"id":"1569566193","weight":4},{"id":"1569566575","weight":4},{"id":"1569566733","weight":4},{"id":"1569566063","weight":4},{"id":"1569566759","weight":4},{"id":"1569565213","weight":4},{"id":"1569566511","weight":4},{"id":"1569566531","weight":4},{"id":"1569565535","weight":8},{"id":"1569559805","weight":4},{"id":"1569566811","weight":8},{"id":"1569566687","weight":4},{"id":"1569565427","weight":4},{"id":"1569554881","weight":4},{"id":"1569566445","weight":16},{"id":"1569566209","weight":4},{"id":"1569566371","weight":4},{"id":"1569564857","weight":4},{"id":"1569564333","weight":4},{"id":"1569566913","weight":4},{"id":"1569566809","weight":4},{"id":"1569566357","weight":4},{"id":"1569565817","weight":4},{"id":"1569565847","weight":4},{"id":"1569555879","weight":8},{"id":"1569558509","weight":4},{"id":"1569566003","weight":12},{"id":"1569565185","weight":8},{"id":"1569566553","weight":4},{"id":"1569566191","weight":4},{"id":"1569566695","weight":4},{"id":"1569565311","weight":4},{"id":"1569566297","weight":4},{"id":"1569564097","weight":8},{"id":"1569566481","weight":4},{"id":"1569566857","weight":4},{"id":"1569565961","weight":4},{"id":"1569563395","weight":4},{"id":"1569566383","weight":4},{"id":"1569565493","weight":4},{"id":"1569566779","weight":8},{"id":"1569566097","weight":4},{"id":"1569566479","weight":4},{"id":"1569565397","weight":4},{"id":"1569557275","weight":4},{"id":"1569566129","weight":8},{"id":"1569565919","weight":8},{"id":"1569565181","weight":4},{"id":"1569565241","weight":4},{"id":"1569566887","weight":8},{"id":"1569564131","weight":4},{"id":"1569566253","weight":8},{"id":"1569566823","weight":8},{"id":"1569566137","weight":8},{"id":"1569566283","weight":4},{"id":"1569566529","weight":8},{"id":"1569566813","weight":8},{"id":"1569565293","weight":4},{"id":"1569563975","weight":24},{"id":"1569560235","weight":4},{"id":"1569564157","weight":4},{"id":"1569566911","weight":8},{"id":"1569564923","weight":16},{"id":"1569566601","weight":8},{"id":"1569557851","weight":8},{"id":"1569566847","weight":8},{"id":"1569565089","weight":4},{"id":"1569567013","weight":8},{"id":"1569560459","weight":4},{"id":"1569565853","weight":12},{"id":"1569564505","weight":4},{"id":"1569565165","weight":8},{"id":"1569566797","weight":4},{"id":"1569564141","weight":8},{"id":"1569566973","weight":8},{"id":"1569561579","weight":4},{"id":"1569566987","weight":4},{"id":"1569565139","weight":8},{"id":"1569565579","weight":4},{"id":"1569566609","weight":4},{"id":"1569560581","weight":4}],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S12.T1.1","endtime":"11:50","authors":"Samar Agnihotri, Sidharth Jaggi, Minghua Chen","date":"1341487800000","papertitle":"Analog Network Coding in General SNR Regime","starttime":"11:30","session":"S12.T1: Network Coding for Wireless","room":"Kresge Rehearsal B (030)","paperid":"1569565321"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
