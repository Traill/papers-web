{"id":"1569565633","paper":{"title":{"text":"Secure Transmission of a Gaussian Source over Gaussian Channels with Side Information"},"authors":[{"name":"Joffrey Villard"},{"name":"Pablo Piantanida"},{"name":"Shlomo Shamai (Shitz)"}],"abstr":{"text":"Abstract\u2014This paper investigates the problem of source- channel coding for secure transmission of a Gaussian source over a Gaussian wiretap channel in presence of arbitrarily correlated side informations at both receivers. By means of an appropriate coding scheme (either hybrid digital/analog or pure digital), the optimal rate-distortion-equivocation region is characterized for most of the scenarios. These results provide the best achievable tradeoff between the requirement on the distortion level at the legitimate receiver and the equivocation rate at the eavesdropper."},"body":{"text":"Consider a multiterminal system composed of three nodes where each one is measuring an analog source \u2013random ﬁeld\u2013 as a function of time. The encoder \u2013referred to as Alice\u2013 wishes to send its observation to a second terminal node \u2013 referred to as Bob\u2013 through a noisy channel with additive white Gaussian noise (AWGN). In this setting, Bob can use his own analogue source as side information to improve on the received information and reﬁne his estimate of Alice\u2019s source. The third terminal \u2013referred to as Eve\u2013 is assumed to be an eavesdropper node that can listen to the messages sent by Alice through another AWGN channel. Obviously, Alice does not trust Eve and hence she wishes to leak the smallest possible amount of information during her communication with Bob.\nThe above scenario involves the information-theoretic no- tion of secrecy (and its application to source/channel coding problems), source coding with side information, as well as joint source-channel coding for transmission of Gaussian sources over AWGN channels. The information-theoretic no- tion of secrecy was ﬁrst introduced by Shannon [1] and then used by Wyner [2] to propose the wiretap channel, which was further extended by Csiszár-Körner [3]. Source coding with side information has been presented by Slepian-Wolf [4], and Wyner-Ziv [5]. Recent results [6], [7] investigate such settings with an additional eavesdropper which must be kept as ignorant as possible of the transmitted source. Although most of the existent work on physical layer security focused on the separation principe (i.e. separate source and channel coding), under security constraints there is no general result of sepa- ration, unlike simple point-to-point problems. Actually recent\nworks [8], [9] show that under some less-noisy conditions sep- aration holds, but a simple counterexample in [9] introduces a pure analog scheme being optimal performs strictly better than existing digital ones. This observation motivates the authors in [10] to investigate hybrid digital/analog schemes for discrete memoryless sources and channels, where they have shown that a joint approach based on analog/digital schemes yields better results for some speciﬁc scenarios.\nIn this paper, we consider the secure transmission of a Gaus- sian source over a Gaussian wiretap channel with matched bandwidth, and in the presence of side information at the receiving terminals, as depicted in Fig. 2. This setting can be seen as the uniﬁcation of the problems of secure source coding with side information at the decoders [7] and the wiretap channel [3]. Our main goal is to understand how Alice can take simultaneous advantage of the statistical differences among the side informations and the channel noises to reveal the minimum amount of information to Eve, while still satisfying the required distortion level at Bob. The central difﬁculty of this problem lies in the characterization of the equivocation at Eve. Indeed, the side information available to Eve which can be exploited in together with its channel observation prevents from directly applying secrecy capacity results [3].\nWe identify four different cases: 1 Bob has a less-noisy channel and side information than Eve; 3 - 4 Eve has a less-noisy channel; and 2 Bob has a less-noisy channel while Eve has less-noisy side information than Bob. For cases 1 , 3 - 4 , a careful maximization of our inner and outer bounds in [9] yields the optimal rate-distortion-equivocation region . In these cases, separation holds and thus a pure digital scheme, combining secure-source coding with channel coding for broadcast channels with conﬁdential messages, turns to be optimal. However, since these bounds do not match for case 2 , we restrict our focus on the hybrid digital/analog scheme introduced in [10]. From this strategy we obtain a new achievable region that is shown to be optimal in case 2\nwhen the side information is only present at the eavesdropper. Notation: For any sequence (x i ) i∈N ∗ , the vector x n stands\nfor the collection (x 1 , . . . , x n ). Let X, Y and Z be three random variables (RVs) with PD p, if p(x|yz) = p(x|y) for each x, y, z, then they form a Markov chain X −− Y −− Z.\nConsider the transmission model depicted in Fig. 1 where the source A at Alice is standard Gaussian, and the cor- responding analogue observations (side information) at Bob and Eve are modeled as the outputs of independent additive white Gaussian noise (AWGN) channels with input A and respective noise powers P B and P E . Communication channels from Alice-to-Bob and Alice-to-Charlie are AWGN channels with respective noise powers P Y and P Z . The average input power of this channel is limited to P . We assume a matched bandwidth, i.e., one channel use is allowed per source symbol.\nEuclidean distance on R is used to measure distortion at Bob d(a, b) = (a − b) 2 , for all a, b ∈ R. Differential entropy h(·) measures uncertainty yielding equivocation rates ∆ ∈ R. We also introduce quantity D E = 2 2∆ /(2πe), which provides a lower bound on the minimum mean-square error of any estimator of A at Eve [11, Theorem 8.6.6].\nDeﬁnition 1 (Code): A source-channel n-code for the present setup depicted in Fig. 1 is deﬁned by\n\u2022 A (stochastic) encoding function at Alice F : R n → R n , deﬁned by some transition probability P F (x n |a n ),\nDeﬁnition 2 (Achievability): A tuple (D, D E ) ∈ R ∗ + 2 is said achievable if, for any ε > 0, there exists a source-channel n-code (F, g) satisfying the accuracy and security constraints:\n2 log (2πe D E ) − ε , 1 n\nProposition 1: Due to the additive Gaussian noises, and de- pending on the relative values of P B , P E (resp. P Y , P Z ), one\nside information (resp. one channel) is always a stochastically degraded version of the other. Hence there are four different cases which are summarized in Table I.\nRecent works [9], [10] deal with a similar setup for the case of discrete sources and channels. A general outer bound as well as two inner bounds (based on digital and hybrid coding schemes) have been derived. Along the same lines, including the input constraint Var [X] ≤ P , achievable rate regions can be readily extended (see [12] for further details) to the present setting of a quadratic Gaussian source over AWGN channels. In what follows, we consider separately each of the cases in Table I, for which we will need to rely (although omitted for space limitations) on the achievable regions in [9], [10].\nFrom [9], we already know that separation holds for the settings 1 , 3 , and 4 . In these cases, the optimal scheme consists of a source encoder that outputs two layers which are further encoded by using the channel code of a broadcast channel with conﬁdential messages [3] (see Fig. 2). The ﬁrst layer r c can be seen as a common message, which is consid- ered to be known at Eve, while the second layer r p forms a private message which is \u2013partially\u2013 protected by introducing an independent random noise r f . In the setup considered in this paper, Gaussian variables are optimal, yielding the closed- from expressions given by Theorems 1 and 2 below.\nTheorem 1 (optimal region for cases 1 and 3 ): Assume that P B ≤ P E , a tuple (D, D E ) is achievable if and only if\nProof: The proof of the converse part will be omitted. In fact, it relies on the general outer bound in [9, Prop. 2] together\nwith the entropy power inequality (EPI) [13]. For further details we refer the reader to [12, Appendix F]). Whereas the direct part easily follows from [9, Prop. 1] by choosing appropriate Gaussian auxiliary random variables.\nTheorem 2 (optimal region for case 4 ): Let P B > P E , P Y ≥ P Z , a tuple (D, D E ) is achievable if and only if\nProof: A sketch of proof of the converse part is given in Appendix A. Details of the proof of direct part are omitted since it easily follows by evaluating the corresponding achiev- able region with an appropriate choice of Gaussian auxiliary RVs (see [9, Prop. 2] for further details).\nAs a matter of fact, the case 2 where Bob has \u201cbetter\u201d channel (P Y < P Z ) and \u201cworse\u201d side information (P B > P E ) than Eve, is still open. A careful maximization for the quadratic Gaussian case of the variables involved in the outer bound in [9, Theorem 2] yields the proposition below.\nProposition 2 (outer bound for case 2 ): Let P B > P E and P Y < P Z , any achievable tuple (D, D E ) satisﬁes the following inequalities:\nProof: The proof of this outer bound is similar to the one of the converse part of Theorem 2 (given in Appendix A). For further details we refer the reader to see [12, Appendix H].\nWe now use the hybrid digital/analog scheme proposed in [10] which is depicted in Fig. 3. Roughly speaking, it consists in sending independent digital random noise r f using a Gelfand-Pinsker code [14] for the state-dependent channel with input X, state A and output (B, Y ). As in [10, Sec- tion IV], we choose U , V and X of [10, Theorem 3] as:\nU = ∅ \t (common description) V = αA + γN \t (private description) X = βA − γN\nwhere α ∈ R, β ∈ [0, 1), γ = 1 − β 2 and N ∼ N (0, 1) is a standard Gaussian random variable independent of A.\nIn [12], it is shown that care must be exercised when using this coding scheme. Notice that unlike dirty-paper coding for communication without secrecy constraints but with non- causal channel state information to the encoder [15], the source A \u2013viewed as the channel state of the corresponding equivalent channel\u2013 and the bin index are not independent.\n× √\nProposition 3 (Hybrid scheme for all cases): A tuple (D, D E ) ∈ R ∗ + 2 is achievable if\n \n \nProof: Proposition 3 follows from [10, Theorem 3] after some algebraic manipulations on the involved covariance matrices (see [12, Appendix I]).\nAs a matter of fact, the hybrid scheme of Proposition 3 does not seem to be optimal in the general case as we will see in Section V. However, it achieves the outer bound of Proposition 2 in the special case when P Y < P Z and P B → ∞ that we refer to as case 2 , as stated in the following theorem.\nTheorem 3 (optimal region for case 2 ): Assume \t that P B → ∞ with P Y < P Z , then a tuple (D, D E ) ∈ R ∗ + 2 is achievable if and only if\nProof: The converse part directly follows from Proposi- tion 2 by letting P B tend to inﬁnity. Whereas the direct part follows after Proposition 3 by letting P B tend to inﬁnity and choosing, for every distortion level D ∈ \t 1 1+ P\nIn this section, we plot largest achievable D E as a function of the distortion level at Bob D, for three cases of particular interest and compare (with numerical optimization whether it is needed) the different coding schemes:\n\u2022 a pure analog scheme, consisting in directly sending a scaled version of the source over the channel,\nFirst of all, we observe that any of the proposed schemes is sufﬁcient to achieve the optimal performance in all cases. According to Theorems 1 and 2, the digital scheme of [9] is optimal in case 1 (see Fig. 4). However, it is strictly sub- optimal in case 2 , as shown by Fig. 5. In this case, the proposed hybrid digital/analog scheme outperforms both pure analog and digital schemes. According to Theorem 3, it is moreover optimal in case 2 (see Fig. 6). Interestingly enough, a time-sharing combination of digital and analog schemes falls short to achieve the entire region in this case.\nOf course, at a ﬁrst look the above conclusion may not be surprising because it is well-known that joint source-channel coding/decoding performs better for general broadcast set- tings [16]. Indeed, this holds true under no secrecy constraints and when perfect reconstruct of the source is intended at all the decoders. Nevertheless, the present settings under secure constraints is rather different since Alice only wants to help Bob while keeping the uncertainty at Eve as higher as possible. Therefore the intuition would indicate that the optimal strategy should not be a joint source-channel coding scheme, since separate source and channel coding can allow the encoder to protect by introducing uniform noise the information (e.g. Theorems 1 and 2). Finally, it should be worth to mention here that different coding is needed to achieve the optimal tradeoffs in cases 1 , 3 - 4 and 2 . Whereas in order to fully solve case 2 it is clear that a novel scheme would be needed. The main difﬁculty in exploring other coding schemes relies\nin the evaluation of the uncertainty at Eve. In spite of the aforementioned limitations, several interesting extensions of this work can be identiﬁed, e.g., Gaussian vector settings, a generalization of the well-known CEO problem to incorporate security constraints, etc.\nAssume that P B > P E and P Y ≥ P Z , and let (D, D E ) be an achievable tuple. From [9, Proposition 2], there exist RVs U , V , X with joint PD 1\n∆ ≤ h(A|V B) + I(A; B|U ) − I(A; E|U ) , Var [X] ≤ P ,\nand tuple (D, ∆) veriﬁes the following inequalities: I(V ; A|B) ≤ I(X; Y ) ,\n∆ ≤ h(A|V B) − h(E|V B) + h(E|AB) , Var [X] ≤ P .\nwhere ¯ N B ∼ N (0, P B − P E ) is independent of A and N E ∼ N (0, P E ). In order to ﬁnd an upper bound on the r.h.s. of (1), we need the following expansion of E, for any γ ∈ R:\nNote that (A, B, C) is a Gaussian vector, and that A and C are independent for any γ. The usefulness of the above expansion comes from the fact that C is also independent of B if γ = P E P\nE[BC] = (1 − γ) E [BN E ] − γ E B ¯ N B = (1 − γ)P E − γ (P B − P E ) = P E − γP B = 0 .\nFinally, since V only depends on A, C, it is independent of (V, A, B). By using expansion (A), we now write\nh(E|V B) = h(γB + (1 − γ)A + C|V B) = h((1 − γ)A + C|V B) .\nAnd from the above paragraph, the conditional EPI holds between A and C (given (V, B)):\nwhere the last equality follows from expansion (A). Gathering the above equations, (1) yields\n= 1 2\nWe now introduce the parameter ν = 2 2h(A|V B) /(2πe). From the fact that conditioning reduces the entropy and clas- sical properties of the differential entropy, the above parameter is bounded as follows:\nHence from standard properties of differential entropy, and the fact that distortion measure d is the Euclidean distance on R, the following sequence of inequalities holds true:\nGathering the above equations, tuple (D, D E ) veriﬁes the following inequalities:\nEliminating parameter ν in the above system proves the converse part of Theorem 2."},"refs":[{"authors":[{"name":"C. Shannon"}],"title":{"text":"Communication theory of secrecy systems"}},{"authors":[{"name":"A. Wyner"}],"title":{"text":"The wire-tap channel"}},{"authors":[{"name":"I. Csiszár"},{"name":"J. Körner"}],"title":{"text":"Broadcast channels with conﬁdential mes- sages"}},{"authors":[{"name":"D. Slepian"},{"name":"J. Wolf"}],"title":{"text":"Noiseless coding of correlated information sources"}},{"authors":[{"name":"A. Wyner"},{"name":"J. Ziv"}],"title":{"text":"The rate-distortion function for source coding with side information at the decoder"}},{"authors":[{"name":"V. Prabhakaran"},{"name":"K. Ramchandran"}],"title":{"text":"On secure distributed source coding"}},{"authors":[{"name":"J. Villard"},{"name":"P. Piantanida"}],"title":{"text":"Secure lossy source coding with side information at the decoders"}},{"authors":[{"name":"N. Merhav"}],"title":{"text":"Shannon\u2019s secrecy system with informed receivers and its application to systematic coding for wiretapped channels"}},{"authors":[{"name":"J. Villard"},{"name":"P. Piantanida"},{"name":"S. Shamai"}],"title":{"text":"Secure lossy source-channel wiretapping with side information at the receiving terminals"}},{"authors":[],"title":{"text":"Hybrid digital/analog schemes for secure transmission with side information"}},{"authors":[{"name":"T. Cove"},{"name":"J. Thoma"}],"title":{"text":"Elements of information theory (2nd Ed)"}},{"authors":[{"name":"J. Villard"},{"name":"P. Piantanida"},{"name":"S. Shamai"}],"title":{"text":"Secure transmission of sources over noisy channels with side information at the receivers"}},{"authors":[{"name":"C. Shannon"}],"title":{"text":"A mathematical theory of communication"}},{"authors":[{"name":"S. Gel\u2019fand"},{"name":"M. Pinsker"}],"title":{"text":"Coding for channel with random parame- ters"}},{"authors":[{"name":"M. Costa"}],"title":{"text":"Writing on dirty paper"}},{"authors":[{"name":"E. Tuncel"}],"title":{"text":"Slepian-Wolf coding over broadcast channels"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569565633.pdf"},"links":[{"id":"1569566381","weight":9},{"id":"1569566527","weight":4},{"id":"1569566485","weight":18},{"id":"1569565383","weight":4},{"id":"1569566725","weight":9},{"id":"1569566385","weight":4},{"id":"1569567049","weight":4},{"id":"1569566875","weight":4},{"id":"1569559617","weight":9},{"id":"1569566683","weight":13},{"id":"1569560629","weight":4},{"id":"1569566227","weight":4},{"id":"1569566943","weight":13},{"id":"1569566591","weight":4},{"id":"1569566571","weight":4},{"id":"1569564481","weight":4},{"id":"1569566415","weight":4},{"id":"1569566469","weight":4},{"id":"1569566081","weight":13},{"id":"1569565613","weight":4},{"id":"1569551535","weight":4},{"id":"1569565461","weight":4},{"id":"1569564245","weight":4},{"id":"1569564227","weight":9},{"id":"1569566119","weight":13},{"id":"1569564233","weight":9},{"id":"1569566319","weight":4},{"id":"1569558459","weight":4},{"id":"1569565291","weight":4},{"id":"1569564203","weight":4},{"id":"1569562685","weight":9},{"id":"1569566751","weight":4},{"id":"1569566467","weight":4},{"id":"1569565771","weight":4},{"id":"1569566157","weight":4},{"id":"1569565859","weight":4},{"id":"1569565809","weight":4},{"id":"1569566579","weight":4},{"id":"1569556091","weight":4},{"id":"1569565347","weight":9},{"id":"1569565455","weight":4},{"id":"1569564989","weight":4},{"id":"1569566523","weight":4},{"id":"1569565953","weight":4},{"id":"1569566895","weight":4},{"id":"1569564189","weight":4},{"id":"1569566985","weight":4},{"id":"1569565907","weight":4},{"id":"1569566239","weight":4},{"id":"1569566679","weight":9},{"id":"1569566753","weight":4},{"id":"1569558681","weight":9},{"id":"1569565213","weight":9},{"id":"1569566643","weight":9},{"id":"1569565841","weight":18},{"id":"1569567665","weight":9},{"id":"1569561143","weight":4},{"id":"1569565667","weight":4},{"id":"1569561795","weight":9},{"id":"1569566423","weight":4},{"id":"1569567015","weight":4},{"id":"1569566811","weight":4},{"id":"1569559111","weight":9},{"id":"1569562285","weight":4},{"id":"1569553537","weight":4},{"id":"1569552251","weight":4},{"id":"1569553519","weight":13},{"id":"1569566231","weight":9},{"id":"1569554881","weight":4},{"id":"1569554971","weight":4},{"id":"1569566209","weight":4},{"id":"1569565655","weight":4},{"id":"1569566909","weight":4},{"id":"1569565087","weight":4},{"id":"1569564857","weight":4},{"id":"1569565033","weight":13},{"id":"1569566447","weight":4},{"id":"1569565887","weight":4},{"id":"1569555879","weight":4},{"id":"1569565219","weight":31},{"id":"1569558509","weight":4},{"id":"1569565095","weight":4},{"id":"1569566553","weight":4},{"id":"1569564969","weight":9},{"id":"1569565029","weight":4},{"id":"1569565357","weight":4},{"id":"1569561245","weight":4},{"id":"1569565393","weight":4},{"id":"1569565527","weight":4},{"id":"1569567029","weight":4},{"id":"1569566655","weight":4},{"id":"1569566673","weight":9},{"id":"1569566667","weight":4},{"id":"1569564097","weight":4},{"id":"1569566407","weight":4},{"id":"1569566481","weight":4},{"id":"1569565439","weight":9},{"id":"1569562551","weight":4},{"id":"1569565415","weight":4},{"id":"1569555367","weight":4},{"id":"1569566383","weight":4},{"id":"1569566805","weight":4},{"id":"1569566929","weight":4},{"id":"1569566983","weight":4},{"id":"1569566097","weight":4},{"id":"1569566479","weight":4},{"id":"1569566873","weight":4},{"id":"1569565765","weight":4},{"id":"1569557275","weight":4},{"id":"1569566129","weight":13},{"id":"1569565919","weight":9},{"id":"1569565181","weight":4},{"id":"1569565661","weight":9},{"id":"1569566887","weight":4},{"id":"1569564131","weight":18},{"id":"1569561221","weight":9},{"id":"1569565421","weight":4},{"id":"1569566547","weight":9},{"id":"1569566823","weight":18},{"id":"1569566595","weight":13},{"id":"1569566137","weight":9},{"id":"1569565013","weight":4},{"id":"1569565375","weight":4},{"id":"1569566639","weight":4},{"id":"1569566755","weight":4},{"id":"1569565597","weight":4},{"id":"1569566771","weight":4},{"id":"1569566641","weight":4},{"id":"1569559035","weight":9},{"id":"1569564437","weight":9},{"id":"1569551905","weight":9},{"id":"1569564861","weight":4},{"id":"1569566619","weight":13},{"id":"1569561185","weight":9},{"id":"1569565669","weight":9},{"id":"1569566817","weight":4},{"id":"1569566389","weight":4},{"id":"1569566435","weight":4},{"id":"1569567483","weight":4},{"id":"1569566911","weight":4},{"id":"1569566299","weight":9},{"id":"1569564281","weight":4},{"id":"1569565805","weight":22},{"id":"1569561713","weight":4},{"id":"1569566933","weight":4},{"id":"1569563919","weight":9},{"id":"1569557851","weight":13},{"id":"1569555891","weight":4},{"id":"1569566847","weight":4},{"id":"1569563725","weight":4},{"id":"1569565635","weight":4},{"id":"1569565113","weight":13},{"id":"1569564257","weight":18},{"id":"1569566449","weight":9},{"id":"1569566987","weight":4},{"id":"1569564755","weight":9},{"id":"1569564509","weight":9},{"id":"1569551541","weight":9},{"id":"1569565139","weight":9},{"id":"1569564419","weight":13},{"id":"1569564807","weight":4},{"id":"1569566609","weight":4},{"id":"1569566113","weight":18},{"id":"1569566417","weight":9}],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S7.T4.5","endtime":"16:20","authors":"Joffrey Villard, Pablo Piantanida, Shlomo (Shitz) Shamai","date":"1341331200000","papertitle":"Secure Transmission of a Gaussian Source over Gaussian Channels with Side Information","starttime":"16:00","session":"S7.T4: Secrecy in Computation and Communication","room":"Stratton 20 Chimneys (306)","paperid":"1569565633"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
