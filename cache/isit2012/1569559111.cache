{"id":"1569559111","paper":{"title":{"text":"Polar Coding for the Slepian-Wolf Problem Based on Monotone Chain Rules"},"authors":[{"name":"Erdal Arıkan"}],"abstr":{"text":"Abstract\u2014We give a polar coding scheme that achieves the full admissible rate region in the Slepian-Wolf problem without time-sharing. The method is based on a source polarization result using monotone chain rule expansions.\nIndex Terms\u2014Monotone chain rules, polar codes, Slepian-Wolf problem, source polarization."},"body":{"text":"Consider a memoryless source with generic variables (X, Y ) ∼ P X,Y where P X,Y is a ﬁxed but arbitrary prob- ability distribution on X × Y with X = Y = {0, 1}. Let (X N , Y N ) denote N successive outputs of this source, X N = (X 1 , . . . , X N ), Y N = (Y 1 , . . . , Y N ). This paper\nconsiders the Slepian-Wolf problem for this source. As usual, the coding system consists of two encoders and one decoder. For a speciﬁed rate pair (R 1 , R 2 ), encoder 1 observes X N and encodes it into a codeword of length N R 1 bits; encoder 2 observes Y N and encodes it into a codeword of length\nN R 2 bits. The decoder observes the two codewords and is expected to recover (X N , Y N ) with small probability of error. The Slepian-Wolf result [1] states that this is possible if (R 1 , R 2 ) falls strictly inside the Slepian-Wolf rate region deﬁned as R SW = {(R x , R y ) : R x ≥ H(X|Y ), R y ≥ H(Y |X), R x + R y ≥ H(X, Y )}. The subset of R SW consisting of points for which R x + R y = H(X, Y ) is referred to as the dominant face (of the rate region); and the points (R x , R y ) = (H(X), H(Y |X)) and (R x , R y ) = (H(X |Y ), H(Y )) are referred to as the corner points.\nPolar coding for the above Slepian-Wolf problem was ﬁrst considered by Hussami et al [2] (see also Korada [3]) who showed that the corner points of R SW could be achieved by polar codes for the special case where P X and P Y are uniform on {0, 1}. In [4], this result was proved without any restrictions on P X and P Y . These results showed that polar codes could achieve the entire region R SW by time-sharing between two codes designed for the corner points.\nThis paper is concerned with the question of whether polar codes can achieve R SW without aid from time-sharing. This question is motivated by the fact that there are random-coding methods, such as Cover\u2019s \u201cbinning\u201d method [5], that do not require time-sharing to achieve R SW . Thus, the question is important for understanding the power of polar coding relative to other coding methods both as a proof method and also for practical applications.\nIn fact, such questions on the relative power of polar coding ﬁrst arose in the context of the multiple access channel (MAC), which is the dual of the Slepian-Wolf problem. In [6], S¸as¸o˘glu\net al described a polar coding scheme for the MAC that did not use time-sharing and yet was able to achieve some interior ( i.e. , non-corner) points of the dominant face of the MAC capacity region. The method in [6] was based on \u201cjoint polarization\u201d for the MAC and it produced a multitude of extreme channels, revealing a novel aspect of polarization in the multi-terminal case. Abbe and Telatar reﬁned and extended the joint polarization approach in [7], [8]. Meanwhile, on the Slepian-Wolf front, the joint polarization approach was formulated in [9]. In [10], Abbe gave a uniﬁed treatment of joint polarization for the MAC and Slepian-Wolf problems using \u201cmatrix polarization.\u201d The question of whether joint po- larization alone could achieve the entire achievable rate regions for the MAC or the Slepian-Wolf problems remained unsolved until recently when S¸as¸o˘glu [11] answered the question in the negative by giving counter-examples. This was a set-back for the polarization approach.\nIn this paper, we consider polarization in a broader setting and give a polar coding method that achieves R SW without time-sharing. In this broader setting joint polarization appears as a special instance of a general approach. The main idea of our approach is described in the next section.\nConsider a source block (X N , Y N ) as above. Suppose N = 2 n for some n ≥ 1 and deﬁne\nwhere the exponent denotes the nth Kronecker power and B N is the \u201cbit-reversal\u201d permutation (see [12]). Since (X N , Y N ) → (U N , V N ) is a one-to-one mapping, we have\nwhich states that entropy is conserved. Polar codes can be obtained from (3) by various chain rule expansions of H(U N , V N ). To construct a polar code that achieves a corner point of R SW , one expands H(U N , V N ) as\nand shows that the entropy terms polarize to 0 or 1 as N increases.\nIn the joint polarization approach mentioned above, one uses the expansion\nand proves that the entropy terms in (5) polarize to 0, 1, or 2. Actually, to construct a speciﬁc polar code, one needs to expand (5) further, for example, as\nand show that the entropy terms in (6) converge to 0 or 1. By using the degrees of freedom in expanding (5) into an expansion of type (6), one obtains polar codes achieving various rates on the dominant face of R SW directly (without time-sharing). However, as shown in [11], this approach cannot achieve the entire dominant face in general.\nIt is clear that there are many other ways in which the total entropy H(U N , V N ) can be expanded into a sum of individual entropy terms, suggesting that there may exist many more polar codes, again raising the hope that the entire dominant face may be achievable by polar coding. This is the idea pursued in this paper.\nWe call a chain rule expansion of U N V N monotone w.r.t. U N if the expansion is of the form\nwhere S 2N = (S 1 , . . . , S 2N ) is a permutation of U N V N such that the permutation preserves the relative order of the ele- ments of U N . We deﬁne the monotonicity of a chain rule w.r.t. V N similarly. A chain rule for U N V N is said to be monotone if it is monotone w.r.t. both U N and V N . The expansions (4) and (6) are examples of monotone chain rules. The expansion H(U 2 ) + H(U 1 |U 2 ) + H(V 1 |U 1 , U 2 ) + H(V 2 |U 1 , U 2 , V 1 ) is\nWe use diagrams, as in Fig. 1, to represent monotone chain rules, and refer to them brieﬂy as \u201cchain rule diagrams.\u201d Each directed path in Fig. 1, from ∅ to U 4 V 4 , corresponds to a monotone chain rule on H(U 4 , V 4 ). For example, the \u201ccorner-point\u201d path that goes from ∅ horizontally to U 4 and then vertically down to U 4 V 4 corresponds to the expansion (4). The \u201cstaircase\u201d path ( ∅, U 1 , U 1 V 1 , U 2 V 1 , U 2 V 2 , U 3 V 2 , U 3 V 3 , U 4 V 3 , U 4 V 4 )\nA label U i V j attached to a node in a chain rule diagram designates the known variables when, and if, a chain rule visits that node; the entropy H(U i , V j ) is used to measure the amount of that knowledge. The edge connecting node U i−1 V j to node U i V j is associated with the variable U i and carries H(U i |U i−1 , V j ) units of incremental knowledge. Likewise, the edge connecting two vertically adjacent nodes\nU i V j−1 and U i V j is associated with V j and carries an incre- mental knowledge of H(V j |U i , V j−1 ) units. There is a path- independence property associated with states of knowledge in chain rule diagrams in the sense that the accumulated knowledge H(U i , V j ) at a node U i V j is the sum of the conditional entropy terms along any path from ∅ to U i V j . In this sense, the entropy values assigned to the nodes form a potential function. Investigation of the properties of this potential function is left for future work. Here, we just note an elementary monotonicity property that may be useful for such studies.\nProposition 1. The conditional entropy terms associated with vertical edges in the chain rule diagram for U N V N are monotone in the sense that, for any ﬁxed 1 ≤ j ≤ N, H(V j |U i−1 , V j−1 ) ≥ H(V j |U i , V j−1 ) for all 1 ≤ i ≤ N. Likewise, for any ﬁxed 1 ≤ i ≤ N, H(U i |U i−1 , V j−1 ) ≥ H(U i |U i−1 , V j ) for all 1 ≤ j ≤ N.\nThe chain rule diagram for U N V N contains 2N N paths from the initial node ∅ to the ﬁnal node U N V N . We identify each path in the diagram by a string b 2N = b 1 b 2 · · · b 2N where b i is 0 if the ith move along the path is in the horizontal direction and 1 otherwise. For instance, the corner-point path in Fig. 1 that goes from ∅ to U 4 then to U 4 V 4 has the label 00001111. The label 01010101 designates the staircase path of expansion (6).\nLet S 2N = (S 1 , . . . , S 2N ) denote the edge variables along a given path b 2N . For example, for b 8 = 01010101, the edge variables are S 8 = (U 1 , V 1 , U 2 , V 2 , U 3 , V 3 , U 4 , V 4 ).\nFor any given path b 2N with edge variables S 2N , we deﬁne a pair of rates\nThe rate R 1 ( R 2 ) is the sum of the conditional entropy terms on the horizontal (vertical) edges in the path, normalized by N . For b 8 = 01010101, the rate R 1 is given by\nStated in terms of the original source variables, these inequal- ities take the following form.\nProposition 2. Let U N V N be obtained from a memoryless source X N Y N by (1). Then, the rate pair (R 1 , R 2 ) for any monotone chain rule expansion of U N V N satisﬁes\nThe ﬁrst inequality is satisﬁed with equality for the path 1 N 0 N , and the second inequality is satisﬁed with equality for 0 N 1 N .\nThis follows easily from the fact that the transform (1) is one-to-one. Thus, the rate pairs (R 1 , R 2 ) over the class of monotone chain rules lie on the dominant face of the region R SW , spanning its two end-points. The next question we address is whether the rate pairs from this class form a dense subset of the dominant face.\nLet b 2N and ˜ b 2N be any two paths in the chain rule diagram for U N V N , with rate pairs (R 1 , R 2 ) and ( ˜ R 1 , ˜ R 2 ), respectively. We deﬁne the distance between b 2N and ˜ b 2N as\nNote that since R 1 + R 2 = ˜ R 1 + ˜ R 2 = H(X, Y ), this distance is also given by |R 2 − ˜ R 2 |.\nWe now seek a combinatorial notion of neighborhood among paths that is consistent with the above notion of distance. It is tempting to deﬁne two paths as neighbors if they differ by a transposition; however, this does not quite work here. For example, the path b 8 = 01010011 has a rate R 1 given by (10) while the path ˜ b 8 = 11010010, which differs from b 8 by a single transposition, has a rate given by\nIt is not clear if |R 1 − ˜ R 1 | is small. If we restrict the class of transpositions as follows, we obtain a notion of neighborhood which serves our purposes.\nLet two paths ˜ b 2N and b 2N be neighbors if ˜ b 2N can be obtained from b 2N by transposing b i with b j for some i < j such that (i) b i = b j and (ii) the substring b i+1 b i+2 · · · b j−1 bracketed by the transposed elements is either a string of all 0s\nor all 1s. For instance, 10000111 and 00001111 are neighbors but 01001011 and 00001111 are not. Note that a path cannot be a neighbor of itself according to this deﬁnition.\nProof: Let b 2N be a path with edge variables S 2N and let ˜ b 2N differ from b 2N by a transposition in the coordinates i < j. Assume that b i = 0, b j = 1, and that the bracketed string b i+1 · · · b j−1 is all 1s. Then, observe that R 1 − ˜ R 1 = (1/N )[H(S i |S i−1 ) − H(S i |S i−1 , S j , S j−1 i+1 )]. It is clear that R 1 − ˜ R 1 ≥ 0. Moreover, R 1 − ˜ R 1 ≤ (1/N)H(S i |S i−1 ) ≤ 1/N . Thus, |R 1 − ˜ R 1 | ≤ 1/N. This covers the case of b j i being equal to 01 j−i . There are three other possibilities for b j i , namely, 0 j−i 1, 1 j−i 0, and 10 j−i . These other cases can be treated similarly to the ﬁrst by exchanging the roles of b 2N and ˜ b 2N or by considering R 2 − ˜ R 2 or both.\nWe now turn our attention to rate approximations. For this, we focus on the subset of paths V 2N ∆ = {0 i 1 N 0 N −i : 0 ≤ i ≤ N } that have only one vertical segment.\nTheorem 1. Let (R x , R y ) be a given rate pair on the dominant face of the Slepian-Wolf rate region. For any given > 0, there exists N and a chain rule b 2N on U N V N such that b 2N belongs to the class V 2N and has a rate pair (R 1 , R 2 ) satisfying\nProof: Fix N > 1/ . Let (R 1 (i), R 2 (i)) denote the rate pair for the path 0 i 1 N 0 N −i , for 0 ≤ i ≤ N. We have R 1 (0) = H(X |Y ) and R 1 (N ) = H(X). Also, |R 1 (i + 1) − R 1 (i) | ≤\n1/N by Proposition 3. Thus, for any R x ∈ [H(X|Y ), H(X)] there exists 0 ≤ i ≤ N such that |R 1 (i) − R x | ≤ 1/N. For this i, we must also have that |R 2 (i) − R y | ≤ 1/N.\nTheorem 1 shows that we can approximate arbitrary points on the dominant face of R SW with paths from the class {V 2N : N = 2 n , n ≥ 1}. Clearly, other classes of paths could have been used (some more effectively) for rate approximations. The class {V 2N } has the advantage of being simple.\nAlthough we have found a way of approximating rates, the polarization issue has not yet been addressed. Here, we introduce an operation on paths that achieves polarization while keeping the rate approximation intact.\nFor any path b 2N = b 1 b 2 · · · b 2N representing a monotone chain rule for U N V N and any integer k = 2 m , let kb 2N denote\nwhich represents a monotone chain rule for U kN V kN . This operation is a geometric scaling operation in the sense that it preserves the \u201cshape\u201d of the original path. In particular, if b 2N belongs to the class V 2N then kb 2N belongs to V 2kN .\nFix a path b 2N for U N V N and consider the path 2b 2N for U 2N V 2N . Let S 2N and T 4N denote the edge variables for\nb 2N and 2b 2N , respectively. Let ˜ S 2N be an independent copy of S 2N . The transformation (1) may be viewed as a mapping from the pair of random vectors (S 2N , ˜ S 2N ) to T 4N with\nThis gives the following relationship between the entropies H(T 2i−1 |T 2i−2 ) + H(T 2i |T 2i−1 )\n= H(S i ⊕ ˜ S i , S i |S i−1 ⊕ ˜ S i−1 , S i−1 ) = H( ˜ S i , S i | ˜ S i−1 , S i−1 )\nThis may be interpreted as a local conservation law for conditional entropies under path scaling. As a corollary, the path rates (R 1 , R 2 ) are preserved under path scaling.\nProposition 4. Let b 2N be a ﬁxed path. Let (R 1 , R 2 ) be the rate pair for b 2N . Then, for any m ≥ 1, (R 1 , R 2 ) is also the rate pair for the path 2 m b 2N .\nH(T 2i |T 2i−1 ) = H(S i |T 2i−2 , T 2i−1 ) ≤ H(S i |T 2i−2 )\nwhere there is equality if and only if H(T 2i |T 2i−1 ) equals 0 or 1. Thus,\nWe can keep doubling (scaling by two) the paths to enhance polarization. Asymptotically, we obtain the following result.\nTheorem 2. Let (X, Y ) ∼ P X,Y be an arbitrary memoryless source over the alphabet X × Y where X = Y = {0, 1}. Consider the setting deﬁned by equations (1) and (2). Fix N 0 = 2 n 0 for some n 0 ≥ 1. Fix a path b 2N 0 for U N 0 V N 0 . Let (R 1 , R 2 ) be the rate pair for b 2N 0 . Let N = 2 m N 0 for m ≥ 1 and let T 2N be the edge variables for 2 m b 2N 0 . Then, for any given δ > 0, as m goes to inﬁnity, we have\ni−1 ) < 1 − δ} → 0, (18) |A 1 (δ) |\nwhere A j (δ) = {1 ≤ i ≤ 2N : b i = j, H(T i |T i−1 ) > δ } for j = 0, 1. Furthermore, this statement remains true even if δ is allowed to go to zero as a function of N as δ = O(2 − N β ), where β is ﬁxed as any positive number less than 1/2.\nWe omit the proof of this theorem due to space limitations and also because it follows by standard ideas presented in detail elsewhere. We just note that the ﬁrst step of the proof is to set up a martingale for the conditional entropy terms using\nthe conservation law (15). One may then use the approach taken in [4] which uses an auxiliary supermartingale based on the source Bhattacharyya parameters; alternatively, one may use the direct approach by S¸as¸o˘glu [11, Lemma 2.1] in which only the main martingale is used. To prove the exponential convergence claim of the theorem one may use the method presented in [13].\nTo summarize, this subsection has shown that one can achieve rate-approximation and polarization without leaving the class of paths {V 2N : N = 2 n , n ≥ 1}.\nWe now combine the above results to give a polar coding scheme for the Slepian-Wolf problem. The polar codes consid- ered here are deﬁned by two parameters (b 2N , δ) where b 2N is a monotone chain rule for U N V N and δ > 0 is a threshold parameter.\nGiven a source realization (x N , y N ), encoders 1 and 2 compute u N = x N G N and v N = y N G N , respectively, as deﬁned by equations (1) and (2). The realizations u N and v N deﬁne a realization t 2N of the edge variables T 2N associated with b 2N . Encoder 1 possesses u N = (t i : b i = 0) and transmits the variables (t i : i ∈ A 1 (δ)), while encoder 2 possesses v N = (t i : b i = 1) and transmits (t i : i ∈ A 2 (δ)). The rates for this scheme are given by |A 1 (δ) |/N for user 1 and |A 2 (δ) |/N for user 2.\nThe decoder receives the variables (t i : i ∈ A(δ)} where A(δ) = A 1 (δ) ∪ A 2 (δ) and wishes to reconstruct the missing variables (t i : i / ∈ A(δ)). For this task, we consider a successive cancellation (SC) decoder, as in [12] and [4]. The SC decoder enters the ith step of decoding with the decisions ˆ t i−1 from previous steps and sets the current decision as ˆ t i = 0 if Pr(T i = 0 |T i−1 = ˆ t i−1 ) is greater than Pr(T i = 1 |T i−1 = ˆ t i−1 ) and as ˆ t i = 1 otherwise. If i ∈ A(δ), the decoder overrides this rule by setting ˆ t i = t i since in that case the decoder already knows the correct value of t i .\nOnce the estimate ˆ t 2N of t 2N is obtained, the decoder sets ˆ u N = (ˆ t i : b i = 0) and ˆ v N = (ˆ t i : b i = 1), and calculates ˆ x N = ˆ u N (G N ) − 1 and ˆ y N = ˆ v N (G N ) − 1 , to obtain the estimates of x N and y N , respectively. Note that for the mapping G N here, the inverse of G N is itself, so this ﬁnal step is just another encoding operation.\nThe performance of the above coding scheme is mea- sured by the probability of frame error, deﬁned as P e ∆ = Pr[( ˆ X N , ˆ Y N ) = (X N , Y N )]. Equivalent expressions for the frame error probability are P e = Pr[( ˆ U N , ˆ V N ) = (U N , V N )] and P e = Pr( ˆ T N = T N ). By the \u201cgenie-bound\u201d for SC decoders (see, e.g., [12]), the frame error can be bounded as P e ≤ i / ∈ A(δ) Pr( ˆ T i = T i | ˆ T i−1 = T i−1 ). Further, one has Pr( ˆ T i = T i | ˆ T i−1 = T i−1 ) ≤ Z(T i |T i−1 ) where Z(T i |T i−1 )\nis the source Bhattacharyya parameter deﬁned in [4]. The parameter Z(T i |T i−1 ) is in turn bounded by H(T i |T i−1 ) by Prop. 2 of [4]. Thus, P e ≤ i / ∈ A(δ) H(T i |T i−1 ) ≤ (N − |A(δ)|)\nTheorem 3. Consider an arbitrary memoryless source (X, Y ) ∼ P X,Y over the alphabet X × Y with X = Y = {0, 1}. Let (R x , R y ) be a target point in the Slepian-Wolf rate region. Given any > 0 and β < 1/2, there exists a polar coding scheme (b 2N , δ) such that (i) the path b 2N has the form 0 i 1 N 0 N −i for some 0 ≤ i ≤ N, (ii) the threshold parameter satisﬁes δ = O(2 − N β ), (iii) users 1 and 2 transmit at rates |A 1 (δ) |/N ≤ R x + and |A 2 (δ) |/N ≤ R y + , respectively, and (iv) the probability of error under successive cancellation decoding satisﬁes P e = O(2 − 1 2 N β ).\nProof: We may assume without loss of generality that the target rate (R x , R y ) lies on the dominant face of the rate region R SW . Theorem 1 guarantees the existence of a path b 2N 0 in V 2N 0 for which the rate pair (R 1 , R 2 ) satisﬁes R 1 ≤ R x + /2 and R 2 ≤ R y + /2. We ﬁx such a path. Theorem 2 guarantees that there exists a path b 2N = 2 m b 2N 0 for some m ≥ 1 for which the sets A 1 (δ) and A 2 (δ) satisfy |A 1 (δ) |/N ≤ R 1 + /2 and |A 2 (δ) |/N ≤ R 2 + /2 with δ = O(2 − N β ). The Slepian- Wolf code deﬁned by the parameters (b 2N , δ) achieves the rates |A 1 (δ) |/N ≤ R x + and |A 2 (δ) |/N ≤ R y + , and has a probability of error bounded by P e ≤ N\nThe encoding operations in the above Slepian-Wolf polar coding scheme are the same as in the single-user case and have complexity O(N log N ) as in that case [12].\nIt can be shown that the SC decoder here can be imple- mented in complexity O(N log N ) as in the single user case. At each step of decoding, the SC decoder needs to calculate a probability of the form P 2N (u i , v j ) ∆ = Pr(U i = u i , V j = v j ), where the subscript 2N indicates the length of the code. Depending on whether i and j are odd or even, there is a different recursive formula to carry out this calculation. For example, P 2N (u 2i−1 , v 2j−1 ) can be calculated as\nwhere u 2i o and u 2i e denote the sub-vectors consisting of odd- numbered and even-numbered coordinates of u 2i , respectively, and similarly for v 2j o and v 2j e . This reduction is continued until the desired probabilities can be computed from P X,Y directly.\nFinally, for code construction, one needs to be able to com- pute entropy terms of the form {H(T i |T i−1 ) : 1 ≤ i ≤ 2N} along a chosen path. This type of computation is necessary both for rate approximations and also for determining the sets A 1 (δ) and A 2 (δ). We conjecture that the density evolution method for ordinary polar coding developed in [14] and [15] can be adapted to this case, too, so as to compute these entropy terms with sufﬁcient precision in complexity O(N ).\nWe considered polarization in the context of monotone chain rules, which is the largest class of chain rules that respects the natural decoding order deﬁned by polarization. The main coding result has been the derivation of a polar coding scheme that achieves the Slepian-Wolf rate region without time-sharing.\nMost of the discussion has been restricted to the subset of monotone chain rules represented by paths of the type 0 i 1 N 0 N −i for 0 ≤ i ≤ N. On closer inspection, the use of such paths reminds one of the \u201csource-splitting\u201d approach to Slepian-Wolf coding developed by Rimoldi and Urbanke [16]. A path of the form 0 i 1 N 0 N −i has three segments, with each segment corresponding to a virtual source in the rate-splitting argument. In effect, the polar codes that we have constructed appear to operate at a corner point of a Slepian-Wolf rate region for three virtual sources.\nFinally, we wish to note that, although not discussed ex- plicitly, the results of this paper have duals in the context of coding for the MAC and yield capacity-achieving polar codes without time-sharing in that context."},"refs":[{"authors":[{"name":"D. Slepian"},{"name":"J. Wolf"}],"title":{"text":"Noiseless coding of correlated information sources"}},{"authors":[{"name":"N. Hussami"},{"name":"S. B. Korada"},{"name":"R. Urbanke"}],"title":{"text":"Performance of polar codes for channel and source coding"}},{"authors":[{"name":"S. B. Korad"}],"title":{"text":"Polar codes for channel and source coding"}},{"authors":[{"name":"E. Arıkan"}],"title":{"text":"Source polarization"}},{"authors":[{"name":"T. Cover"}],"title":{"text":"A proof of the data compression theorem of Slepian and Wolf for ergodic sources"}},{"authors":[{"name":"E. S¸as¸o˘glu"},{"name":"E. Telatar"},{"name":"E. Yeh"}],"title":{"text":"Polar codes for the two-user binary-input multiple-access channel"}},{"authors":[{"name":"E. Abbe"},{"name":"E. Telatar"}],"title":{"text":"MAC polar codes and matroids"}},{"authors":[{"name":"E. Abbe"},{"name":"E. Telatar"}],"title":{"text":"Polar Codes for the m-User MAC"}},{"authors":[{"name":"E. Arıkan"}],"title":{"text":"Source polarization"}},{"authors":[{"name":"E. Abbe"}],"title":{"text":"Extracting randomness and dependencies via a matrix polar- ization"}},{"authors":[{"name":"E. S¸as¸o˘glu"}],"title":{"text":"Polar Coding Theorems for Discrete Systems"}},{"authors":[{"name":"E. Arıkan"}],"title":{"text":"Channel polarization: A method for constructing capacity- achieving codes for symmetric binary-input memoryless channels"}},{"authors":[{"name":"E. Arıkan"},{"name":"E. Telatar"}],"title":{"text":"On the rate of channel polarization"}},{"authors":[{"name":"R. Mori"},{"name":"T. Tanaka"}],"title":{"text":"Performance and construction of polar codes on symmetric binary-input memoryless channels"}},{"authors":[{"name":"I. Tal"},{"name":"A. Vardy"}],"title":{"text":"How to Construct Polar Codes"}},{"authors":[{"name":"B. Rimoldi"},{"name":"R. Urbanke"}],"title":{"text":"Asynchronous Slepian-Wolf coding via source-splitting"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569559111.pdf"},"links":[{"id":"1569566485","weight":5},{"id":"1569565883","weight":16},{"id":"1569565867","weight":5},{"id":"1569565691","weight":5},{"id":"1569566605","weight":11},{"id":"1569566683","weight":11},{"id":"1569565551","weight":5},{"id":"1569566943","weight":5},{"id":"1569564481","weight":5},{"id":"1569566415","weight":5},{"id":"1569566081","weight":5},{"id":"1569566871","weight":5},{"id":"1569565461","weight":5},{"id":"1569566207","weight":22},{"id":"1569560427","weight":5},{"id":"1569559541","weight":5},{"id":"1569565317","weight":5},{"id":"1569564203","weight":5},{"id":"1569564249","weight":5},{"id":"1569558483","weight":5},{"id":"1569565347","weight":5},{"id":"1569551763","weight":5},{"id":"1569564189","weight":5},{"id":"1569564613","weight":5},{"id":"1569566865","weight":5},{"id":"1569566617","weight":5},{"id":"1569563307","weight":33},{"id":"1569555999","weight":5},{"id":"1569566643","weight":5},{"id":"1569566369","weight":5},{"id":"1569561143","weight":5},{"id":"1569566581","weight":16},{"id":"1569566423","weight":5},{"id":"1569565257","weight":5},{"id":"1569558901","weight":5},{"id":"1569553909","weight":5},{"id":"1569552251","weight":5},{"id":"1569553519","weight":5},{"id":"1569567051","weight":5},{"id":"1569566231","weight":5},{"id":"1569565655","weight":5},{"id":"1569566909","weight":5},{"id":"1569566809","weight":5},{"id":"1569566447","weight":5},{"id":"1569565887","weight":5},{"id":"1569565633","weight":11},{"id":"1569565219","weight":11},{"id":"1569554759","weight":5},{"id":"1569566223","weight":5},{"id":"1569562207","weight":11},{"id":"1569566191","weight":11},{"id":"1569566655","weight":5},{"id":"1569566501","weight":5},{"id":"1569566245","weight":5},{"id":"1569560503","weight":5},{"id":"1569565439","weight":5},{"id":"1569565885","weight":11},{"id":"1569566805","weight":5},{"id":"1569566293","weight":44},{"id":"1569565765","weight":33},{"id":"1569565215","weight":5},{"id":"1569565093","weight":5},{"id":"1569565919","weight":5},{"id":"1569565241","weight":5},{"id":"1569565661","weight":11},{"id":"1569566737","weight":38},{"id":"1569564595","weight":5},{"id":"1569566035","weight":5},{"id":"1569564305","weight":33},{"id":"1569566547","weight":11},{"id":"1569565177","weight":5},{"id":"1569565375","weight":5},{"id":"1569566639","weight":5},{"id":"1569566755","weight":5},{"id":"1569566713","weight":5},{"id":"1569565597","weight":5},{"id":"1569566641","weight":5},{"id":"1569564437","weight":5},{"id":"1569565529","weight":5},{"id":"1569566619","weight":5},{"id":"1569565271","weight":11},{"id":"1569566075","weight":5},{"id":"1569566817","weight":5},{"id":"1569567483","weight":5},{"id":"1569564281","weight":5},{"id":"1569565769","weight":5},{"id":"1569565805","weight":11},{"id":"1569561713","weight":5},{"id":"1569557851","weight":16},{"id":"1569567691","weight":5},{"id":"1569565861","weight":5},{"id":"1569565537","weight":5},{"id":"1569566847","weight":5},{"id":"1569565997","weight":11},{"id":"1569565731","weight":5},{"id":"1569566797","weight":5},{"id":"1569565707","weight":16},{"id":"1569565113","weight":5},{"id":"1569565143","weight":38},{"id":"1569564931","weight":5},{"id":"1569566973","weight":5},{"id":"1569565031","weight":5},{"id":"1569551751","weight":5},{"id":"1569565139","weight":11},{"id":"1569566067","weight":11},{"id":"1569566825","weight":11},{"id":"1569566443","weight":5},{"id":"1569566727","weight":44},{"id":"1569565315","weight":5}],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S4.T1.2","endtime":"17:20","authors":"Erdal Arıkan","date":"1341248400000","papertitle":"Polar Coding for the Slepian-Wolf Problem Based on Monotone Chain Rules","starttime":"17:00","session":"S4.T1: The Slepian-Wolf and CEO Problems","room":"Kresge Rehearsal B (030)","paperid":"1569559111"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
